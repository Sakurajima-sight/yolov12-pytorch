# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
åœ¨æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ã€‚

ç”¨æ³•ï¼š
    $ yolo mode=train model=yolov8n.pt data=coco8.yaml imgsz=640 epochs=100 batch=16
"""

import gc
import math
import os
import subprocess
import time
import warnings
from copy import copy, deepcopy
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np
import torch
from torch import distributed as dist
from torch import nn, optim

from ultralytics.cfg import get_cfg, get_save_dir
from ultralytics.data.utils import check_cls_dataset, check_det_dataset
from ultralytics.nn.tasks import attempt_load_one_weight, attempt_load_weights
from ultralytics.utils import (
    DEFAULT_CFG,
    LOCAL_RANK,
    LOGGER,
    RANK,
    TQDM,
    __version__,
    callbacks,
    clean_url,
    colorstr,
    emojis,
    yaml_save,
)
from ultralytics.utils.autobatch import check_train_batch_size
from ultralytics.utils.checks import check_amp, check_file, check_imgsz, check_model_file_from_stem, print_args
from ultralytics.utils.dist import ddp_cleanup, generate_ddp_command
from ultralytics.utils.files import get_latest_run
from ultralytics.utils.torch_utils import (
    TORCH_2_4,
    EarlyStopping,
    ModelEMA,
    autocast,
    convert_optimizer_state_dict_to_fp16,
    init_seeds,
    one_cycle,
    select_device,
    strip_optimizer,
    torch_distributed_zero_first,
)


class BaseTrainer:
    """
    åˆ›å»ºè®­ç»ƒå™¨çš„åŸºç±»ã€‚

    å±æ€§:
        args (SimpleNamespace): è®­ç»ƒå™¨çš„é…ç½®ã€‚
        validator (BaseValidator): éªŒè¯å™¨å®ä¾‹ã€‚
        model (nn.Module): æ¨¡å‹å®ä¾‹ã€‚
        callbacks (defaultdict): å›è°ƒå‡½æ•°çš„å­—å…¸ã€‚
        save_dir (Path): ä¿å­˜ç»“æœçš„ç›®å½•ã€‚
        wdir (Path): ä¿å­˜æƒé‡çš„ç›®å½•ã€‚
        last (Path): æœ€åæ£€æŸ¥ç‚¹çš„è·¯å¾„ã€‚
        best (Path): æœ€ä½³æ£€æŸ¥ç‚¹çš„è·¯å¾„ã€‚
        save_period (int): æ¯xä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœå°äº1åˆ™ç¦ç”¨ï¼‰ã€‚
        batch_size (int): è®­ç»ƒæ—¶çš„æ‰¹é‡å¤§å°ã€‚
        epochs (int): è®­ç»ƒçš„æ€»è½®æ•°ã€‚
        start_epoch (int): è®­ç»ƒçš„èµ·å§‹è½®æ•°ã€‚
        device (torch.device): ç”¨äºè®­ç»ƒçš„è®¾å¤‡ã€‚
        amp (bool): å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰çš„æ ‡å¿—ã€‚
        scaler (amp.GradScaler): AMPçš„æ¢¯åº¦ç¼©æ”¾å™¨ã€‚
        data (str): æ•°æ®è·¯å¾„ã€‚
        trainset (torch.utils.data.Dataset): è®­ç»ƒæ•°æ®é›†ã€‚
        testset (torch.utils.data.Dataset): æµ‹è¯•æ•°æ®é›†ã€‚
        ema (nn.Module): æ¨¡å‹çš„EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰ã€‚
        resume (bool): æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚
        lf (nn.Module): æŸå¤±å‡½æ•°ã€‚
        scheduler (torch.optim.lr_scheduler._LRScheduler): å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
        best_fitness (float): è¾¾åˆ°çš„æœ€ä½³é€‚åº”åº¦å€¼ã€‚
        fitness (float): å½“å‰çš„é€‚åº”åº¦å€¼ã€‚
        loss (float): å½“å‰çš„æŸå¤±å€¼ã€‚
        tloss (float): æ€»æŸå¤±å€¼ã€‚
        loss_names (list): æŸå¤±åç§°çš„åˆ—è¡¨ã€‚
        csv (Path): ç»“æœCSVæ–‡ä»¶çš„è·¯å¾„ã€‚
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """
        åˆå§‹åŒ– BaseTrainer ç±»ã€‚

        å‚æ•°:
            cfg (str, å¯é€‰): é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤ä¸º DEFAULT_CFGã€‚
            overrides (dict, å¯é€‰): é…ç½®çš„è¦†ç›–ã€‚é»˜è®¤ä¸º Noneã€‚
        """
        self.args = get_cfg(cfg, overrides)
        self.check_resume(overrides)
        self.device = select_device(self.args.device, self.args.batch)
        self.validator = None
        self.metrics = None
        self.plots = {}
        init_seeds(self.args.seed + 1 + RANK, deterministic=self.args.deterministic)

        # ç›®å½•
        self.save_dir = get_save_dir(self.args)
        self.args.name = self.save_dir.name  # æ›´æ–°æ—¥å¿—çš„åç§°
        self.wdir = self.save_dir / "weights"  # æƒé‡ç›®å½•
        if RANK in {-1, 0}:
            self.wdir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•
            self.args.save_dir = str(self.save_dir)
            yaml_save(self.save_dir / "args.yaml", vars(self.args))  # ä¿å­˜è¿è¡Œå‚æ•°
        self.last, self.best = self.wdir / "last.pt", self.wdir / "best.pt"  # æ£€æŸ¥ç‚¹è·¯å¾„
        self.save_period = self.args.save_period

        self.batch_size = self.args.batch
        self.epochs = self.args.epochs or 100  # å¦‚æœç”¨æˆ·æ„å¤–ä¼ é€’ epochs=None ä¸”æœ‰å®šæ—¶è®­ç»ƒï¼Œåˆ™é»˜è®¤ä¸º 100
        self.start_epoch = 0
        if RANK == -1:
            print_args(vars(self.args))

        # è®¾å¤‡
        if self.device.type in {"cpu", "mps"}:
            self.args.workers = 0  # æ›´å¿«çš„ CPU è®­ç»ƒï¼Œå› ä¸ºæ—¶é—´ä¸»è¦è¢«æ¨ç†å æ®ï¼Œè€Œä¸æ˜¯æ•°æ®åŠ è½½

        # æ¨¡å‹å’Œæ•°æ®é›†
        self.model = check_model_file_from_stem(self.args.model)  # æ·»åŠ åç¼€ï¼Œä¾‹å¦‚ yolov8n -> yolov8n.pt
        with torch_distributed_zero_first(LOCAL_RANK):  # é¿å…æ•°æ®é›†è‡ªåŠ¨ä¸‹è½½å¤šæ¬¡
            self.trainset, self.testset = self.get_dataset()
        self.ema = None

        # ä¼˜åŒ–å·¥å…·åˆå§‹åŒ–
        self.lf = None
        self.scheduler = None

        # æ¯ä¸ª epoch çš„æŒ‡æ ‡
        self.best_fitness = None
        self.fitness = None
        self.loss = None
        self.tloss = None
        self.loss_names = ["Loss"]
        self.csv = self.save_dir / "results.csv"
        self.plot_idx = [0, 1, 2]

        # HUB
        self.hub_session = None

        # å›è°ƒå‡½æ•°
        self.callbacks = _callbacks or callbacks.get_default_callbacks()
        if RANK in {-1, 0}:
            callbacks.add_integration_callbacks(self)

    def add_callback(self, event: str, callback):
        """æ·»åŠ ç»™å®šçš„å›è°ƒå‡½æ•°ã€‚"""
        self.callbacks[event].append(callback)

    def set_callback(self, event: str, callback):
        """ç”¨ç»™å®šçš„å›è°ƒå‡½æ•°æ›¿æ¢ç°æœ‰çš„å›è°ƒå‡½æ•°ã€‚"""
        self.callbacks[event] = [callback]

    def run_callbacks(self, event: str):
        """è¿è¡Œä¸ç‰¹å®šäº‹ä»¶å…³è”çš„æ‰€æœ‰å›è°ƒå‡½æ•°ã€‚"""
        for callback in self.callbacks.get(event, []):
            callback(self)

    def train(self):
        """åœ¨å¤š GPU ç³»ç»Ÿä¸­å…è®¸ device='' æˆ– device=None é»˜è®¤ä½¿ç”¨ device=0ã€‚"""
        if isinstance(self.args.device, str) and len(self.args.device):  # å³ device='0' æˆ– device='0,1,2,3'
            world_size = len(self.args.device.split(","))
        elif isinstance(self.args.device, (tuple, list)):  # å³ device=[0, 1, 2, 3]ï¼ˆä»å‘½ä»¤è¡Œä¼ å…¥çš„å¤š GPU åˆ—è¡¨ï¼‰
            world_size = len(self.args.device)
        elif self.args.device in {"cpu", "mps"}:  # å³ device='cpu' æˆ– 'mps'
            world_size = 0
        elif torch.cuda.is_available():  # å³ device=None æˆ– device='' æˆ– device=number
            world_size = 1  # é»˜è®¤ä½¿ç”¨è®¾å¤‡ 0
        else:  # å³ device=None æˆ– device=''
            world_size = 0

        # å¦‚æœæ˜¯ DDP è®­ç»ƒåˆ™è¿è¡Œå­è¿›ç¨‹ï¼Œå¦åˆ™æ­£å¸¸è®­ç»ƒ
        if world_size > 1 and "LOCAL_RANK" not in os.environ:
            # å‚æ•°æ£€æŸ¥
            if self.args.rect:
                LOGGER.warning("è­¦å‘Š âš ï¸ 'rect=True' ä¸å¤š GPU è®­ç»ƒä¸å…¼å®¹ï¼Œè®¾ç½® 'rect=False'")
                self.args.rect = False
            if self.args.batch < 1.0:
                LOGGER.warning(
                    "è­¦å‘Š âš ï¸ 'batch<1' çš„ AutoBatch ä¸å¤š GPU è®­ç»ƒä¸å…¼å®¹ï¼Œè®¾ç½®é»˜è®¤å€¼ 'batch=16'"
                )
                self.args.batch = 16

            # å‘½ä»¤
            cmd, file = generate_ddp_command(world_size, self)
            try:
                LOGGER.info(f"{colorstr('DDP:')} è°ƒè¯•å‘½ä»¤ {' '.join(cmd)}")
                subprocess.run(cmd, check=True)
            except Exception as e:
                raise e
            finally:
                ddp_cleanup(self, str(file))

        else:
            self._do_train(world_size)

    def _setup_scheduler(self):
        """åˆå§‹åŒ–è®­ç»ƒå­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚"""
        if self.args.cos_lr:
            self.lf = one_cycle(1, self.args.lrf, self.epochs)  # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦ 1->hyp['lrf']
        else:
            self.lf = lambda x: max(1 - x / self.epochs, 0) * (1.0 - self.args.lrf) + self.args.lrf  # çº¿æ€§å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=self.lf)

    def _setup_ddp(self, world_size):
        """åˆå§‹åŒ–å¹¶è®¾ç½®ç”¨äºè®­ç»ƒçš„ DistributedDataParallel å‚æ•°ã€‚"""
        torch.cuda.set_device(RANK)
        self.device = torch.device("cuda", RANK)
        # LOGGER.info(f'DDP ä¿¡æ¯: RANK {RANK}, WORLD_SIZE {world_size}, DEVICE {self.device}')
        os.environ["TORCH_NCCL_BLOCKING_WAIT"] = "1"  # è®¾ç½®ä¸ºå¼ºåˆ¶è¶…æ—¶
        dist.init_process_group(
            backend="nccl" if dist.is_nccl_available() else "gloo",
            timeout=timedelta(seconds=10800),  # 3 å°æ—¶
            rank=RANK,
            world_size=world_size,
        )

    def _setup_train(self, world_size):
        """åœ¨æ­£ç¡®çš„è¿›ç¨‹ä¸­æ„å»ºæ•°æ®åŠ è½½å™¨å’Œä¼˜åŒ–å™¨ã€‚"""
        # æ¨¡å‹
        self.run_callbacks("on_pretrain_routine_start")
        ckpt = self.setup_model()
        self.model = self.model.to(self.device)
        self.set_model_attributes()

        # å†»ç»“å±‚
        freeze_list = (
            self.args.freeze
            if isinstance(self.args.freeze, list)
            else range(self.args.freeze)
            if isinstance(self.args.freeze, int)
            else []
        )
        always_freeze_names = [".dfl"]  # å§‹ç»ˆå†»ç»“è¿™äº›å±‚
        freeze_layer_names = [f"model.{x}." for x in freeze_list] + always_freeze_names
        for k, v in self.model.named_parameters():
            # v.register_hook(lambda x: torch.nan_to_num(x))  # NaN å˜ä¸º 0ï¼ˆå·²æ³¨é‡Šæ‰ä»¥é¿å…è®­ç»ƒç»“æœä¸ç¨³å®šï¼‰
            if any(x in k for x in freeze_layer_names):
                LOGGER.info(f"å†»ç»“å±‚ '{k}'")
                v.requires_grad = False
            elif not v.requires_grad and v.dtype.is_floating_point:  # åªæœ‰æµ®ç‚¹å‹å¼ é‡æ‰èƒ½è¦æ±‚è®¡ç®—æ¢¯åº¦
                LOGGER.info(
                    f"è­¦å‘Š âš ï¸ è®¾ç½® 'requires_grad=True' ä¸ºè¢«å†»ç»“çš„å±‚ '{k}'ã€‚"
                    "æŸ¥çœ‹ ultralytics.engine.trainer ä»¥è‡ªå®šä¹‰å†»ç»“å±‚ã€‚"
                )
                v.requires_grad = True

        # æ£€æŸ¥ AMPï¼ˆè‡ªåŠ¨æ··åˆç²¾åº¦ï¼‰
        self.amp = torch.tensor(self.args.amp).to(self.device)  # True æˆ– False
        if self.amp and RANK in {-1, 0}:  # å• GPU å’Œ DDP
            callbacks_backup = callbacks.default_callbacks.copy()  # å¤‡ä»½å›è°ƒå‡½æ•°ï¼Œå› ä¸º check_amp() ä¼šé‡ç½®å®ƒä»¬
            self.amp = torch.tensor(check_amp(self.model), device=self.device)
            callbacks.default_callbacks = callbacks_backup  # æ¢å¤å›è°ƒå‡½æ•°
        if RANK > -1 and world_size > 1:  # DDP
            dist.broadcast(self.amp, src=0)  # ä» rank 0 å¹¿æ’­å¼ é‡åˆ°æ‰€æœ‰å…¶ä»– ranksï¼ˆè¿”å› Noneï¼‰
        self.amp = bool(self.amp)  # è½¬æ¢ä¸ºå¸ƒå°”å€¼
        self.scaler = (
            torch.amp.GradScaler("cuda", enabled=self.amp) if TORCH_2_4 else torch.cuda.amp.GradScaler(enabled=self.amp)
        )
        if world_size > 1:
            self.model = nn.parallel.DistributedDataParallel(self.model, device_ids=[RANK], find_unused_parameters=True)
            self.set_model_attributes()  # åœ¨ DDP å°è£…åå†æ¬¡è®¾ç½®æ¨¡å‹å±æ€§

        # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸
        gs = max(int(self.model.stride.max() if hasattr(self.model, "stride") else 32), 32)  # ç½‘æ ¼å¤§å°ï¼ˆæœ€å¤§æ­¥å¹…ï¼‰
        self.args.imgsz = check_imgsz(self.args.imgsz, stride=gs, floor=gs, max_dim=1)
        self.stride = gs  # ç”¨äºå¤šå°ºåº¦è®­ç»ƒ

        # æ‰¹é‡å¤§å°
        if self.batch_size < 1 and RANK == -1:  # ä»…å• GPUï¼Œä¼°ç®—æœ€ä½³æ‰¹é‡å¤§å°
            self.args.batch = self.batch_size = self.auto_batch()

        # æ•°æ®åŠ è½½å™¨
        batch_size = self.batch_size // max(world_size, 1)
        self.train_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=LOCAL_RANK, mode="train")
        if RANK in {-1, 0}:
            # æ³¨æ„ï¼šå½“è®­ç»ƒ DOTA æ•°æ®é›†æ—¶ï¼ŒåŒå€æ‰¹é‡å¤§å°å¯èƒ½ä¼šå¯¼è‡´è¶…è¿‡ 2000 ä¸ªç‰©ä½“çš„å›¾åƒå†…å­˜æº¢å‡ºï¼ˆOOMï¼‰ã€‚
            self.test_loader = self.get_dataloader(
                self.testset, batch_size=batch_size if self.args.task == "obb" else batch_size * 2, rank=-1, mode="val"
            )
            self.validator = self.get_validator()
            metric_keys = self.validator.metrics.keys + self.label_loss_items(prefix="val")
            self.metrics = dict(zip(metric_keys, [0] * len(metric_keys)))
            self.ema = ModelEMA(self.model)
            if self.args.plots:
                self.plot_training_labels()

        # ä¼˜åŒ–å™¨
        self.accumulate = max(round(self.args.nbs / self.batch_size), 1)  # åœ¨ä¼˜åŒ–å‰ç´¯ç§¯æŸå¤±
        weight_decay = self.args.weight_decay * self.batch_size * self.accumulate / self.args.nbs  # ç¼©æ”¾æƒé‡è¡°å‡
        iterations = math.ceil(len(self.train_loader.dataset) / max(self.batch_size, self.args.nbs)) * self.epochs
        self.optimizer = self.build_optimizer(
            model=self.model,
            name=self.args.optimizer,
            lr=self.args.lr0,
            momentum=self.args.momentum,
            decay=weight_decay,
            iterations=iterations,
        )
        # è°ƒåº¦å™¨
        self._setup_scheduler()
        self.stopper, self.stop = EarlyStopping(patience=self.args.patience), False
        self.resume_training(ckpt)
        self.scheduler.last_epoch = self.start_epoch - 1  # ä¸ç§»åŠ¨
        self.run_callbacks("on_pretrain_routine_end")

    def _do_train(self, world_size=1):
        """è®­ç»ƒå®Œæˆåï¼Œå¦‚æœæŒ‡å®šäº†å‚æ•°åˆ™è¿›è¡Œè¯„ä¼°å’Œç»˜å›¾ã€‚"""
        if world_size > 1:
            self._setup_ddp(world_size)
        self._setup_train(world_size)

        nb = len(self.train_loader)  # æ‰¹æ¬¡æ•°é‡
        nw = max(round(self.args.warmup_epochs * nb), 100) if self.args.warmup_epochs > 0 else -1  # é¢„çƒ­è¿­ä»£æ¬¡æ•°
        last_opt_step = -1
        self.epoch_time = None
        self.epoch_time_start = time.time()
        self.train_time_start = time.time()
        self.run_callbacks("on_train_start")
        LOGGER.info(
            f"å›¾åƒå°ºå¯¸ {self.args.imgsz} è®­ç»ƒ, {self.args.imgsz} éªŒè¯\n"
            f"ä½¿ç”¨ {self.train_loader.num_workers * (world_size or 1)} ä¸ªæ•°æ®åŠ è½½å™¨å·¥ä½œçº¿ç¨‹\n"
            f"æ—¥å¿—ç»“æœä¿å­˜è‡³ {colorstr('bold', self.save_dir)}\n"
            f"å¼€å§‹è®­ç»ƒ {f'{self.args.time} å°æ—¶...' if self.args.time else f'{self.epochs} è½®...'}"
        )
        if self.args.close_mosaic:
            base_idx = (self.epochs - self.args.close_mosaic) * nb
            self.plot_idx.extend([base_idx, base_idx + 1, base_idx + 2])
        epoch = self.start_epoch
        self.optimizer.zero_grad()  # æ¸…é™¤ä»»ä½•æ¢å¤çš„æ¢¯åº¦ï¼Œç¡®ä¿è®­ç»ƒå¼€å§‹æ—¶çš„ç¨³å®šæ€§
        while True:
            self.epoch = epoch
            self.run_callbacks("on_train_epoch_start")
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")  # æŠ‘åˆ¶ 'Detected lr_scheduler.step() before optimizer.step()'
                self.scheduler.step()

            self.model.train()
            if RANK != -1:
                self.train_loader.sampler.set_epoch(epoch)
            pbar = enumerate(self.train_loader)
            # æ›´æ–°æ•°æ®åŠ è½½å™¨å±æ€§ï¼ˆå¯é€‰ï¼‰
            if epoch == (self.epochs - self.args.close_mosaic):
                self._close_dataloader_mosaic()
                self.train_loader.reset()

            if RANK in {-1, 0}:
                LOGGER.info(self.progress_string())
                pbar = TQDM(enumerate(self.train_loader), total=nb)
            self.tloss = None
            for i, batch in pbar:
                self.run_callbacks("on_train_batch_start")
                # é¢„çƒ­
                ni = i + nb * epoch
                if ni <= nw:
                    xi = [0, nw]  # x æ’å€¼
                    self.accumulate = max(1, int(np.interp(ni, xi, [1, self.args.nbs / self.batch_size]).round()))
                    for j, x in enumerate(self.optimizer.param_groups):
                        # åç½®å­¦ä¹ ç‡ä» 0.1 ä¸‹é™åˆ° lr0ï¼Œå…¶ä»–æ‰€æœ‰å­¦ä¹ ç‡ä» 0.0 ä¸Šå‡åˆ° lr0
                        x["lr"] = np.interp(
                            ni, xi, [self.args.warmup_bias_lr if j == 0 else 0.0, x["initial_lr"] * self.lf(epoch)]
                        )
                        if "momentum" in x:
                            x["momentum"] = np.interp(ni, xi, [self.args.warmup_momentum, self.args.momentum])

                # å‘å‰ä¼ æ’­
                with autocast(self.amp):
                    batch = self.preprocess_batch(batch)
                    self.loss, self.loss_items = self.model(batch)
                    if RANK != -1:
                        self.loss *= world_size
                    self.tloss = (
                        (self.tloss * i + self.loss_items) / (i + 1) if self.tloss is not None else self.loss_items
                    )

                # åå‘ä¼ æ’­
                self.scaler.scale(self.loss).backward()

                # ä¼˜åŒ– - https://pytorch.org/docs/master/notes/amp_examples.html
                if ni - last_opt_step >= self.accumulate:
                    self.optimizer_step()
                    last_opt_step = ni

                    # å®šæ—¶åœæ­¢
                    if self.args.time:
                        self.stop = (time.time() - self.train_time_start) > (self.args.time * 3600)
                        if RANK != -1:  # å¦‚æœæ˜¯ DDP è®­ç»ƒ
                            broadcast_list = [self.stop if RANK == 0 else None]
                            dist.broadcast_object_list(broadcast_list, 0)  # å¹¿æ’­ 'stop' ç»™æ‰€æœ‰ ranks
                            self.stop = broadcast_list[0]
                        if self.stop:  # å¦‚æœè®­ç»ƒæ—¶é—´è¶…è¿‡
                            break

                # æ—¥å¿—
                if RANK in {-1, 0}:
                    loss_length = self.tloss.shape[0] if len(self.tloss.shape) else 1
                    pbar.set_description(
                        ("%11s" * 2 + "%11.4g" * (2 + loss_length))
                        % (
                            f"{epoch + 1}/{self.epochs}",
                            f"{self._get_memory():.3g}G",  # (GB) GPU å†…å­˜åˆ©ç”¨ç‡
                            *(self.tloss if loss_length > 1 else torch.unsqueeze(self.tloss, 0)),  # æŸå¤±
                            batch["cls"].shape[0],  # æ‰¹é‡å¤§å°ï¼Œä¾‹å¦‚ 8
                            batch["img"].shape[-1],  # å›¾åƒå°ºå¯¸ï¼Œä¾‹å¦‚ 640
                        )
                    )
                    self.run_callbacks("on_batch_end")
                    if self.args.plots and ni in self.plot_idx:
                        self.plot_training_samples(batch, ni)

                self.run_callbacks("on_train_batch_end")

            self.lr = {f"lr/pg{ir}": x["lr"] for ir, x in enumerate(self.optimizer.param_groups)}  # ä¾›æ—¥å¿—ä½¿ç”¨
            self.run_callbacks("on_train_epoch_end")
            if RANK in {-1, 0}:
                final_epoch = epoch + 1 >= self.epochs
                self.ema.update_attr(self.model, include=["yaml", "nc", "args", "names", "stride", "class_weights"])

                # éªŒè¯
                if self.args.val or final_epoch or self.stopper.possible_stop or self.stop:
                    self.metrics, self.fitness = self.validate()
                self.save_metrics(metrics={**self.label_loss_items(self.tloss), **self.metrics, **self.lr})
                self.stop |= self.stopper(epoch + 1, self.fitness) or final_epoch
                if self.args.time:
                    self.stop |= (time.time() - self.train_time_start) > (self.args.time * 3600)

                # ä¿å­˜æ¨¡å‹
                if self.args.save or final_epoch:
                    self.save_model()
                    self.run_callbacks("on_model_save")

            # è°ƒåº¦å™¨
            t = time.time()
            self.epoch_time = t - self.epoch_time_start
            self.epoch_time_start = t
            if self.args.time:
                mean_epoch_time = (t - self.train_time_start) / (epoch - self.start_epoch + 1)
                self.epochs = self.args.epochs = math.ceil(self.args.time * 3600 / mean_epoch_time)
                self._setup_scheduler()
                self.scheduler.last_epoch = self.epoch  # ä¸ç§»åŠ¨
                self.stop |= epoch >= self.epochs  # å¦‚æœè¶…è¿‡ epochsï¼Œåˆ™åœæ­¢
            self.run_callbacks("on_fit_epoch_end")
            self._clear_memory()

            # æå‰åœæ­¢
            if RANK != -1:  # å¦‚æœæ˜¯ DDP è®­ç»ƒ
                broadcast_list = [self.stop if RANK == 0 else None]
                dist.broadcast_object_list(broadcast_list, 0)  # å¹¿æ’­ 'stop' ç»™æ‰€æœ‰ ranks
                self.stop = broadcast_list[0]
            if self.stop:
                break  # å¿…é¡»ç»ˆæ­¢æ‰€æœ‰ DDP ranks
            epoch += 1

        if RANK in {-1, 0}:
            # ä½¿ç”¨ best.pt åšæœ€ç»ˆéªŒè¯
            seconds = time.time() - self.train_time_start
            LOGGER.info(f"\n{epoch - self.start_epoch + 1} è½®è®­ç»ƒå®Œæˆï¼Œå…±è€—æ—¶ {seconds / 3600:.3f} å°æ—¶ã€‚")
            self.final_eval()
            if self.args.plots:
                self.plot_metrics()
            self.run_callbacks("on_train_end")
        self._clear_memory()
        self.run_callbacks("teardown")

    def auto_batch(self, max_num_obj=0):
        """é€šè¿‡è®¡ç®—æ¨¡å‹çš„å†…å­˜å ç”¨æ¥è·å–æ‰¹é‡å¤§å°ã€‚"""
        return check_train_batch_size(
            model=self.model,
            imgsz=self.args.imgsz,
            amp=self.amp,
            batch=self.batch_size,
            max_num_obj=max_num_obj,
        )  # è¿”å›æ‰¹é‡å¤§å°

    def _get_memory(self):
        """è·å–åŠ é€Ÿå™¨çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆå•ä½ï¼šGBï¼‰ã€‚"""
        if self.device.type == "mps":
            memory = torch.mps.driver_allocated_memory()
        elif self.device.type == "cpu":
            memory = 0
        else:
            memory = torch.cuda.memory_reserved()
        return memory / 1e9

    def _clear_memory(self):
        """åœ¨ä¸åŒå¹³å°ä¸Šæ¸…ç†åŠ é€Ÿå™¨çš„å†…å­˜ã€‚"""
        gc.collect()
        if self.device.type == "mps":
            torch.mps.empty_cache()
        elif self.device.type == "cpu":
            return
        else:
            torch.cuda.empty_cache()

    def read_results_csv(self):
        """è¯»å– results.csv æ–‡ä»¶å¹¶è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä½¿ç”¨ pandasã€‚"""
        import pandas as pd  # ä½œç”¨åŸŸå†…å¯¼å…¥ä»¥æé«˜ 'import ultralytics' çš„é€Ÿåº¦

        return pd.read_csv(self.csv).to_dict(orient="list")

    def save_model(self):
        """ä¿å­˜æ¨¡å‹è®­ç»ƒçš„æ£€æŸ¥ç‚¹ä»¥åŠé™„åŠ çš„å…ƒæ•°æ®ã€‚"""
        import io

        # å°†æ£€æŸ¥ç‚¹åºåˆ—åŒ–ä¸ºå­—èŠ‚ç¼“å†²åŒºï¼ˆæ¯”é‡å¤è°ƒç”¨ torch.save() æ›´å¿«ï¼‰
        buffer = io.BytesIO()
        torch.save(
            {
                "epoch": self.epoch,
                "best_fitness": self.best_fitness,
                "model": None,  # æ¢å¤å’Œæœ€ç»ˆæ£€æŸ¥ç‚¹ä» EMA ä¸­æ´¾ç”Ÿ
                "ema": deepcopy(self.ema.ema).half(),
                "updates": self.ema.updates,
                "optimizer": convert_optimizer_state_dict_to_fp16(deepcopy(self.optimizer.state_dict())),
                "train_args": vars(self.args),  # ä»¥å­—å…¸å½¢å¼ä¿å­˜è®­ç»ƒå‚æ•°
                "train_metrics": {**self.metrics, **{"fitness": self.fitness}},
                "train_results": self.read_results_csv(),
                "date": datetime.now().isoformat(),
                "version": __version__,
                "license": "AGPL-3.0 (https://ultralytics.com/license)",
                "docs": "https://docs.ultralytics.com",
            },
            buffer,
        )
        serialized_ckpt = buffer.getvalue()  # è·å–åºåˆ—åŒ–åçš„å†…å®¹ä»¥ä¿å­˜

        # ä¿å­˜æ£€æŸ¥ç‚¹
        self.last.write_bytes(serialized_ckpt)  # ä¿å­˜ last.pt
        if self.best_fitness == self.fitness:
            self.best.write_bytes(serialized_ckpt)  # ä¿å­˜ best.pt
        if (self.save_period > 0) and (self.epoch % self.save_period == 0):
            (self.wdir / f"epoch{self.epoch}.pt").write_bytes(serialized_ckpt)  # ä¿å­˜ epochï¼Œä¾‹å¦‚ 'epoch3.pt'
        # å¦‚æœéœ€è¦å…³é—­é©¬èµ›å…‹å¹¶ä¸”å½“å‰ä¸ºè®­ç»ƒå€’æ•°ç¬¬ n ä¸ª epochï¼ˆæ³¨é‡Šæ‰çš„éƒ¨åˆ†ï¼‰
        # if self.args.close_mosaic and self.epoch == (self.epochs - self.args.close_mosaic - 1):
        #    (self.wdir / "last_mosaic.pt").write_bytes(serialized_ckpt)  # ä¿å­˜é©¬èµ›å…‹æ£€æŸ¥ç‚¹

    def get_dataset(self):
        """
        å¦‚æœæ•°æ®å­—å…¸å­˜åœ¨ï¼Œä»ä¸­è·å–è®­ç»ƒå’ŒéªŒè¯è·¯å¾„ã€‚

        å¦‚æœæ•°æ®æ ¼å¼æ— æ³•è¯†åˆ«ï¼Œåˆ™è¿”å› Noneã€‚
        """
        try:
            if self.args.task == "classify":
                data = check_cls_dataset(self.args.data)
            elif self.args.data.split(".")[-1] in {"yaml", "yml"} or self.args.task in {
                "detect",
                "segment",
                "pose",
                "obb",
            }:
                data = check_det_dataset(self.args.data)
                if "yaml_file" in data:
                    self.args.data = data["yaml_file"]  # ç”¨äºéªŒè¯ 'yolo train data=url.zip' çš„ç”¨æ³•
        except Exception as e:
            raise RuntimeError(emojis(f"æ•°æ®é›† '{clean_url(self.args.data)}' é”™è¯¯ âŒ {e}")) from e
        self.data = data
        return data["train"], data.get("val") or data.get("test")

    def setup_model(self):
        """åŠ è½½/åˆ›å»º/ä¸‹è½½é€‚ç”¨äºä»»ä½•ä»»åŠ¡çš„æ¨¡å‹ã€‚"""
        if isinstance(self.model, torch.nn.Module):  # å¦‚æœæ¨¡å‹å·²ç»åŠ è½½ï¼Œæ— éœ€å†æ¬¡è®¾ç½®
            return

        cfg, weights = self.model, None
        ckpt = None
        if str(self.model).endswith(".pt"):
            weights, ckpt = attempt_load_one_weight(self.model)
            cfg = weights.yaml
        elif isinstance(self.args.pretrained, (str, Path)):
            weights, _ = attempt_load_one_weight(self.args.pretrained)
        self.model = self.get_model(cfg=cfg, weights=weights, verbose=RANK == -1)  # è°ƒç”¨ Model(cfg, weights)
        return ckpt

    def optimizer_step(self):
        """æ‰§è¡Œè®­ç»ƒä¼˜åŒ–å™¨çš„å•æ­¥æ“ä½œï¼ŒåŒ…æ‹¬æ¢¯åº¦è£å‰ªå’Œ EMA æ›´æ–°ã€‚"""
        self.scaler.unscale_(self.optimizer)  # åç¼©æ”¾æ¢¯åº¦
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)  # æ¢¯åº¦è£å‰ª
        self.scaler.step(self.optimizer)
        self.scaler.update()
        self.optimizer.zero_grad()
        if self.ema:
            self.ema.update(self.model)

    def preprocess_batch(self, batch):
        """æ ¹æ®ä»»åŠ¡ç±»å‹å…è®¸è‡ªå®šä¹‰é¢„å¤„ç†æ¨¡å‹è¾“å…¥å’ŒçœŸå®æ ‡ç­¾ã€‚"""
        return batch

    def validate(self):
        """
        ä½¿ç”¨ self.validator åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡ŒéªŒè¯ã€‚

        è¿”å›çš„å­—å…¸é¢„è®¡åŒ…å« "fitness" é”®ã€‚
        """
        metrics = self.validator(self)
        fitness = metrics.pop("fitness", -self.loss.detach().cpu().numpy())  # å¦‚æœæœªæ‰¾åˆ° fitnessï¼Œåˆ™ä½¿ç”¨æŸå¤±ä½œä¸º fitness æµ‹é‡
        if not self.best_fitness or self.best_fitness < fitness:
            self.best_fitness = fitness
        return metrics, fitness

    def get_model(self, cfg=None, weights=None, verbose=True):
        """è·å–æ¨¡å‹ï¼Œå¹¶åœ¨åŠ è½½ cfg æ–‡ä»¶æ—¶å¼•å‘ NotImplementedErrorã€‚"""
        raise NotImplementedError("æ­¤ä»»åŠ¡çš„è®­ç»ƒå™¨ä¸æ”¯æŒåŠ è½½ cfg æ–‡ä»¶")

    def get_validator(self):
        """å½“è°ƒç”¨ get_validator å‡½æ•°æ—¶ï¼Œè¿”å› NotImplementedErrorã€‚"""
        raise NotImplementedError("è®­ç»ƒå™¨ä¸­æœªå®ç° get_validator å‡½æ•°")

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        """è¿”å›ç”±torch.data.Dataloaderæ´¾ç”Ÿçš„æ•°æ®åŠ è½½å™¨ã€‚"""
        raise NotImplementedError("get_dataloaderå‡½æ•°åœ¨è®­ç»ƒå™¨ä¸­å°šæœªå®ç°")

    def build_dataset(self, img_path, mode="train", batch=None):
        """æ„å»ºæ•°æ®é›†ã€‚"""
        raise NotImplementedError("build_datasetå‡½æ•°åœ¨è®­ç»ƒå™¨ä¸­å°šæœªå®ç°")

    def label_loss_items(self, loss_items=None, prefix="train"):
        """
        è¿”å›ä¸€ä¸ªå¸¦æœ‰æ ‡è®°çš„è®­ç»ƒæŸå¤±é¡¹å¼ é‡çš„æŸå¤±å­—å…¸ã€‚

        æ³¨æ„ï¼š
            å¯¹äºåˆ†ç±»ä»»åŠ¡ä¸éœ€è¦æ­¤åŠŸèƒ½ï¼Œä½†å¯¹äºåˆ†å‰²å’Œæ£€æµ‹ä»»åŠ¡æ˜¯å¿…è¦çš„ã€‚
        """
        return {"loss": loss_items} if loss_items is not None else ["loss"]

    def set_model_attributes(self):
        """åœ¨è®­ç»ƒå‰è®¾ç½®æˆ–æ›´æ–°æ¨¡å‹å‚æ•°ã€‚"""
        self.model.names = self.data["names"]

    def build_targets(self, preds, targets):
        """ä¸ºè®­ç»ƒ YOLO æ¨¡å‹æ„å»ºç›®æ ‡å¼ é‡ã€‚"""
        pass

    def progress_string(self):
        """è¿”å›æè¿°è®­ç»ƒè¿›åº¦çš„å­—ç¬¦ä¸²ã€‚"""
        return ""

    # TODO: å¯èƒ½éœ€è¦å°†ä»¥ä¸‹å‡½æ•°æ”¾å…¥å›è°ƒä¸­
    def plot_training_samples(self, batch, ni):
        """åœ¨ YOLO è®­ç»ƒè¿‡ç¨‹ä¸­ç»˜åˆ¶è®­ç»ƒæ ·æœ¬ã€‚"""
        pass

    def plot_training_labels(self):
        """ä¸º YOLO æ¨¡å‹ç»˜åˆ¶è®­ç»ƒæ ‡ç­¾ã€‚"""
        pass

    def save_metrics(self, metrics):
        """å°†è®­ç»ƒæŒ‡æ ‡ä¿å­˜åˆ° CSV æ–‡ä»¶ä¸­ã€‚"""
        keys, vals = list(metrics.keys()), list(metrics.values())
        n = len(metrics) + 2  # åˆ—çš„æ•°é‡
        s = "" if self.csv.exists() else (("%s," * n % tuple(["epoch", "time"] + keys)).rstrip(",") + "\n")  # è¡¨å¤´
        t = time.time() - self.train_time_start
        with open(self.csv, "a") as f:
            f.write(s + ("%.6g," * n % tuple([self.epoch + 1, t] + vals)).rstrip(",") + "\n")

    def plot_metrics(self):
        """ç»˜åˆ¶å¹¶å¯è§†åŒ–æ˜¾ç¤ºæŒ‡æ ‡ã€‚"""
        pass

    def on_plot(self, name, data=None):
        """æ³¨å†Œå›¾è¡¨ï¼ˆä¾‹å¦‚ï¼Œä»¥ä¾¿åœ¨å›è°ƒä¸­ä½¿ç”¨ï¼‰ã€‚"""
        path = Path(name)
        self.plots[path] = {"data": data, "timestamp": time.time()}

    def final_eval(self):
        """æ‰§è¡Œæœ€ç»ˆè¯„ä¼°å’ŒéªŒè¯ï¼Œé€‚ç”¨äºç›®æ ‡æ£€æµ‹ YOLO æ¨¡å‹ã€‚"""
        ckpt = {}
        for f in self.last, self.best:
            if f.exists():
                if f is self.last:
                    ckpt = strip_optimizer(f)
                elif f is self.best:
                    k = "train_results"  # ä» last.pt æ›´æ–° best.pt çš„ train_metrics
                    strip_optimizer(f, updates={k: ckpt[k]} if k in ckpt else None)
                    LOGGER.info(f"\næ­£åœ¨éªŒè¯ {f}...")
                    self.validator.args.plots = self.args.plots
                    self.metrics = self.validator(model=f)
                    self.metrics.pop("fitness", None)
                    self.run_callbacks("on_fit_epoch_end")

    def check_resume(self, overrides):
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ¢å¤çš„æ£€æŸ¥ç‚¹ï¼Œå¹¶æ ¹æ®éœ€è¦æ›´æ–°å‚æ•°ã€‚"""
        resume = self.args.resume
        if resume:
            try:
                exists = isinstance(resume, (str, Path)) and Path(resume).exists()
                last = Path(check_file(resume) if exists else get_latest_run())

                # æ£€æŸ¥æ¢å¤æ•°æ®çš„ YAML æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦åˆ™å¼ºåˆ¶é‡æ–°ä¸‹è½½æ•°æ®é›†
                ckpt_args = attempt_load_weights(last).args
                if not Path(ckpt_args["data"]).exists():
                    ckpt_args["data"] = self.args.data

                resume = True
                self.args = get_cfg(ckpt_args)
                self.args.model = self.args.resume = str(last)  # æ¢å¤æ¨¡å‹
                for k in (
                    "imgsz",
                    "batch",
                    "device",
                    "close_mosaic",
                ):  # å…è®¸å‚æ•°æ›´æ–°ä»¥å‡å°‘å†…å­˜æˆ–åœ¨æ¢å¤æ—¶æ›´æ–°è®¾å¤‡
                    if k in overrides:
                        setattr(self.args, k, overrides[k])

            except Exception as e:
                raise FileNotFoundError(
                    "æœªæ‰¾åˆ°æ¢å¤æ£€æŸ¥ç‚¹ã€‚è¯·ä¼ é€’ä¸€ä¸ªæœ‰æ•ˆçš„æ£€æŸ¥ç‚¹ä»¥æ¢å¤è®­ç»ƒï¼Œ"
                    "ä¾‹å¦‚ 'yolo train resume model=path/to/last.pt'"
                ) from e
        self.resume = resume

    def resume_training(self, ckpt):
        """ä»ç»™å®šçš„ epoch å’Œæœ€ä½³ fitness æ¢å¤ YOLO è®­ç»ƒã€‚"""
        if ckpt is None or not self.resume:
            return
        best_fitness = 0.0
        start_epoch = ckpt.get("epoch", -1) + 1
        if ckpt.get("optimizer", None) is not None:
            self.optimizer.load_state_dict(ckpt["optimizer"])  # æ¢å¤ä¼˜åŒ–å™¨
            best_fitness = ckpt["best_fitness"]
        if self.ema and ckpt.get("ema"):
            self.ema.ema.load_state_dict(ckpt["ema"].float().state_dict())  # æ¢å¤ EMA
            self.ema.updates = ckpt["updates"]
        assert start_epoch > 0, (
            f"{self.args.model} å·²è®­ç»ƒè‡³ {self.epochs} è½®ï¼Œæ— æ³•æ¢å¤è®­ç»ƒã€‚\n"
            f"è¯·å¼€å§‹æ–°çš„è®­ç»ƒè€Œä¸æ˜¯æ¢å¤ï¼Œç¤ºä¾‹ï¼š'yolo train model={self.args.model}'"
        )
        LOGGER.info(f"ä»ç¬¬ {start_epoch + 1} è½®æ¢å¤è®­ç»ƒ {self.args.model}ï¼Œç›´åˆ°æ€»è½®æ¬¡ {self.epochs}")
        if self.epochs < start_epoch:
            LOGGER.info(
                f"{self.model} å·²è®­ç»ƒ {ckpt['epoch']} è½®ã€‚ç»§ç»­å¾®è°ƒ {self.epochs} è½®ã€‚"
            )
            self.epochs += ckpt["epoch"]  # å¾®è°ƒé¢å¤–çš„è½®æ¬¡
        self.best_fitness = best_fitness
        self.start_epoch = start_epoch
        if start_epoch > (self.epochs - self.args.close_mosaic):
            self._close_dataloader_mosaic()

    def _close_dataloader_mosaic(self):
        """æ›´æ–°æ•°æ®åŠ è½½å™¨ä»¥åœæ­¢ä½¿ç”¨ Mosaic æ•°æ®å¢å¼ºã€‚"""
        if hasattr(self.train_loader.dataset, "mosaic"):
            self.train_loader.dataset.mosaic = False
        if hasattr(self.train_loader.dataset, "close_mosaic"):
            LOGGER.info("å…³é—­æ•°æ®åŠ è½½å™¨çš„ Mosaic")
            self.train_loader.dataset.close_mosaic(hyp=copy(self.args))

    def build_optimizer(self, model, name="auto", lr=0.001, momentum=0.9, decay=1e-5, iterations=1e5):
        """
        ä¸ºç»™å®šçš„æ¨¡å‹æ„å»ºä¸€ä¸ªä¼˜åŒ–å™¨ï¼ŒåŸºäºæŒ‡å®šçš„ä¼˜åŒ–å™¨åç§°ã€å­¦ä¹ ç‡ã€åŠ¨é‡ã€æƒé‡è¡°å‡å’Œè¿­ä»£æ¬¡æ•°ã€‚

        å‚æ•°:
            model (torch.nn.Module): è¦ä¸ºå…¶æ„å»ºä¼˜åŒ–å™¨çš„æ¨¡å‹ã€‚
            name (str, å¯é€‰): è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨åç§°ã€‚å¦‚æœæ˜¯ 'auto'ï¼Œåˆ™æ ¹æ®è¿­ä»£æ¬¡æ•°è‡ªåŠ¨é€‰æ‹©ä¼˜åŒ–å™¨ã€‚é»˜è®¤å€¼ï¼š'auto'ã€‚
            lr (float, å¯é€‰): ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡ã€‚é»˜è®¤å€¼ï¼š0.001ã€‚
            momentum (float, å¯é€‰): ä¼˜åŒ–å™¨çš„åŠ¨é‡å› å­ã€‚é»˜è®¤å€¼ï¼š0.9ã€‚
            decay (float, å¯é€‰): ä¼˜åŒ–å™¨çš„æƒé‡è¡°å‡ã€‚é»˜è®¤å€¼ï¼š1e-5ã€‚
            iterations (float, å¯é€‰): è¿­ä»£æ¬¡æ•°ï¼Œå†³å®šå¦‚æœä¼˜åŒ–å™¨åç§°ä¸º 'auto' æ—¶é€‰æ‹©å“ªç§ä¼˜åŒ–å™¨ã€‚é»˜è®¤å€¼ï¼š1e5ã€‚

        è¿”å›:
            (torch.optim.Optimizer): æ„å»ºçš„ä¼˜åŒ–å™¨ã€‚
        """
        g = [], [], []  # ä¼˜åŒ–å™¨å‚æ•°ç»„
        bn = tuple(v for k, v in nn.__dict__.items() if "Norm" in k)  # å½’ä¸€åŒ–å±‚ï¼Œä¾‹å¦‚ BatchNorm2d()
        if name == "auto":
            LOGGER.info(
                f"{colorstr('optimizer:')} 'optimizer=auto' è¢«æ£€æµ‹åˆ°ï¼Œ"
                f"å¿½ç•¥ 'lr0={self.args.lr0}' å’Œ 'momentum={self.args.momentum}'ï¼Œ"
                f"è‡ªåŠ¨é€‰æ‹©æœ€ä½³çš„ 'optimizer'ã€'lr0' å’Œ 'momentum'... "
            )
            nc = getattr(model, "nc", 10)  # ç±»åˆ«æ•°
            lr_fit = round(0.002 * 5 / (4 + nc), 6)  # lr0 é€‚é…å…¬å¼ï¼Œä¿ç•™ 6 ä½å°æ•°
            name, lr, momentum = ("SGD", 0.01, 0.9) if iterations > 10000 else ("AdamW", lr_fit, 0.9)
            self.args.warmup_bias_lr = 0.0  # å¯¹äº Adamï¼Œbias å­¦ä¹ ç‡ä¸è¶…è¿‡ 0.01

        for module_name, module in model.named_modules():
            for param_name, param in module.named_parameters(recurse=False):
                fullname = f"{module_name}.{param_name}" if module_name else param_name
                if "bias" in fullname:  # åç½®ï¼ˆä¸è¡°å‡ï¼‰
                    g[2].append(param)
                elif isinstance(module, bn):  # æƒé‡ï¼ˆä¸è¡°å‡ï¼‰
                    g[1].append(param)
                else:  # æƒé‡ï¼ˆè¡°å‡ï¼‰
                    g[0].append(param)

        optimizers = {"Adam", "Adamax", "AdamW", "NAdam", "RAdam", "RMSProp", "SGD", "auto"}
        name = {x.lower(): x for x in optimizers}.get(name.lower())
        if name in {"Adam", "Adamax", "AdamW", "NAdam", "RAdam"}:
            optimizer = getattr(optim, name, optim.Adam)(g[2], lr=lr, betas=(momentum, 0.999), weight_decay=0.0)
        elif name == "RMSProp":
            optimizer = optim.RMSprop(g[2], lr=lr, momentum=momentum)
        elif name == "SGD":
            optimizer = optim.SGD(g[2], lr=lr, momentum=momentum, nesterov=True)
        else:
            raise NotImplementedError(
                f"ä¼˜åŒ–å™¨ '{name}' æœªåœ¨å¯ç”¨ä¼˜åŒ–å™¨åˆ—è¡¨ {optimizers} ä¸­æ‰¾åˆ°ã€‚"
                "å¦‚éœ€æ”¯æŒæ›´å¤šä¼˜åŒ–å™¨ï¼Œè¯·è®¿é—® https://github.com/ultralytics/ultralytics æå‡ºè¯·æ±‚ã€‚"
            )

        optimizer.add_param_group({"params": g[0], "weight_decay": decay})  # æ·»åŠ  g0 å¹¶ä½¿ç”¨æƒé‡è¡°å‡
        optimizer.add_param_group({"params": g[1], "weight_decay": 0.0})  # æ·»åŠ  g1ï¼ˆBatchNorm2d æƒé‡ï¼‰
        LOGGER.info(
            f"{colorstr('optimizer:')} {type(optimizer).__name__}(lr={lr}, momentum={momentum}) å…·æœ‰å‚æ•°ç»„ "
            f"{len(g[1])} æƒé‡(è¡°å‡=0.0)ï¼Œ{len(g[0])} æƒé‡(è¡°å‡={decay})ï¼Œ{len(g[2])} åç½®(è¡°å‡=0.0)"
        )
        return optimizer
