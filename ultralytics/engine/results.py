# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
Ultralytics ç»“æœã€æ¡†å’Œæ©ç ç±»ï¼Œç”¨äºå¤„ç†æ¨ç†ç»“æœã€‚

ç”¨æ³•ï¼šè¯·å‚é˜… https://docs.ultralytics.com/modes/predict/
"""

from copy import deepcopy
from functools import lru_cache
from pathlib import Path

import numpy as np
import torch

from ultralytics.data.augment import LetterBox
from ultralytics.utils import LOGGER, SimpleClass, ops
from ultralytics.utils.checks import check_requirements
from ultralytics.utils.plotting import Annotator, colors, save_one_box
from ultralytics.utils.torch_utils import smart_inference_mode


class BaseTensor(SimpleClass):
    """
    åŸºç¡€å¼ é‡ç±»ï¼Œæä¾›é™„åŠ æ–¹æ³•ä»¥ä¾¿äºæ“ä½œå’Œè®¾å¤‡å¤„ç†ã€‚

    å±æ€§:
        data (torch.Tensor | np.ndarray): é¢„æµ‹æ•°æ®ï¼Œå¦‚è¾¹ç•Œæ¡†ã€æ©ç æˆ–å…³é”®ç‚¹ã€‚
        orig_shape (Tuple[int, int]): å›¾åƒçš„åŸå§‹å½¢çŠ¶ï¼Œé€šå¸¸ä¸º (é«˜åº¦, å®½åº¦) æ ¼å¼ã€‚

    æ–¹æ³•:
        cpu: è¿”å›å­˜å‚¨åœ¨CPUå†…å­˜ä¸­çš„å¼ é‡å‰¯æœ¬ã€‚
        numpy: å°†å¼ é‡è¿”å›ä¸ºnumpyæ•°ç»„å‰¯æœ¬ã€‚
        cuda: å°†å¼ é‡ç§»åŠ¨åˆ°GPUå†…å­˜ä¸­ï¼Œå¦‚æœéœ€è¦åˆ™è¿”å›æ–°çš„å®ä¾‹ã€‚
        to: è¿”å›å…·æœ‰æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹çš„å¼ é‡å‰¯æœ¬ã€‚

    ç¤ºä¾‹:
        >>> import torch
        >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
        >>> orig_shape = (720, 1280)
        >>> base_tensor = BaseTensor(data, orig_shape)
        >>> cpu_tensor = base_tensor.cpu()
        >>> numpy_array = base_tensor.numpy()
        >>> gpu_tensor = base_tensor.cuda()
    """

    def __init__(self, data, orig_shape) -> None:
        """
        ä½¿ç”¨é¢„æµ‹æ•°æ®å’Œå›¾åƒçš„åŸå§‹å½¢çŠ¶åˆå§‹åŒ–BaseTensorã€‚

        å‚æ•°:
            data (torch.Tensor | np.ndarray): é¢„æµ‹æ•°æ®ï¼Œå¦‚è¾¹ç•Œæ¡†ã€æ©ç æˆ–å…³é”®ç‚¹ã€‚
            orig_shape (Tuple[int, int]): å›¾åƒçš„åŸå§‹å½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚

        ç¤ºä¾‹:
            >>> import torch
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> orig_shape = (720, 1280)
            >>> base_tensor = BaseTensor(data, orig_shape)
        """
        assert isinstance(data, (torch.Tensor, np.ndarray)), "data å¿…é¡»æ˜¯ torch.Tensor æˆ– np.ndarray ç±»å‹"
        self.data = data
        self.orig_shape = orig_shape

    @property
    def shape(self):
        """
        è¿”å›åº•å±‚æ•°æ®å¼ é‡çš„å½¢çŠ¶ã€‚

        è¿”å›:
            (Tuple[int, ...]): æ•°æ®å¼ é‡çš„å½¢çŠ¶ã€‚

        ç¤ºä¾‹:
            >>> data = torch.rand(100, 4)
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> print(base_tensor.shape)
            (100, 4)
        """
        return self.data.shape

    def cpu(self):
        """
        è¿”å›å­˜å‚¨åœ¨CPUå†…å­˜ä¸­çš„å¼ é‡å‰¯æœ¬ã€‚

        è¿”å›:
            (BaseTensor): ä¸€ä¸ªæ–°çš„BaseTensorå¯¹è±¡ï¼Œå…¶ä¸­çš„æ•°æ®å¼ é‡è¢«ç§»åŠ¨åˆ°CPUå†…å­˜ä¸­ã€‚

        ç¤ºä¾‹:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]]).cuda()
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> cpu_tensor = base_tensor.cpu()
            >>> isinstance(cpu_tensor, BaseTensor)
            True
            >>> cpu_tensor.data.device
            device(type='cpu')
        """
        return self if isinstance(self.data, np.ndarray) else self.__class__(self.data.cpu(), self.orig_shape)

    def numpy(self):
        """
        è¿”å›å¼ é‡çš„numpyæ•°ç»„å‰¯æœ¬ã€‚

        è¿”å›:
            (np.ndarray): ä¸€ä¸ªåŒ…å«ä¸åŸå¼ é‡ç›¸åŒæ•°æ®çš„numpyæ•°ç»„ã€‚

        ç¤ºä¾‹:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> orig_shape = (720, 1280)
            >>> base_tensor = BaseTensor(data, orig_shape)
            >>> numpy_array = base_tensor.numpy()
            >>> print(type(numpy_array))
            <class 'numpy.ndarray'>
        """
        return self if isinstance(self.data, np.ndarray) else self.__class__(self.data.numpy(), self.orig_shape)

    def cuda(self):
        """
        å°†å¼ é‡ç§»åŠ¨åˆ°GPUå†…å­˜ä¸­ã€‚

        è¿”å›:
            (BaseTensor): ä¸€ä¸ªæ–°çš„BaseTensorå®ä¾‹ï¼Œå…¶ä¸­çš„æ•°æ®è¢«ç§»åŠ¨åˆ°GPUå†…å­˜ä¸­ï¼Œå¦‚æœæ•°æ®å·²ç»æ˜¯numpyæ•°ç»„ï¼Œåˆ™è¿”å›è‡ªèº«ã€‚

        ç¤ºä¾‹:
            >>> import torch
            >>> from ultralytics.engine.results import BaseTensor
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> gpu_tensor = base_tensor.cuda()
            >>> print(gpu_tensor.data.device)
            cuda:0
        """
        return self.__class__(torch.as_tensor(self.data).cuda(), self.orig_shape)

    def to(self, *args, **kwargs):
        """
        è¿”å›å…·æœ‰æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹çš„å¼ é‡å‰¯æœ¬ã€‚

        å‚æ•°:
            *args (Any): ä¼ é€’ç»™ torch.Tensor.to() çš„å¯å˜é•¿åº¦å‚æ•°ã€‚
            **kwargs (Any): ä¼ é€’ç»™ torch.Tensor.to() çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        è¿”å›:
            (BaseTensor): ä¸€ä¸ªæ–°çš„BaseTensorå®ä¾‹ï¼Œæ•°æ®è¢«ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡å’Œ/æˆ–æ•°æ®ç±»å‹ã€‚

        ç¤ºä¾‹:
            >>> base_tensor = BaseTensor(torch.randn(3, 4), orig_shape=(480, 640))
            >>> cuda_tensor = base_tensor.to("cuda")
            >>> float16_tensor = base_tensor.to(dtype=torch.float16)
        """
        return self.__class__(torch.as_tensor(self.data).to(*args, **kwargs), self.orig_shape)

    def __len__(self):  # é‡å†™len(results)
        """
        è¿”å›åº•å±‚æ•°æ®å¼ é‡çš„é•¿åº¦ã€‚

        è¿”å›:
            (int): æ•°æ®å¼ é‡åœ¨ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šçš„å…ƒç´ æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> len(base_tensor)
            2
        """
        return len(self.data)

    def __getitem__(self, idx):
        """
        è¿”å›åŒ…å«æŒ‡å®šç´¢å¼•å…ƒç´ çš„æ–°BaseTensorå®ä¾‹ã€‚

        å‚æ•°:
            idx (int | List[int] | torch.Tensor): ç”¨äºé€‰æ‹©æ•°æ®å¼ é‡ä¸­çš„å…ƒç´ çš„ç´¢å¼•æˆ–ç´¢å¼•åˆ—è¡¨ã€‚

        è¿”å›:
            (BaseTensor): ä¸€ä¸ªæ–°çš„BaseTensorå®ä¾‹ï¼ŒåŒ…å«ç´¢å¼•åçš„æ•°æ®ã€‚

        ç¤ºä¾‹:
            >>> data = torch.tensor([[1, 2, 3], [4, 5, 6]])
            >>> base_tensor = BaseTensor(data, orig_shape=(720, 1280))
            >>> result = base_tensor[0]  # é€‰æ‹©ç¬¬ä¸€è¡Œ
            >>> print(result.data)
            tensor([1, 2, 3])
        """
        return self.__class__(self.data[idx], self.orig_shape)


class Results(SimpleClass):
    """
    ç”¨äºå­˜å‚¨å’Œæ“ä½œæ¨ç†ç»“æœçš„ç±»ã€‚

    è¯¥ç±»å°è£…äº†å¤„ç† YOLO æ¨¡å‹çš„æ£€æµ‹ã€åˆ†å‰²ã€å§¿æ€ä¼°è®¡å’Œåˆ†ç±»ç»“æœçš„åŠŸèƒ½ã€‚

    å±æ€§:
        orig_img (numpy.ndarray): ä½œä¸º numpy æ•°ç»„çš„åŸå§‹å›¾åƒã€‚
        orig_shape (Tuple[int, int]): å›¾åƒçš„åŸå§‹å½¢çŠ¶ï¼Œä»¥ (é«˜åº¦, å®½åº¦) æ ¼å¼è¡¨ç¤ºã€‚
        boxes (Boxes | None): åŒ…å«æ£€æµ‹è¾¹ç•Œæ¡†çš„å¯¹è±¡ã€‚
        masks (Masks | None): åŒ…å«æ£€æµ‹æ©æ¨¡çš„å¯¹è±¡ã€‚
        probs (Probs | None): åŒ…å«åˆ†ç±»ä»»åŠ¡ä¸­æ¯ä¸ªç±»çš„æ¦‚ç‡çš„å¯¹è±¡ã€‚
        keypoints (Keypoints | None): åŒ…å«æ¯ä¸ªå¯¹è±¡æ£€æµ‹åˆ°çš„å…³é”®ç‚¹çš„å¯¹è±¡ã€‚
        obb (OBB | None): åŒ…å«é¢å‘ç›®æ ‡çš„è¾¹ç•Œæ¡†çš„å¯¹è±¡ã€‚
        speed (Dict[str, float | None]): åŒ…å«é¢„å¤„ç†ã€æ¨ç†å’Œåå¤„ç†é€Ÿåº¦çš„å­—å…¸ã€‚
        names (Dict[int, str]): ç±» ID ä¸ç±»åçš„æ˜ å°„å­—å…¸ã€‚
        path (str): å›¾åƒæ–‡ä»¶çš„è·¯å¾„ã€‚
        _keys (Tuple[str, ...]): å†…éƒ¨ä½¿ç”¨çš„å±æ€§åç§°å…ƒç»„ã€‚

    æ–¹æ³•:
        update: ä½¿ç”¨æ–°çš„æ£€æµ‹ç»“æœæ›´æ–°å¯¹è±¡å±æ€§ã€‚
        cpu: è¿”å›ä¸€ä¸ªå‰¯æœ¬ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡éƒ½å­˜å‚¨åœ¨ CPU å†…å­˜ä¸­ã€‚
        numpy: è¿”å›ä¸€ä¸ªå‰¯æœ¬ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡éƒ½è½¬æ¢ä¸º numpy æ•°ç»„ã€‚
        cuda: è¿”å›ä¸€ä¸ªå‰¯æœ¬ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡éƒ½å­˜å‚¨åœ¨ GPU å†…å­˜ä¸­ã€‚
        to: è¿”å›ä¸€ä¸ªå‰¯æœ¬ï¼Œå…¶ä¸­å¼ é‡å­˜å‚¨åœ¨æŒ‡å®šçš„è®¾å¤‡å’Œæ•°æ®ç±»å‹ä¸­ã€‚
        new: è¿”å›ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…·æœ‰ç›¸åŒçš„å›¾åƒã€è·¯å¾„å’Œåç§°ã€‚
        plot: åœ¨è¾“å…¥å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœï¼Œå¹¶è¿”å›å¸¦æ³¨é‡Šçš„å›¾åƒã€‚
        show: åœ¨å±å¹•ä¸Šæ˜¾ç¤ºå¸¦æ³¨é‡Šçš„ç»“æœã€‚
        save: å°†å¸¦æ³¨é‡Šçš„ç»“æœä¿å­˜åˆ°æ–‡ä»¶ã€‚
        verbose: è¿”å›æ¯ä¸ªä»»åŠ¡çš„æ—¥å¿—å­—ç¬¦ä¸²ï¼Œè¯¦ç»†æè¿°æ£€æµ‹å’Œåˆ†ç±»ç»“æœã€‚
        save_txt: å°†æ£€æµ‹ç»“æœä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ã€‚
        save_crop: ä¿å­˜è£å‰ªåçš„æ£€æµ‹å›¾åƒã€‚
        tojson: å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸º JSON æ ¼å¼ã€‚

    ç¤ºä¾‹:
        >>> results = model("path/to/image.jpg")
        >>> for result in results:
        ...     print(result.boxes)  # æ‰“å°æ£€æµ‹æ¡†
        ...     result.show()  # æ˜¾ç¤ºå¸¦æ³¨é‡Šçš„å›¾åƒ
        ...     result.save(filename="result.jpg")  # ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾åƒ
    """

    def __init__(
        self, orig_img, path, names, boxes=None, masks=None, probs=None, keypoints=None, obb=None, speed=None
    ) -> None:
        """
        åˆå§‹åŒ– Results ç±»ï¼Œç”¨äºå­˜å‚¨å’Œæ“ä½œæ¨ç†ç»“æœã€‚

        å‚æ•°:
            orig_img (numpy.ndarray): ä½œä¸º numpy æ•°ç»„çš„åŸå§‹å›¾åƒã€‚
            path (str): å›¾åƒæ–‡ä»¶çš„è·¯å¾„ã€‚
            names (Dict): ç±»åå­—å…¸ã€‚
            boxes (torch.Tensor | None): åŒ…å«æ¯ä¸ªæ£€æµ‹çš„è¾¹ç•Œæ¡†åæ ‡çš„äºŒç»´å¼ é‡ã€‚
            masks (torch.Tensor | None): åŒ…å«æ£€æµ‹æ©æ¨¡çš„ä¸‰ç»´å¼ é‡ï¼Œæ¯ä¸ªæ©æ¨¡æ˜¯ä¸€ä¸ªäºŒå€¼å›¾åƒã€‚
            probs (torch.Tensor | None): åŒ…å«æ¯ä¸ªç±»çš„æ¦‚ç‡çš„å¼ é‡ï¼Œç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚
            keypoints (torch.Tensor | None): åŒ…å«æ¯ä¸ªæ£€æµ‹çš„å…³é”®ç‚¹åæ ‡çš„äºŒç»´å¼ é‡ã€‚
            obb (torch.Tensor | None): åŒ…å«æ¯ä¸ªæ£€æµ‹çš„é¢å‘ç›®æ ‡çš„è¾¹ç•Œæ¡†åæ ‡çš„äºŒç»´å¼ é‡ã€‚
            speed (Dict | None): åŒ…å«é¢„å¤„ç†ã€æ¨ç†å’Œåå¤„ç†é€Ÿåº¦ï¼ˆms/å›¾åƒï¼‰çš„å­—å…¸ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> result = results[0]  # è·å–ç¬¬ä¸€ä¸ªç»“æœ
            >>> boxes = result.boxes  # è·å–ç¬¬ä¸€ä¸ªç»“æœçš„è¾¹ç•Œæ¡†
            >>> masks = result.masks  # è·å–ç¬¬ä¸€ä¸ªç»“æœçš„æ©æ¨¡

        æ³¨æ„:
            å¯¹äºé»˜è®¤çš„å§¿æ€æ¨¡å‹ï¼Œäººä½“å§¿æ€ä¼°è®¡çš„å…³é”®ç‚¹ç´¢å¼•ä¸ºï¼š
            0: é¼»å­, 1: å·¦çœ¼, 2: å³çœ¼, 3: å·¦è€³, 4: å³è€³
            5: å·¦è‚©, 6: å³è‚©, 7: å·¦è‚˜, 8: å³è‚˜
            9: å·¦è…•, 10: å³è…•, 11: å·¦è‡€, 12: å³è‡€
            13: å·¦è†, 14: å³è†, 15: å·¦è¸, 16: å³è¸
        """
        self.orig_img = orig_img
        self.orig_shape = orig_img.shape[:2]
        self.boxes = Boxes(boxes, self.orig_shape) if boxes is not None else None  # åŸå§‹å¤§å°çš„è¾¹ç•Œæ¡†
        self.masks = Masks(masks, self.orig_shape) if masks is not None else None  # åŸå§‹å¤§å°æˆ–å›¾åƒå¤§å°çš„æ©æ¨¡
        self.probs = Probs(probs) if probs is not None else None
        self.keypoints = Keypoints(keypoints, self.orig_shape) if keypoints is not None else None
        self.obb = OBB(obb, self.orig_shape) if obb is not None else None
        self.speed = speed if speed is not None else {"preprocess": None, "inference": None, "postprocess": None}
        self.names = names
        self.path = path
        self.save_dir = None
        self._keys = "boxes", "masks", "probs", "keypoints", "obb"

    def __getitem__(self, idx):
        """
        è¿”å›æ¨ç†ç»“æœä¸­ç‰¹å®šç´¢å¼•çš„ Results å¯¹è±¡ã€‚

        å‚æ•°:
            idx (int | slice): ç´¢å¼•æˆ–åˆ‡ç‰‡ï¼Œç”¨äºä» Results å¯¹è±¡ä¸­æ£€ç´¢ã€‚

        è¿”å›:
            (Results): ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼ŒåŒ…å«æ¨ç†ç»“æœçš„æŒ‡å®šå­é›†ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")  # æ‰§è¡Œæ¨ç†
            >>> single_result = results[0]  # è·å–ç¬¬ä¸€ä¸ªç»“æœ
            >>> subset_results = results[1:4]  # è·å–ä¸€ä¸ªç»“æœçš„åˆ‡ç‰‡
        """
        return self._apply("__getitem__", idx)

    def __len__(self):
        """
        è¿”å› Results å¯¹è±¡ä¸­çš„æ£€æµ‹æ•°é‡ã€‚

        è¿”å›:
            (int): æ£€æµ‹çš„æ•°é‡ï¼Œå–å†³äºç¬¬ä¸€ä¸ªéç©ºå±æ€§ï¼ˆboxesã€masksã€probsã€keypoints æˆ– obbï¼‰çš„é•¿åº¦ã€‚

        ç¤ºä¾‹:
            >>> results = Results(orig_img, path, names, boxes=torch.rand(5, 4))
            >>> len(results)
            5
        """
        for k in self._keys:
            v = getattr(self, k)
            if v is not None:
                return len(v)

    def update(self, boxes=None, masks=None, probs=None, obb=None):
        """
        ä½¿ç”¨æ–°çš„æ£€æµ‹æ•°æ®æ›´æ–° Results å¯¹è±¡ã€‚

        è¯¥æ–¹æ³•å…è®¸æ›´æ–° Results å¯¹è±¡çš„è¾¹ç•Œæ¡†ã€æ©æ¨¡ã€æ¦‚ç‡å’Œé¢å‘ç›®æ ‡çš„è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰ã€‚å®ƒç¡®ä¿è¾¹ç•Œæ¡†è¢«è£å‰ªåˆ°åŸå§‹å›¾åƒå½¢çŠ¶ã€‚

        å‚æ•°:
            boxes (torch.Tensor | None): å½¢çŠ¶ä¸º (N, 6) çš„å¼ é‡ï¼ŒåŒ…å«è¾¹ç•Œæ¡†åæ ‡å’Œç½®ä¿¡åº¦ã€‚æ ¼å¼ä¸º (x1, y1, x2, y2, conf, class)ã€‚
            masks (torch.Tensor | None): å½¢çŠ¶ä¸º (N, H, W) çš„å¼ é‡ï¼ŒåŒ…å«åˆ†å‰²æ©æ¨¡ã€‚
            probs (torch.Tensor | None): å½¢çŠ¶ä¸º (num_classes,) çš„å¼ é‡ï¼ŒåŒ…å«æ¯ä¸ªç±»çš„æ¦‚ç‡ã€‚
            obb (torch.Tensor | None): å½¢çŠ¶ä¸º (N, 5) çš„å¼ é‡ï¼ŒåŒ…å«é¢å‘ç›®æ ‡çš„è¾¹ç•Œæ¡†åæ ‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> new_boxes = torch.tensor([[100, 100, 200, 200, 0.9, 0]])
            >>> results[0].update(boxes=new_boxes)
        """
        if boxes is not None:
            self.boxes = Boxes(ops.clip_boxes(boxes, self.orig_shape), self.orig_shape)
        if masks is not None:
            self.masks = Masks(masks, self.orig_shape)
        if probs is not None:
            self.probs = probs
        if obb is not None:
            self.obb = OBB(obb, self.orig_shape)

    def _apply(self, fn, *args, **kwargs):
        """
        å°†å‡½æ•°åº”ç”¨äºæ‰€æœ‰éç©ºå±æ€§ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«ä¿®æ”¹åçš„å±æ€§ã€‚

        è¯¥æ–¹æ³•é€šå¸¸ç”± .to()ã€.cuda()ã€.cpu() ç­‰æ–¹æ³•å†…éƒ¨è°ƒç”¨ã€‚

        å‚æ•°:
            fn (str): è¦åº”ç”¨çš„å‡½æ•°çš„åç§°ã€‚
            *args (Any): è¦ä¼ é€’ç»™å‡½æ•°çš„å¯å˜é•¿åº¦å‚æ•°ã€‚
            **kwargs (Any): è¦ä¼ é€’ç»™å‡½æ•°çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        è¿”å›:
            (Results): ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«è¢«åº”ç”¨å‡½æ•°ä¿®æ”¹è¿‡çš„å±æ€§ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     result_cuda = result.cuda()
            ...     result_cpu = result.cpu()
        """
        r = self.new()
        for k in self._keys:
            v = getattr(self, k)
            if v is not None:
                setattr(r, k, getattr(v, fn)(*args, **kwargs))
        return r

    def cpu(self):
        """
        è¿”å›ä¸€ä¸ªå‰¯æœ¬ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡éƒ½è¢«ç§»åŠ¨åˆ° CPU å†…å­˜ä¸­ã€‚

        è¯¥æ–¹æ³•åˆ›å»ºä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡å±æ€§ï¼ˆè¾¹ç•Œæ¡†ã€æ©æ¨¡ã€æ¦‚ç‡ã€å…³é”®ç‚¹ã€é¢å‘ç›®æ ‡çš„è¾¹ç•Œæ¡†ï¼‰éƒ½è¢«ç§»åŠ¨åˆ° CPU å†…å­˜ä¸­ã€‚
        å®ƒå¯¹äºå°†æ•°æ®ä» GPU è½¬ç§»åˆ° CPU è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†æˆ–ä¿å­˜éå¸¸æœ‰ç”¨ã€‚

        è¿”å›:
            (Results): ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡å±æ€§éƒ½åœ¨ CPU å†…å­˜ä¸­ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")  # æ‰§è¡Œæ¨ç†
            >>> cpu_result = results[0].cpu()  # å°†ç¬¬ä¸€ä¸ªç»“æœç§»åˆ° CPU
            >>> print(cpu_result.boxes.device)  # è¾“å‡º: cpu
        """
        return self._apply("cpu")

    def numpy(self):
        """
        å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡è½¬æ¢ä¸º numpy æ•°ç»„ã€‚

        è¿”å›:
            (Results): ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡éƒ½è¢«è½¬æ¢ä¸º numpy æ•°ç»„ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> numpy_result = results[0].numpy()
            >>> type(numpy_result.boxes.data)
            <class 'numpy.ndarray'>

        æ³¨æ„:
            è¯¥æ–¹æ³•åˆ›å»ºä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼ŒåŸå§‹å¯¹è±¡ä¿æŒä¸å˜ã€‚å®ƒå¯¹äºä¸åŸºäº numpy çš„åº“è¿›è¡Œäº¤äº’ï¼Œæˆ–è€…å½“éœ€è¦ CPU ä¸Šçš„æ“ä½œæ—¶éå¸¸æœ‰ç”¨ã€‚
        """
        return self._apply("numpy")

    def cuda(self):
        """
        å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡ç§»åŠ¨åˆ° GPU å†…å­˜ä¸­ã€‚

        è¿”å›:
            (Results): ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡éƒ½è¢«ç§»åŠ¨åˆ° CUDA è®¾å¤‡ä¸Šã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> cuda_results = results[0].cuda()  # å°†ç¬¬ä¸€ä¸ªç»“æœç§»åˆ° GPU
            >>> for result in results:
            ...     result_cuda = result.cuda()  # å°†æ¯ä¸ªç»“æœç§»åˆ° GPU
        """
        return self._apply("cuda")

    def to(self, *args, **kwargs):
        """
        å°† Results å¯¹è±¡ä¸­çš„æ‰€æœ‰å¼ é‡ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡å’Œæ•°æ®ç±»å‹ä¸­ã€‚

        å‚æ•°:
            *args (Any): è¦ä¼ é€’ç»™ torch.Tensor.to() çš„å¯å˜é•¿åº¦å‚æ•°ã€‚
            **kwargs (Any): è¦ä¼ é€’ç»™ torch.Tensor.to() çš„ä»»æ„å…³é”®å­—å‚æ•°ã€‚

        è¿”å›:
            (Results): ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…¶ä¸­æ‰€æœ‰å¼ é‡éƒ½è¢«ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡å’Œæ•°æ®ç±»å‹ä¸­ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> result_cuda = results[0].to("cuda")  # å°†ç¬¬ä¸€ä¸ªç»“æœç§»åˆ° GPU
            >>> result_cpu = results[0].to("cpu")  # å°†ç¬¬ä¸€ä¸ªç»“æœç§»åˆ° CPU
            >>> result_half = results[0].to(dtype=torch.float16)  # å°†ç¬¬ä¸€ä¸ªç»“æœè½¬æ¢ä¸ºåŠç²¾åº¦
        """
        return self._apply("to", *args, **kwargs)

    def new(self):
        """
        åˆ›å»ºä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå…·æœ‰ç›¸åŒçš„å›¾åƒã€è·¯å¾„ã€åç§°å’Œé€Ÿåº¦å±æ€§ã€‚

        è¿”å›:
            (Results): ä¸€ä¸ªæ–°çš„ Results å¯¹è±¡ï¼Œå¤åˆ¶äº†åŸå§‹å®ä¾‹çš„å±æ€§ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> new_result = results[0].new()
        """
        return Results(orig_img=self.orig_img, path=self.path, names=self.names, speed=self.speed)

    def plot(
        self,
        conf=True,
        line_width=None,
        font_size=None,
        font="Arial.ttf",
        pil=False,
        img=None,
        im_gpu=None,
        kpt_radius=5,
        kpt_line=True,
        labels=True,
        boxes=True,
        masks=True,
        probs=True,
        show=False,
        save=False,
        filename=None,
        color_mode="class",
    ):
        """
        åœ¨è¾“å…¥çš„ RGB å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœã€‚

        å‚æ•°:
            conf (bool): æ˜¯å¦ç»˜åˆ¶æ£€æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
            line_width (float | None): è¾¹ç•Œæ¡†çš„çº¿å®½ã€‚å¦‚æœä¸º Noneï¼Œåˆ™æ ¹æ®å›¾åƒå¤§å°è¿›è¡Œç¼©æ”¾ã€‚
            font_size (float | None): æ–‡æœ¬çš„å­—ä½“å¤§å°ã€‚å¦‚æœä¸º Noneï¼Œåˆ™æ ¹æ®å›¾åƒå¤§å°è¿›è¡Œç¼©æ”¾ã€‚
            font (str): ç”¨äºæ–‡æœ¬çš„å­—ä½“ã€‚
            pil (bool): æ˜¯å¦è¿”å› PIL å›¾åƒã€‚
            img (np.ndarray | None): è¦ç»˜åˆ¶çš„å›¾åƒã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨åŸå§‹å›¾åƒã€‚
            im_gpu (torch.Tensor | None): GPU ä¸Šçš„å½’ä¸€åŒ–å›¾åƒï¼Œç”¨äºæ›´å¿«é€Ÿåœ°ç»˜åˆ¶æ©æ¨¡ã€‚
            kpt_radius (int): ç»˜åˆ¶çš„å…³é”®ç‚¹åŠå¾„ã€‚
            kpt_line (bool): æ˜¯å¦ç»˜åˆ¶è¿æ¥å…³é”®ç‚¹çš„çº¿ã€‚
            labels (bool): æ˜¯å¦ç»˜åˆ¶è¾¹ç•Œæ¡†çš„æ ‡ç­¾ã€‚
            boxes (bool): æ˜¯å¦ç»˜åˆ¶è¾¹ç•Œæ¡†ã€‚
            masks (bool): æ˜¯å¦ç»˜åˆ¶æ©æ¨¡ã€‚
            probs (bool): æ˜¯å¦ç»˜åˆ¶åˆ†ç±»æ¦‚ç‡ã€‚
            show (bool): æ˜¯å¦æ˜¾ç¤ºå¸¦æ³¨é‡Šçš„å›¾åƒã€‚
            save (bool): æ˜¯å¦ä¿å­˜å¸¦æ³¨é‡Šçš„å›¾åƒã€‚
            filename (str | None): ä¿å­˜å›¾åƒçš„æ–‡ä»¶åï¼Œå¦‚æœ save ä¸º Trueã€‚
            color_mode (bool): æŒ‡å®šé¢œè‰²æ¨¡å¼ï¼Œä¾‹å¦‚ 'instance' æˆ– 'class'ã€‚é»˜è®¤ä¸º 'class'ã€‚

        è¿”å›:
            (np.ndarray): å¸¦æ³¨é‡Šçš„å›¾åƒä½œä¸º numpy æ•°ç»„ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> for result in results:
            ...     im = result.plot()
            ...     im.show()
        """
        assert color_mode in {"instance", "class"}, f"Expected color_mode='instance' or 'class', not {color_mode}."
        if img is None and isinstance(self.orig_img, torch.Tensor):
            img = (self.orig_img[0].detach().permute(1, 2, 0).contiguous() * 255).to(torch.uint8).cpu().numpy()

        names = self.names
        is_obb = self.obb is not None
        pred_boxes, show_boxes = self.obb if is_obb else self.boxes, boxes
        pred_masks, show_masks = self.masks, masks
        pred_probs, show_probs = self.probs, probs
        annotator = Annotator(
            deepcopy(self.orig_img if img is None else img),
            line_width,
            font_size,
            font,
            pil or (pred_probs is not None and show_probs),  # åˆ†ç±»ä»»åŠ¡é»˜è®¤ä½¿ç”¨ pil=True
            example=names,
        )

        # ç»˜åˆ¶åˆ†å‰²ç»“æœ
        if pred_masks and show_masks:
            if im_gpu is None:
                img = LetterBox(pred_masks.shape[1:])(image=annotator.result())
                im_gpu = (
                    torch.as_tensor(img, dtype=torch.float16, device=pred_masks.data.device)
                    .permute(2, 0, 1)
                    .flip(0)
                    .contiguous()
                    / 255
                )
            idx = (
                pred_boxes.id
                if pred_boxes.id is not None and color_mode == "instance"
                else pred_boxes.cls
                if pred_boxes and color_mode == "class"
                else reversed(range(len(pred_masks)))
            )
            annotator.masks(pred_masks.data, colors=[colors(x, True) for x in idx], im_gpu=im_gpu)

        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        if pred_boxes is not None and show_boxes:
            for i, d in enumerate(reversed(pred_boxes)):
                c, d_conf, id = int(d.cls), float(d.conf) if conf else None, None if d.id is None else int(d.id.item())
                name = ("" if id is None else f"id:{id} ") + names[c]
                label = (f"{name} {d_conf:.2f}" if conf else name) if labels else None
                box = d.xyxyxyxy.reshape(-1, 4, 2).squeeze() if is_obb else d.xyxy.squeeze()
                annotator.box_label(
                    box,
                    label,
                    color=colors(
                        c
                        if color_mode == "class"
                        else id
                        if id is not None
                        else i
                        if color_mode == "instance"
                        else None,
                        True,
                    ),
                    rotated=is_obb,
                )

        # ç»˜åˆ¶åˆ†ç±»ç»“æœ
        if pred_probs is not None and show_probs:
            text = ",\n".join(f"{names[j] if names else j} {pred_probs.data[j]:.2f}" for j in pred_probs.top5)
            x = round(self.orig_shape[0] * 0.03)
            annotator.text([x, x], text, txt_color=(255, 255, 255))  # TODO: å…è®¸è®¾ç½®é¢œè‰²

        # ç»˜åˆ¶å§¿æ€ç»“æœ
        if self.keypoints is not None:
            for i, k in enumerate(reversed(self.keypoints.data)):
                annotator.kpts(
                    k,
                    self.orig_shape,
                    radius=kpt_radius,
                    kpt_line=kpt_line,
                    kpt_color=colors(i, True) if color_mode == "instance" else None,
                )

        # æ˜¾ç¤ºç»“æœ
        if show:
            annotator.show(self.path)

        # ä¿å­˜ç»“æœ
        if save:
            annotator.save(filename)

        return annotator.result()

    def show(self, *args, **kwargs):
        """
        æ˜¾ç¤ºå¸¦æ³¨é‡Šçš„æ¨ç†ç»“æœå›¾åƒã€‚

        è¯¥æ–¹æ³•åœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå¹¶æ˜¾ç¤ºå®ƒã€‚å®ƒæ˜¯ç›´æ¥å¯è§†åŒ–æ¨¡å‹é¢„æµ‹çš„æ–¹ä¾¿æ–¹æ³•ã€‚

        å‚æ•°:
            *args (Any): å¯å˜é•¿åº¦çš„å‚æ•°åˆ—è¡¨ï¼Œå°†ä¼ é€’ç»™ `plot()` æ–¹æ³•ã€‚
            **kwargs (Any): å¯å˜å…³é”®å­—å‚æ•°ï¼Œå°†ä¼ é€’ç»™ `plot()` æ–¹æ³•ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> results[0].show()  # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æœ
            >>> for result in results:
            ...     result.show()  # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
        """
        self.plot(show=True, *args, **kwargs)

    def save(self, filename=None, *args, **kwargs):
        """
        å°†å¸¦æ³¨é‡Šçš„æ¨ç†ç»“æœå›¾åƒä¿å­˜åˆ°æ–‡ä»¶ã€‚

        è¯¥æ–¹æ³•åœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœå¹¶å°†å¸¦æ³¨é‡Šçš„å›¾åƒä¿å­˜åˆ°æ–‡ä»¶ã€‚å®ƒåˆ©ç”¨ `plot` æ–¹æ³•ç”Ÿæˆå¸¦æ³¨é‡Šçš„å›¾åƒï¼Œç„¶åä¿å­˜åˆ°æŒ‡å®šçš„æ–‡ä»¶åã€‚

        å‚æ•°:
            filename (str | Path | None): ä¿å­˜å¸¦æ³¨é‡Šå›¾åƒçš„æ–‡ä»¶åã€‚å¦‚æœä¸º Noneï¼Œåˆ™æ ¹æ®åŸå§‹å›¾åƒè·¯å¾„ç”Ÿæˆé»˜è®¤æ–‡ä»¶åã€‚
            *args (Any): å¯å˜é•¿åº¦çš„å‚æ•°åˆ—è¡¨ï¼Œå°†ä¼ é€’ç»™ `plot` æ–¹æ³•ã€‚
            **kwargs (Any): å¯å˜å…³é”®å­—å‚æ•°ï¼Œå°†ä¼ é€’ç»™ `plot` æ–¹æ³•ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     result.save("annotated_image.jpg")
            >>> # æˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰ç»˜å›¾å‚æ•°
            >>> for result in results:
            ...     result.save("annotated_image.jpg", conf=False, line_width=2)
        """
        if not filename:
            filename = f"results_{Path(self.path).name}"
        self.plot(save=True, filename=filename, *args, **kwargs)
        return filename

    def verbose(self):
        """
        è¿”å›æ¯ä¸ªä»»åŠ¡çš„æ—¥å¿—å­—ç¬¦ä¸²ï¼Œè¯¦ç»†æè¿°æ£€æµ‹å’Œåˆ†ç±»ç»“æœã€‚

        è¯¥æ–¹æ³•ç”Ÿæˆä¸€ä¸ªå¯è¯»æ€§å¼ºçš„å­—ç¬¦ä¸²ï¼Œæ€»ç»“æ£€æµ‹å’Œåˆ†ç±»ç»“æœã€‚å®ƒåŒ…æ‹¬æ¯ä¸ªç±»çš„æ£€æµ‹æ•°é‡å’Œåˆ†ç±»ä»»åŠ¡çš„å‰äº”ä¸ªæ¦‚ç‡ã€‚

        è¿”å›:
            (str): ä¸€ä¸ªæ ¼å¼åŒ–çš„å­—ç¬¦ä¸²ï¼ŒåŒ…å«ç»“æœæ‘˜è¦ã€‚å¯¹äºæ£€æµ‹ä»»åŠ¡ï¼Œå®ƒåŒ…æ‹¬æ¯ä¸ªç±»çš„æ£€æµ‹æ•°é‡ã€‚å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œå®ƒåŒ…å«å‰äº”ä¸ªç±»çš„æ¦‚ç‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     print(result.verbose())
            2 persons, 1 car, 3 traffic lights,
            dog 0.92, cat 0.78, horse 0.64,

        æ³¨æ„:
            - å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç»“æœï¼Œåˆ™è¯¥æ–¹æ³•è¿”å› "(no detections), "ã€‚
            - å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œè¿”å›å‰äº”ä¸ªç±»çš„æ¦‚ç‡å’Œå¯¹åº”çš„ç±»åã€‚
            - è¿”å›çš„å­—ç¬¦ä¸²æŒ‰é€—å·åˆ†éš”ï¼Œå¹¶ä»¥é€—å·å’Œç©ºæ ¼ç»“å°¾ã€‚
        """
        log_string = ""
        probs = self.probs
        if len(self) == 0:
            return log_string if probs is not None else f"{log_string}(no detections), "
        if probs is not None:
            log_string += f"{', '.join(f'{self.names[j]} {probs.data[j]:.2f}' for j in probs.top5)}, "
        if boxes := self.boxes:
            for c in boxes.cls.unique():
                n = (boxes.cls == c).sum()  # æ¯ä¸ªç±»çš„æ£€æµ‹æ•°é‡
                log_string += f"{n} {self.names[int(c)]}{'s' * (n > 1)}, "
        return log_string

    def save_txt(self, txt_file, save_conf=False):
        """
        å°†æ£€æµ‹ç»“æœä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ä¸­ã€‚

        å‚æ•°:
            txt_file (str | Path): è¾“å‡ºæ–‡æœ¬æ–‡ä»¶çš„è·¯å¾„ã€‚
            save_conf (bool): æ˜¯å¦å°†ç½®ä¿¡åº¦åˆ†æ•°åŒ…å«åœ¨è¾“å‡ºä¸­ã€‚

        è¿”å›:
            (str): ä¿å­˜çš„æ–‡æœ¬æ–‡ä»¶çš„è·¯å¾„ã€‚

        ç¤ºä¾‹:
            >>> from ultralytics import YOLO
            >>> model = YOLO("yolo11n.pt")
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     result.save_txt("output.txt")

        æ³¨æ„:
            - æ–‡ä»¶ä¸­å°†åŒ…å«æ¯ä¸ªæ£€æµ‹æˆ–åˆ†ç±»çš„ä¸€è¡Œï¼Œç»“æ„å¦‚ä¸‹ï¼š
              - å¯¹äºæ£€æµ‹ï¼š`class confidence x_center y_center width height`
              - å¯¹äºåˆ†ç±»ï¼š`confidence class_name`
              - å¯¹äºæ©æ¨¡å’Œå…³é”®ç‚¹ï¼Œæ ¼å¼ä¼šæœ‰æ‰€ä¸åŒã€‚
            - è¯¥å‡½æ•°ä¼šåœ¨æ–‡ä»¶ä¸å­˜åœ¨æ—¶åˆ›å»ºè¾“å‡ºç›®å½•ã€‚
            - å¦‚æœ `save_conf` ä¸º Falseï¼Œåˆ™ç½®ä¿¡åº¦åˆ†æ•°å°†ä¸åŒ…å«åœ¨è¾“å‡ºä¸­ã€‚
            - æ–‡ä»¶çš„ç°æœ‰å†…å®¹ä¸ä¼šè¢«è¦†ç›–ï¼›æ–°ç»“æœä¼šé™„åŠ åˆ°æ–‡ä»¶æœ«å°¾ã€‚
        """
        is_obb = self.obb is not None
        boxes = self.obb if is_obb else self.boxes
        masks = self.masks
        probs = self.probs
        kpts = self.keypoints
        texts = []
        if probs is not None:
            # åˆ†ç±»
            [texts.append(f"{probs.data[j]:.2f} {self.names[j]}") for j in probs.top5]
        elif boxes:
            # æ£€æµ‹/åˆ†å‰²/å§¿æ€
            for j, d in enumerate(boxes):
                c, conf, id = int(d.cls), float(d.conf), None if d.id is None else int(d.id.item())
                line = (c, *(d.xyxyxyxyn.view(-1) if is_obb else d.xywhn.view(-1)))
                if masks:
                    seg = masks[j].xyn[0].copy().reshape(-1)  # åå‘æ©æ¨¡.xynï¼Œ(n,2) è½¬ä¸º (n*2)
                    line = (c, *seg)
                if kpts is not None:
                    kpt = torch.cat((kpts[j].xyn, kpts[j].conf[..., None]), 2) if kpts[j].has_visible else kpts[j].xyn
                    line += (*kpt.reshape(-1).tolist(),)
                line += (conf,) * save_conf + (() if id is None else (id,))
                texts.append(("%g " * len(line)).rstrip() % line)

        if texts:
            Path(txt_file).parent.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•
            with open(txt_file, "a") as f:
                f.writelines(text + "\n" for text in texts)

    def save_crop(self, save_dir, file_name=Path("im.jpg")):
        """
        å°†è£å‰ªåçš„æ£€æµ‹å›¾åƒä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚

        è¯¥æ–¹æ³•å°†æ£€æµ‹åˆ°çš„ç‰©ä½“è£å‰ªå›¾åƒä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚æ¯ä¸ªè£å‰ªå›¾åƒä¿å­˜åˆ°ä»¥ç‰©ä½“ç±»å‘½åçš„å­ç›®å½•ä¸­ï¼Œæ–‡ä»¶ååŸºäºè¾“å…¥çš„ `file_name`ã€‚

        å‚æ•°:
            save_dir (str | Path): è¦ä¿å­˜è£å‰ªå›¾åƒçš„ç›®å½•è·¯å¾„ã€‚
            file_name (str | Path): ä¿å­˜è£å‰ªå›¾åƒçš„åŸºæ–‡ä»¶åã€‚é»˜è®¤å€¼ä¸º Path("im.jpg")ã€‚

        æ³¨æ„:
            - è¯¥æ–¹æ³•ä¸æ”¯æŒåˆ†ç±»ä»»åŠ¡æˆ–é¢å‘ç›®æ ‡çš„è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰ä»»åŠ¡ã€‚
            - è£å‰ªå›¾åƒå°†ä¿å­˜ä¸º 'save_dir/class_name/file_name.jpg'ã€‚
            - å¦‚æœå­ç›®å½•ä¸å­˜åœ¨ï¼Œå°†ä¼šè‡ªåŠ¨åˆ›å»ºã€‚
            - åŸå§‹å›¾åƒåœ¨è£å‰ªå‰è¢«å¤åˆ¶ï¼Œä»¥é¿å…ä¿®æ”¹åŸå§‹å›¾åƒã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     result.save_crop(save_dir="path/to/crops", file_name="detection")
        """
        if self.probs is not None:
            LOGGER.warning("WARNING âš ï¸ åˆ†ç±»ä»»åŠ¡ä¸æ”¯æŒ `save_crop`ã€‚")
            return
        if self.obb is not None:
            LOGGER.warning("WARNING âš ï¸ OBB ä»»åŠ¡ä¸æ”¯æŒ `save_crop`ã€‚")
            return
        for d in self.boxes:
            save_one_box(
                d.xyxy,
                self.orig_img.copy(),
                file=Path(save_dir) / self.names[int(d.cls)] / Path(file_name).with_suffix(".jpg"),
                BGR=True,
            )

    def summary(self, normalize=False, decimals=5):
        """
        å°†æ¨ç†ç»“æœè½¬æ¢ä¸ºæ±‡æ€»å­—å…¸ï¼Œå¹¶å¯é€‰åœ°å¯¹è¾¹ç•Œæ¡†åæ ‡è¿›è¡Œå½’ä¸€åŒ–ã€‚

        è¯¥æ–¹æ³•åˆ›å»ºä¸€ä¸ªåŒ…å«æ¯ä¸ªæ£€æµ‹æˆ–åˆ†ç±»ç»“æœçš„å­—å…¸åˆ—è¡¨ã€‚å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œå®ƒè¿”å› top ç±»å’Œå¯¹åº”çš„ç½®ä¿¡åº¦ã€‚å¯¹äºæ£€æµ‹ä»»åŠ¡ï¼Œå®ƒåŒ…å«ç±»ä¿¡æ¯ã€è¾¹ç•Œæ¡†åæ ‡ï¼Œå¹¶å¯é€‰åœ°åŒ…æ‹¬æ©æ¨¡æ®µå’Œå…³é”®ç‚¹ã€‚

        å‚æ•°:
            normalize (bool): æ˜¯å¦æ ¹æ®å›¾åƒå°ºå¯¸å½’ä¸€åŒ–è¾¹ç•Œæ¡†åæ ‡ã€‚é»˜è®¤ä¸º Falseã€‚
            decimals (int): è¾“å‡ºå€¼çš„å°æ•°ä½æ•°ã€‚é»˜è®¤ä¸º 5ã€‚

        è¿”å›:
            (List[Dict]): ä¸€ä¸ªåŒ…å«æ¯ä¸ªæ£€æµ‹æˆ–åˆ†ç±»ç»“æœçš„å­—å…¸åˆ—è¡¨ã€‚æ¯ä¸ªå­—å…¸çš„ç»“æ„æ ¹æ®ä»»åŠ¡ç±»å‹ï¼ˆåˆ†ç±»æˆ–æ£€æµ‹ï¼‰å’Œå¯ç”¨çš„ä¿¡æ¯ï¼ˆè¾¹ç•Œæ¡†ã€æ©æ¨¡ã€å…³é”®ç‚¹ï¼‰æœ‰æ‰€ä¸åŒã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> summary = results[0].summary()
            >>> print(summary)
        """
        # åˆ›å»ºæ£€æµ‹ç»“æœçš„å­—å…¸åˆ—è¡¨
        results = []
        if self.probs is not None:
            class_id = self.probs.top1
            results.append(
                {
                    "name": self.names[class_id],
                    "class": class_id,
                    "confidence": round(self.probs.top1conf.item(), decimals),
                }
            )
            return results

        is_obb = self.obb is not None
        data = self.obb if is_obb else self.boxes
        h, w = self.orig_shape if normalize else (1, 1)
        for i, row in enumerate(data):  # xyxy, track_id å¦‚æœæœ‰è·Ÿè¸ªï¼Œconf, class_id
            class_id, conf = int(row.cls), round(row.conf.item(), decimals)
            box = (row.xyxyxyxy if is_obb else row.xyxy).squeeze().reshape(-1, 2).tolist()
            xy = {}
            for j, b in enumerate(box):
                xy[f"x{j + 1}"] = round(b[0] / w, decimals)
                xy[f"y{j + 1}"] = round(b[1] / h, decimals)
            result = {"name": self.names[class_id], "class": class_id, "confidence": conf, "box": xy}
            if data.is_track:
                result["track_id"] = int(row.id.item())  # è·Ÿè¸ª ID
            if self.masks:
                result["segments"] = {
                    "x": (self.masks.xy[i][:, 0] / w).round(decimals).tolist(),
                    "y": (self.masks.xy[i][:, 1] / h).round(decimals).tolist(),
                }
            if self.keypoints is not None:
                x, y, visible = self.keypoints[i].data[0].cpu().unbind(dim=1)  # torch Tensor
                result["keypoints"] = {
                    "x": (x / w).numpy().round(decimals).tolist(),  # decimals å‚æ•°éœ€è¦å‘½å
                    "y": (y / h).numpy().round(decimals).tolist(),
                    "visible": visible.numpy().round(decimals).tolist(),
                }
            results.append(result)

        return results

    def to_df(self, normalize=False, decimals=5):
        """
        å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸º Pandas Dataframe æ ¼å¼ã€‚

        è¯¥æ–¹æ³•å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸º Pandas Dataframe æ ¼å¼ã€‚å®ƒåŒ…å«æœ‰å…³æ£€æµ‹åˆ°çš„ç‰©ä½“çš„ä¿¡æ¯ï¼Œä¾‹å¦‚è¾¹ç•Œæ¡†ã€ç±»åã€ç½®ä¿¡åº¦åˆ†æ•°ï¼Œå¹¶å¯é€‰åœ°åŒ…æ‹¬åˆ†å‰²æ©æ¨¡å’Œå…³é”®ç‚¹ã€‚

        å‚æ•°:
            normalize (bool): æ˜¯å¦å°†è¾¹ç•Œæ¡†åæ ‡å½’ä¸€åŒ–åˆ°å›¾åƒå°ºå¯¸ã€‚å¦‚æœä¸º Trueï¼Œåæ ‡å°†è¿”å›ä¸º 0 åˆ° 1 ä¹‹é—´çš„æµ®åŠ¨å€¼ã€‚é»˜è®¤ä¸º Falseã€‚
            decimals (int): è¾“å‡ºå€¼çš„å°æ•°ä½æ•°ã€‚é»˜è®¤ä¸º 5ã€‚

        è¿”å›:
            (DataFrame): ä¸€ä¸ª Pandas Dataframeï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰ç»“æœçš„ä¿¡æ¯ï¼Œå¹¶æŒ‰ç»„ç»‡çš„æ–¹å¼æ’åˆ—ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> df_result = results[0].to_df()
            >>> print(df_result)
        """
        import pandas as pd  # åŠ è½½ä»¥ä¼˜åŒ–æ€§èƒ½

        return pd.DataFrame(self.summary(normalize=normalize, decimals=decimals))

    def to_csv(self, normalize=False, decimals=5, *args, **kwargs):
        """
        å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸º CSV æ ¼å¼ã€‚

        è¯¥æ–¹æ³•å°†æ£€æµ‹ç»“æœåºåˆ—åŒ–ä¸º CSV æ ¼å¼ã€‚å®ƒåŒ…å«æœ‰å…³æ£€æµ‹åˆ°çš„ç‰©ä½“çš„ä¿¡æ¯ï¼Œä¾‹å¦‚è¾¹ç•Œæ¡†ã€ç±»åã€ç½®ä¿¡åº¦åˆ†æ•°ï¼Œå¹¶å¯é€‰åœ°åŒ…æ‹¬åˆ†å‰²æ©æ¨¡å’Œå…³é”®ç‚¹ã€‚

        å‚æ•°:
            normalize (bool): æ˜¯å¦å°†è¾¹ç•Œæ¡†åæ ‡å½’ä¸€åŒ–åˆ°å›¾åƒå°ºå¯¸ã€‚å¦‚æœä¸º Trueï¼Œåæ ‡å°†è¿”å›ä¸º 0 åˆ° 1 ä¹‹é—´çš„æµ®åŠ¨å€¼ã€‚é»˜è®¤ä¸º Falseã€‚
            decimals (int): è¾“å‡ºå€¼çš„å°æ•°ä½æ•°ã€‚é»˜è®¤ä¸º 5ã€‚
            *args (Any): å¯å˜é•¿åº¦çš„å‚æ•°åˆ—è¡¨ï¼Œå°†ä¼ é€’ç»™ pandas.DataFrame.to_csv()ã€‚
            **kwargs (Any): å¯å˜å…³é”®å­—å‚æ•°ï¼Œå°†ä¼ é€’ç»™ pandas.DataFrame.to_csv()ã€‚

        è¿”å›:
            (str): åŒ…å«æ‰€æœ‰ç»“æœçš„ CSV æ–‡ä»¶ï¼Œä»¥ç»„ç»‡è‰¯å¥½çš„æ–¹å¼å­˜å‚¨ä¿¡æ¯ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> csv_result = results[0].to_csv()
            >>> print(csv_result)
        """
        return self.to_df(normalize=normalize, decimals=decimals).to_csv(*args, **kwargs)

    def to_xml(self, normalize=False, decimals=5, *args, **kwargs):
        """
        å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸º XML æ ¼å¼ã€‚

        è¯¥æ–¹æ³•å°†æ£€æµ‹ç»“æœåºåˆ—åŒ–ä¸º XML æ ¼å¼ã€‚å®ƒåŒ…å«æœ‰å…³æ£€æµ‹åˆ°çš„ç‰©ä½“çš„ä¿¡æ¯ï¼Œä¾‹å¦‚è¾¹ç•Œæ¡†ã€ç±»åã€ç½®ä¿¡åº¦åˆ†æ•°ï¼Œå¹¶å¯é€‰åœ°åŒ…æ‹¬åˆ†å‰²æ©æ¨¡å’Œå…³é”®ç‚¹ã€‚

        å‚æ•°:
            normalize (bool): æ˜¯å¦å°†è¾¹ç•Œæ¡†åæ ‡å½’ä¸€åŒ–åˆ°å›¾åƒå°ºå¯¸ã€‚å¦‚æœä¸º Trueï¼Œåæ ‡å°†è¿”å›ä¸º 0 åˆ° 1 ä¹‹é—´çš„æµ®åŠ¨å€¼ã€‚é»˜è®¤ä¸º Falseã€‚
            decimals (int): è¾“å‡ºå€¼çš„å°æ•°ä½æ•°ã€‚é»˜è®¤ä¸º 5ã€‚
            *args (Any): å¯å˜é•¿åº¦çš„å‚æ•°åˆ—è¡¨ï¼Œå°†ä¼ é€’ç»™ pandas.DataFrame.to_xml()ã€‚
            **kwargs (Any): å¯å˜å…³é”®å­—å‚æ•°ï¼Œå°†ä¼ é€’ç»™ pandas.DataFrame.to_xml()ã€‚

        è¿”å›:
            (str): åŒ…å«æ‰€æœ‰ç»“æœçš„ XML å­—ç¬¦ä¸²ï¼Œä»¥ç»„ç»‡è‰¯å¥½çš„æ–¹å¼å­˜å‚¨ä¿¡æ¯ã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> xml_result = results[0].to_xml()
            >>> print(xml_result)
        """
        check_requirements("lxml")
        df = self.to_df(normalize=normalize, decimals=decimals)
        return '<?xml version="1.0" encoding="utf-8"?>\n<root></root>' if df.empty else df.to_xml(*args, **kwargs)

    def tojson(self, normalize=False, decimals=5):
        """å·²å¼ƒç”¨çš„ to_json() ç‰ˆæœ¬ã€‚"""
        LOGGER.warning("WARNING âš ï¸ 'result.tojson()' å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ 'result.to_json()'ã€‚")
        return self.to_json(normalize, decimals)

    def to_json(self, normalize=False, decimals=5):
        """
        å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸º JSON æ ¼å¼ã€‚

        è¯¥æ–¹æ³•å°†æ£€æµ‹ç»“æœåºåˆ—åŒ–ä¸º JSON æ ¼å¼ã€‚å®ƒåŒ…å«æœ‰å…³æ£€æµ‹åˆ°çš„ç‰©ä½“çš„ä¿¡æ¯ï¼Œä¾‹å¦‚è¾¹ç•Œæ¡†ã€ç±»åã€ç½®ä¿¡åº¦åˆ†æ•°ï¼Œå¹¶å¯é€‰åœ°åŒ…æ‹¬åˆ†å‰²æ©æ¨¡å’Œå…³é”®ç‚¹ã€‚

        å‚æ•°:
            normalize (bool): æ˜¯å¦å°†è¾¹ç•Œæ¡†åæ ‡å½’ä¸€åŒ–åˆ°å›¾åƒå°ºå¯¸ã€‚å¦‚æœä¸º Trueï¼Œåæ ‡å°†è¿”å›ä¸º 0 åˆ° 1 ä¹‹é—´çš„æµ®åŠ¨å€¼ã€‚é»˜è®¤ä¸º Falseã€‚
            decimals (int): è¾“å‡ºå€¼çš„å°æ•°ä½æ•°ã€‚é»˜è®¤ä¸º 5ã€‚

        è¿”å›:
            (str): ä¸€ä¸ª JSON å­—ç¬¦ä¸²ï¼ŒåŒ…å«åºåˆ—åŒ–åçš„æ£€æµ‹ç»“æœã€‚

        ç¤ºä¾‹:
            >>> results = model("path/to/image.jpg")
            >>> json_result = results[0].to_json()
            >>> print(json_result)

        æ³¨æ„:
            - å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼ŒJSON å°†åŒ…å«ç±»æ¦‚ç‡ï¼Œè€Œä¸æ˜¯è¾¹ç•Œæ¡†ã€‚
            - å¯¹äºç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼ŒJSON å°†åŒ…æ‹¬è¾¹ç•Œæ¡†åæ ‡ã€ç±»åå’Œç½®ä¿¡åº¦åˆ†æ•°ã€‚
            - å¦‚æœå¯ç”¨ï¼ŒJSON è¾“å‡ºè¿˜å°†åŒ…å«åˆ†å‰²æ©æ¨¡å’Œå…³é”®ç‚¹ã€‚
            - è¯¥æ–¹æ³•å†…éƒ¨ä½¿ç”¨ `summary` æ–¹æ³•ç”Ÿæˆæ•°æ®ç»“æ„ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸º JSONã€‚
        """
        import json

        return json.dumps(self.summary(normalize=normalize, decimals=decimals), indent=2)


class Boxes(BaseTensor):
    """
    ç®¡ç†å’Œæ“ä½œæ£€æµ‹æ¡†çš„ç±»ã€‚

    è¯¥ç±»æä¾›äº†å¤„ç†æ£€æµ‹æ¡†çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬å…¶åæ ‡ã€ç½®ä¿¡åº¦åˆ†æ•°ã€ç±»åˆ«æ ‡ç­¾å’Œå¯é€‰çš„è·Ÿè¸ªIDã€‚å®ƒæ”¯æŒå¤šç§æ¡†æ ¼å¼ï¼Œå¹¶æä¾›æ–¹æ³•æ–¹ä¾¿åœ°åœ¨ä¸åŒåæ ‡ç³»ç»Ÿä¹‹é—´è¿›è¡Œæ“ä½œå’Œè½¬æ¢ã€‚

    å±æ€§:
        data (torch.Tensor | numpy.ndarray): åŒ…å«æ£€æµ‹æ¡†åŠç›¸å…³æ•°æ®çš„åŸå§‹å¼ é‡ã€‚
        orig_shape (Tuple[int, int]): å›¾åƒçš„åŸå§‹å°ºå¯¸ (é«˜åº¦, å®½åº¦)ã€‚
        is_track (bool): æŒ‡ç¤ºæ¡†æ•°æ®ä¸­æ˜¯å¦åŒ…å«è·Ÿè¸ªIDã€‚
        xyxy (torch.Tensor | numpy.ndarray): ä»¥ [x1, y1, x2, y2] æ ¼å¼çš„æ¡†ã€‚
        conf (torch.Tensor | numpy.ndarray): æ¯ä¸ªæ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
        cls (torch.Tensor | numpy.ndarray): æ¯ä¸ªæ¡†çš„ç±»åˆ«æ ‡ç­¾ã€‚
        id (torch.Tensor | numpy.ndarray): æ¯ä¸ªæ¡†çš„è·Ÿè¸ªIDï¼ˆå¦‚æœæœ‰ï¼‰ã€‚
        xywh (torch.Tensor | numpy.ndarray): ä»¥ [x, y, width, height] æ ¼å¼çš„æ¡†ã€‚
        xyxyn (torch.Tensor | numpy.ndarray): ç›¸å¯¹äºåŸå§‹å°ºå¯¸çš„å½’ä¸€åŒ– [x1, y1, x2, y2] æ¡†ã€‚
        xywhn (torch.Tensor | numpy.ndarray): ç›¸å¯¹äºåŸå§‹å°ºå¯¸çš„å½’ä¸€åŒ– [x, y, width, height] æ¡†ã€‚

    æ–¹æ³•:
        cpu(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡å­˜å‚¨åœ¨CPUå†…å­˜ä¸­çš„å¯¹è±¡å‰¯æœ¬ã€‚
        numpy(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„çš„å¯¹è±¡å‰¯æœ¬ã€‚
        cuda(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡å­˜å‚¨åœ¨GPUå†…å­˜ä¸­çš„å¯¹è±¡å‰¯æœ¬ã€‚
        to(*args, **kwargs): è¿”å›ä¸€ä¸ªå°†å¼ é‡å­˜å‚¨åœ¨æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹ä¸­çš„å¯¹è±¡å‰¯æœ¬ã€‚

    ç¤ºä¾‹:
        >>> import torch
        >>> boxes_data = torch.tensor([[100, 50, 150, 100, 0.9, 0], [200, 150, 300, 250, 0.8, 1]])
        >>> orig_shape = (480, 640)  # é«˜åº¦, å®½åº¦
        >>> boxes = Boxes(boxes_data, orig_shape)
        >>> print(boxes.xyxy)
        >>> print(boxes.conf)
        >>> print(boxes.cls)
        >>> print(boxes.xywhn)
    """

    def __init__(self, boxes, orig_shape) -> None:
        """
        ä½¿ç”¨æ£€æµ‹æ¡†æ•°æ®å’ŒåŸå§‹å›¾åƒå½¢çŠ¶åˆå§‹åŒ–Boxesç±»ã€‚

        è¯¥ç±»ç®¡ç†æ£€æµ‹æ¡†ï¼Œæä¾›ä¾¿æ·çš„è®¿é—®å’Œæ“ä½œæ¡†åæ ‡ã€ç½®ä¿¡åº¦åˆ†æ•°ã€ç±»åˆ«æ ‡è¯†ç¬¦å’Œå¯é€‰çš„è·Ÿè¸ªIDã€‚å®ƒæ”¯æŒå¤šç§æ¡†åæ ‡æ ¼å¼ï¼ŒåŒ…æ‹¬ç»å¯¹åæ ‡å’Œå½’ä¸€åŒ–æ ¼å¼ã€‚

        å‚æ•°:
            boxes (torch.Tensor | np.ndarray): ä¸€ä¸ªå½¢çŠ¶ä¸º (num_boxes, 6) æˆ– (num_boxes, 7) çš„å¼ é‡æˆ–numpyæ•°ç»„ã€‚
                åˆ—åº”åŒ…å« [x1, y1, x2, y2, confidence, class, (å¯é€‰) track_id]ã€‚
            orig_shape (Tuple[int, int]): åŸå§‹å›¾åƒçš„å°ºå¯¸ (é«˜åº¦, å®½åº¦)ï¼Œç”¨äºå½’ä¸€åŒ–ã€‚

        å±æ€§:
            data (torch.Tensor): åŒ…å«æ£€æµ‹æ¡†åŠå…¶ç›¸å…³æ•°æ®çš„åŸå§‹å¼ é‡ã€‚
            orig_shape (Tuple[int, int]): ç”¨äºå½’ä¸€åŒ–çš„åŸå§‹å›¾åƒå°ºå¯¸ã€‚
            is_track (bool): æŒ‡ç¤ºæ¡†æ•°æ®ä¸­æ˜¯å¦åŒ…å«è·Ÿè¸ªIDã€‚

        ç¤ºä¾‹:
            >>> import torch
            >>> boxes = torch.tensor([[100, 50, 150, 100, 0.9, 0]])
            >>> orig_shape = (480, 640)
            >>> detection_boxes = Boxes(boxes, orig_shape)
            >>> print(detection_boxes.xyxy)
            tensor([[100.,  50., 150., 100.]])
        """
        if boxes.ndim == 1:
            boxes = boxes[None, :]
        n = boxes.shape[-1]
        assert n in {6, 7}, f"expected 6 or 7 values but got {n}"  # xyxy, track_id, conf, cls
        super().__init__(boxes, orig_shape)
        self.is_track = n == 7
        self.orig_shape = orig_shape

    @property
    def xyxy(self):
        """
        è¿”å›ä»¥ [x1, y1, x2, y2] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): å½¢çŠ¶ä¸º (n, 4) çš„å¼ é‡æˆ–numpyæ•°ç»„ï¼Œå…¶ä¸­åŒ…å«ä»¥ [x1, y1, x2, y2] æ ¼å¼è¡¨ç¤ºçš„è¾¹ç•Œæ¡†åæ ‡ï¼Œn ä¸ºæ¡†çš„æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> boxes = results[0].boxes
            >>> xyxy = boxes.xyxy
            >>> print(xyxy)
        """
        return self.data[:, :4]

    @property
    def conf(self):
        """
        è¿”å›æ¯ä¸ªæ£€æµ‹æ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä¸€ä¸ªä¸€ç»´å¼ é‡æˆ–æ•°ç»„ï¼ŒåŒ…å«æ¯ä¸ªæ£€æµ‹æ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°ï¼Œå½¢çŠ¶ä¸º (N,)ï¼Œå…¶ä¸­ N ä¸ºæ£€æµ‹æ¡†çš„æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> boxes = Boxes(torch.tensor([[10, 20, 30, 40, 0.9, 0]]), orig_shape=(100, 100))
            >>> conf_scores = boxes.conf
            >>> print(conf_scores)
            tensor([0.9000])
        """
        return self.data[:, -2]

    @property
    def cls(self):
        """
        è¿”å›è¡¨ç¤ºæ¯ä¸ªè¾¹ç•Œæ¡†ç±»åˆ«é¢„æµ‹çš„ç±»åˆ«IDå¼ é‡ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä¸€ä¸ªåŒ…å«æ¯ä¸ªæ£€æµ‹æ¡†çš„ç±»åˆ«IDçš„å¼ é‡æˆ–numpyæ•°ç»„ï¼Œå½¢çŠ¶ä¸º (N,)ï¼Œå…¶ä¸­ N ä¸ºæ¡†çš„æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> boxes = results[0].boxes
            >>> class_ids = boxes.cls
            >>> print(class_ids)  # tensor([0., 2., 1.])
        """
        return self.data[:, -1]

    @property
    def id(self):
        """
        å¦‚æœå¯ç”¨ï¼Œè¿”å›æ¯ä¸ªæ£€æµ‹æ¡†çš„è·Ÿè¸ªIDã€‚

        è¿”å›:
            (torch.Tensor | None): å¦‚æœå¯ç”¨äº†è·Ÿè¸ªï¼Œåˆ™è¿”å›åŒ…å«æ¯ä¸ªæ¡†çš„è·Ÿè¸ªIDçš„å¼ é‡ï¼›å¦åˆ™è¿”å›Noneã€‚å½¢çŠ¶ä¸º (N,)ï¼Œå…¶ä¸­ N ä¸ºæ¡†çš„æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> results = model.track("path/to/video.mp4")
            >>> for result in results:
            ...     boxes = result.boxes
            ...     if boxes.is_track:
            ...         track_ids = boxes.id
            ...         print(f"Tracking IDs: {track_ids}")
            ...     else:
            ...         print("è¿™äº›æ¡†æ²¡æœ‰å¯ç”¨è·Ÿè¸ªã€‚")

        å¤‡æ³¨:
            - åªæœ‰åœ¨å¯ç”¨è·Ÿè¸ªæ—¶ï¼ˆå³`is_track`ä¸ºTrueï¼‰è¯¥å±æ€§æ‰å¯ç”¨ã€‚
            - è·Ÿè¸ªIDé€šå¸¸ç”¨äºè§†é¢‘åˆ†æä¸­çš„å¤šå¸§ç›®æ ‡å…³è”ã€‚
        """
        return self.data[:, -3] if self.is_track else None

    @property
    @lru_cache(maxsize=2)  # maxsize 1 should suffice
    def xywh(self):
        """
        å°†è¾¹ç•Œæ¡†ä» [x1, y1, x2, y2] æ ¼å¼è½¬æ¢ä¸º [x, y, width, height] æ ¼å¼ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä»¥ [x_center, y_center, width, height] æ ¼å¼è¡¨ç¤ºçš„æ¡†ï¼Œå…¶ä¸­ x_center å’Œ y_center æ˜¯è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹åæ ‡ï¼Œwidth å’Œ height æ˜¯è¾¹ç•Œæ¡†çš„å®½åº¦å’Œé«˜åº¦ï¼Œè¿”å›çš„å¼ é‡å½¢çŠ¶ä¸º (N, 4)ï¼Œå…¶ä¸­ N ä¸ºæ¡†çš„æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> boxes = Boxes(torch.tensor([[100, 50, 150, 100], [200, 150, 300, 250]]), orig_shape=(480, 640))
            >>> xywh = boxes.xywh
            >>> print(xywh)
            tensor([[100.0000,  50.0000,  50.0000,  50.0000],
                    [200.0000, 150.0000, 100.0000, 100.0000]])
        """
        return ops.xyxy2xywh(self.xyxy)

    @property
    @lru_cache(maxsize=2)
    def xyxyn(self):
        """
        è¿”å›ç›¸å¯¹äºåŸå§‹å›¾åƒå¤§å°çš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†åæ ‡ã€‚

        è¯¥å±æ€§è®¡ç®—å¹¶è¿”å›ä»¥ [x1, y1, x2, y2] æ ¼å¼è¡¨ç¤ºçš„è¾¹ç•Œæ¡†åæ ‡ï¼Œåæ ‡å€¼æ ¹æ®åŸå§‹å›¾åƒå°ºå¯¸å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†åæ ‡ï¼Œå½¢çŠ¶ä¸º (N, 4)ï¼Œå…¶ä¸­ N ä¸ºæ¡†çš„æ•°é‡ã€‚æ¯ä¸€è¡ŒåŒ…å«å½’ä¸€åŒ–çš„ [x1, y1, x2, y2] å€¼ã€‚

        ç¤ºä¾‹:
            >>> boxes = Boxes(torch.tensor([[100, 50, 300, 400, 0.9, 0]]), orig_shape=(480, 640))
            >>> normalized = boxes.xyxyn
            >>> print(normalized)
            tensor([[0.1562, 0.1042, 0.4688, 0.8333]])
        """
        xyxy = self.xyxy.clone() if isinstance(self.xyxy, torch.Tensor) else np.copy(self.xyxy)
        xyxy[..., [0, 2]] /= self.orig_shape[1]
        xyxy[..., [1, 3]] /= self.orig_shape[0]
        return xyxy

    @property
    @lru_cache(maxsize=2)
    def xywhn(self):
        """
        è¿”å›å½’ä¸€åŒ–çš„ [x, y, width, height] æ ¼å¼çš„è¾¹ç•Œæ¡†ã€‚

        è¯¥å±æ€§è®¡ç®—å¹¶è¿”å›ä»¥ [x_center, y_center, width, height] æ ¼å¼è¡¨ç¤ºçš„å½’ä¸€åŒ–è¾¹ç•Œæ¡†åæ ‡ï¼Œæ‰€æœ‰å€¼ç›¸å¯¹äºåŸå§‹å›¾åƒå°ºå¯¸ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): å½’ä¸€åŒ–çš„è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º (N, 4)ï¼Œå…¶ä¸­ N ä¸ºæ¡†çš„æ•°é‡ã€‚æ¯ä¸€è¡ŒåŒ…å«å½’ä¸€åŒ–çš„ [x_center, y_center, width, height] å€¼ã€‚

        ç¤ºä¾‹:
            >>> boxes = Boxes(torch.tensor([[100, 50, 150, 100, 0.9, 0]]), orig_shape=(480, 640))
            >>> normalized = boxes.xywhn
            >>> print(normalized)
            tensor([[0.1953, 0.1562, 0.0781, 0.1042]])
        """
        xywh = ops.xyxy2xywh(self.xyxy)
        xywh[..., [0, 2]] /= self.orig_shape[1]
        xywh[..., [1, 3]] /= self.orig_shape[0]
        return xywh


class Masks(BaseTensor):
    """
    ç”¨äºå­˜å‚¨å’Œæ“ä½œæ£€æµ‹æ©ç çš„ç±»ã€‚

    è¯¥ç±»æ‰©å±•äº† BaseTensor å¹¶æä¾›äº†å¤„ç†åˆ†å‰²æ©ç çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬åœ¨åƒç´ åæ ‡å’Œå½’ä¸€åŒ–åæ ‡ä¹‹é—´è½¬æ¢çš„æ–¹æ³•ã€‚

    å±æ€§:
        data (torch.Tensor | numpy.ndarray): åŒ…å«æ©ç æ•°æ®çš„åŸå§‹å¼ é‡æˆ–æ•°ç»„ã€‚
        orig_shape (tuple): åŸå§‹å›¾åƒçš„å½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
        xy (List[numpy.ndarray]): åƒç´ åæ ‡ä¸‹çš„åˆ†æ®µåˆ—è¡¨ã€‚
        xyn (List[numpy.ndarray]): å½’ä¸€åŒ–åæ ‡ä¸‹çš„åˆ†æ®µåˆ—è¡¨ã€‚

    æ–¹æ³•:
        cpu(): è¿”å›ä¸€ä¸ªæ©ç å¼ é‡å­˜å‚¨åœ¨ CPU å†…å­˜ä¸­çš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚
        numpy(): è¿”å›ä¸€ä¸ªæ©ç å¼ é‡ä½œä¸º numpy æ•°ç»„å­˜å‚¨çš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚
        cuda(): è¿”å›ä¸€ä¸ªæ©ç å¼ é‡å­˜å‚¨åœ¨ GPU å†…å­˜ä¸­çš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚
        to(*args, **kwargs): è¿”å›ä¸€ä¸ªæ©ç å¼ é‡å­˜å‚¨åœ¨æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹ä¸­çš„ Masks å¯¹è±¡å‰¯æœ¬ã€‚

    ç¤ºä¾‹:
        >>> masks_data = torch.rand(1, 160, 160)
        >>> orig_shape = (720, 1280)
        >>> masks = Masks(masks_data, orig_shape)
        >>> pixel_coords = masks.xy
        >>> normalized_coords = masks.xyn
    """

    def __init__(self, masks, orig_shape) -> None:
        """
        ä½¿ç”¨æ£€æµ‹æ©ç æ•°æ®å’ŒåŸå§‹å›¾åƒå½¢çŠ¶åˆå§‹åŒ– Masks ç±»ã€‚

        å‚æ•°:
            masks (torch.Tensor | np.ndarray): æ£€æµ‹æ©ç ï¼Œå½¢çŠ¶ä¸º (num_masks, height, width)ã€‚
            orig_shape (tuple): åŸå§‹å›¾åƒå½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ï¼Œç”¨äºå½’ä¸€åŒ–ã€‚

        ç¤ºä¾‹:
            >>> import torch
            >>> from ultralytics.engine.results import Masks
            >>> masks = torch.rand(10, 160, 160)  # 10 ä¸ª 160x160 åˆ†è¾¨ç‡çš„æ©ç 
            >>> orig_shape = (720, 1280)  # åŸå§‹å›¾åƒå½¢çŠ¶
            >>> mask_obj = Masks(masks, orig_shape)
        """
        if masks.ndim == 2:
            masks = masks[None, :]
        super().__init__(masks, orig_shape)

    @property
    @lru_cache(maxsize=1)
    def xyn(self):
        """
        è¿”å›åˆ†å‰²æ©ç çš„å½’ä¸€åŒ– xy åæ ‡ã€‚

        è¯¥å±æ€§è®¡ç®—å¹¶ç¼“å­˜åˆ†å‰²æ©ç çš„å½’ä¸€åŒ– xy åæ ‡ã€‚åæ ‡æ˜¯ç›¸å¯¹äºåŸå§‹å›¾åƒå½¢çŠ¶è¿›è¡Œå½’ä¸€åŒ–çš„ã€‚

        è¿”å›:
            (List[numpy.ndarray]): ä¸€ä¸ª numpy æ•°ç»„çš„åˆ—è¡¨ï¼Œæ¯ä¸ªæ•°ç»„åŒ…å«ä¸€ä¸ªåˆ†å‰²æ©ç çš„å½’ä¸€åŒ– xy åæ ‡ã€‚
                æ¯ä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (N, 2)ï¼Œå…¶ä¸­ N æ˜¯æ©ç è½®å»“ä¸­çš„ç‚¹æ•°ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> masks = results[0].masks
            >>> normalized_coords = masks.xyn
            >>> print(normalized_coords[0])  # ç¬¬ä¸€ä¸ªæ©ç çš„å½’ä¸€åŒ–åæ ‡
        """
        return [
            ops.scale_coords(self.data.shape[1:], x, self.orig_shape, normalize=True)
            for x in ops.masks2segments(self.data)
        ]

    @property
    @lru_cache(maxsize=1)
    def xy(self):
        """
        è¿”å›æ©ç å¼ é‡ä¸­æ¯ä¸ªåˆ†æ®µçš„ [x, y] åƒç´ åæ ‡ã€‚

        è¯¥å±æ€§è®¡ç®—å¹¶è¿”å› Masks å¯¹è±¡ä¸­æ¯ä¸ªåˆ†å‰²æ©ç çš„åƒç´ åæ ‡åˆ—è¡¨ã€‚åæ ‡è¢«ç¼©æ”¾ä»¥åŒ¹é…åŸå§‹å›¾åƒçš„å°ºå¯¸ã€‚

        è¿”å›:
            (List[numpy.ndarray]): ä¸€ä¸ª numpy æ•°ç»„çš„åˆ—è¡¨ï¼Œæ¯ä¸ªæ•°ç»„åŒ…å«ä¸€ä¸ªåˆ†å‰²æ©ç çš„ [x, y] åƒç´ åæ ‡ã€‚
                æ¯ä¸ªæ•°ç»„çš„å½¢çŠ¶ä¸º (N, 2)ï¼Œå…¶ä¸­ N æ˜¯åˆ†æ®µä¸­çš„ç‚¹æ•°ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> masks = results[0].masks
            >>> xy_coords = masks.xy
            >>> print(len(xy_coords))  # æ©ç çš„æ•°é‡
            >>> print(xy_coords[0].shape)  # ç¬¬ä¸€ä¸ªæ©ç åæ ‡çš„å½¢çŠ¶
        """
        return [
            ops.scale_coords(self.data.shape[1:], x, self.orig_shape, normalize=False)
            for x in ops.masks2segments(self.data)
        ]


class Keypoints(BaseTensor):
    """
    å­˜å‚¨å’Œæ“ä½œæ£€æµ‹å…³é”®ç‚¹çš„ç±»ã€‚

    è¯¥ç±»å°è£…äº†å¤„ç†å…³é”®ç‚¹æ•°æ®çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬åæ ‡æ“ä½œã€å½’ä¸€åŒ–å’Œç½®ä¿¡åº¦å€¼ã€‚

    å±æ€§:
        data (torch.Tensor): åŒ…å«å…³é”®ç‚¹æ•°æ®çš„åŸå§‹å¼ é‡ã€‚
        orig_shape (Tuple[int, int]): å›¾åƒçš„åŸå§‹å°ºå¯¸ (é«˜åº¦, å®½åº¦)ã€‚
        has_visible (bool): æŒ‡ç¤ºå…³é”®ç‚¹æ˜¯å¦åŒ…å«å¯è§æ€§ä¿¡æ¯ã€‚
        xy (torch.Tensor): å…³é”®ç‚¹åæ ‡ï¼Œä»¥ [x, y] æ ¼å¼è¡¨ç¤ºã€‚
        xyn (torch.Tensor): ç›¸å¯¹äºåŸå§‹å›¾åƒå°ºå¯¸çš„å½’ä¸€åŒ–å…³é”®ç‚¹åæ ‡ï¼Œä»¥ [x, y] æ ¼å¼è¡¨ç¤ºã€‚
        conf (torch.Tensor): æ¯ä¸ªå…³é”®ç‚¹çš„ç½®ä¿¡åº¦å€¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚

    æ–¹æ³•:
        cpu(): è¿”å›ä¸€ä¸ªå°†å…³é”®ç‚¹å¼ é‡å­˜å‚¨åœ¨CPUå†…å­˜ä¸­çš„å‰¯æœ¬ã€‚
        numpy(): è¿”å›ä¸€ä¸ªå°†å…³é”®ç‚¹å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„çš„å‰¯æœ¬ã€‚
        cuda(): è¿”å›ä¸€ä¸ªå°†å…³é”®ç‚¹å¼ é‡å­˜å‚¨åœ¨GPUå†…å­˜ä¸­çš„å‰¯æœ¬ã€‚
        to(*args, **kwargs): è¿”å›ä¸€ä¸ªå°†å…³é”®ç‚¹å¼ é‡å­˜å‚¨åœ¨æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹ä¸­çš„å‰¯æœ¬ã€‚

    ç¤ºä¾‹:
        >>> import torch
        >>> from ultralytics.engine.results import Keypoints
        >>> keypoints_data = torch.rand(1, 17, 3)  # 1 ä¸ªæ£€æµ‹ï¼Œ17 ä¸ªå…³é”®ç‚¹ï¼Œ(x, y, conf)
        >>> orig_shape = (480, 640)  # åŸå§‹å›¾åƒå°ºå¯¸ (é«˜åº¦, å®½åº¦)
        >>> keypoints = Keypoints(keypoints_data, orig_shape)
        >>> print(keypoints.xy.shape)  # è®¿é—® xy åæ ‡
        >>> print(keypoints.conf)  # è®¿é—®ç½®ä¿¡åº¦å€¼
        >>> keypoints_cpu = keypoints.cpu()  # å°†å…³é”®ç‚¹ç§»åŠ¨åˆ° CPU
    """

    @smart_inference_mode()  # é¿å… keypoints < conf å‘ç”ŸåŸåœ°é”™è¯¯
    def __init__(self, keypoints, orig_shape) -> None:
        """
        ä½¿ç”¨æ£€æµ‹å…³é”®ç‚¹å’ŒåŸå§‹å›¾åƒå°ºå¯¸åˆå§‹åŒ– Keypoints å¯¹è±¡ã€‚

        è¯¥æ–¹æ³•å¤„ç†è¾“å…¥çš„å…³é”®ç‚¹å¼ é‡ï¼Œæ”¯æŒ 2D å’Œ 3D æ ¼å¼ã€‚å¯¹äº 3D å¼ é‡ (x, y, confidence)ï¼Œ
        å®ƒä¼šé€šè¿‡å°†å…¶åæ ‡è®¾ä¸ºé›¶æ¥å±è”½æ‰ä½ç½®ä¿¡åº¦çš„å…³é”®ç‚¹ã€‚

        å‚æ•°:
            keypoints (torch.Tensor): åŒ…å«å…³é”®ç‚¹æ•°æ®çš„å¼ é‡ã€‚å½¢çŠ¶å¯ä»¥æ˜¯ï¼š
                - (num_objects, num_keypoints, 2)ï¼Œè¡¨ç¤ºåªæœ‰ x, y åæ ‡
                - (num_objects, num_keypoints, 3)ï¼Œè¡¨ç¤º x, y åæ ‡å’Œç½®ä¿¡åº¦åˆ†æ•°
            orig_shape (Tuple[int, int]): åŸå§‹å›¾åƒå°ºå¯¸ (é«˜åº¦, å®½åº¦)ã€‚

        ç¤ºä¾‹:
            >>> kpts = torch.rand(1, 17, 3)  # 1 ä¸ªå¯¹è±¡ï¼Œ17 ä¸ªå…³é”®ç‚¹ï¼ˆCOCO æ ¼å¼ï¼‰ï¼Œx,y,conf
            >>> orig_shape = (720, 1280)  # åŸå§‹å›¾åƒé«˜åº¦ï¼Œå®½åº¦
            >>> keypoints = Keypoints(kpts, orig_shape)
        """
        if keypoints.ndim == 2:
            keypoints = keypoints[None, :]
        if keypoints.shape[2] == 3:  # x, y, conf
            mask = keypoints[..., 2] < 0.5  # ç½®ä¿¡åº¦å°äº 0.5 çš„ç‚¹ï¼ˆä¸å¯è§ï¼‰
            keypoints[..., :2][mask] = 0
        super().__init__(keypoints, orig_shape)
        self.has_visible = self.data.shape[-1] == 3

    @property
    @lru_cache(maxsize=1)
    def xy(self):
        """
        è¿”å›å…³é”®ç‚¹çš„ x, y åæ ‡ã€‚

        è¿”å›:
            (torch.Tensor): ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«å…³é”®ç‚¹çš„ x, y åæ ‡ï¼Œå½¢çŠ¶ä¸º (N, K, 2)ï¼Œ
                å…¶ä¸­ N æ˜¯æ£€æµ‹çš„æ•°é‡ï¼ŒK æ˜¯æ¯ä¸ªæ£€æµ‹çš„å…³é”®ç‚¹æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> keypoints = results[0].keypoints
            >>> xy = keypoints.xy
            >>> print(xy.shape)  # (N, K, 2)
            >>> print(xy[0])  # ç¬¬ä¸€ä¸ªæ£€æµ‹çš„å…³é”®ç‚¹ x, y åæ ‡

        å¤‡æ³¨:
            - è¿”å›çš„åæ ‡æ˜¯ç›¸å¯¹äºåŸå§‹å›¾åƒå°ºå¯¸çš„åƒç´ å•ä½ã€‚
            - å¦‚æœå…³é”®ç‚¹åˆå§‹åŒ–æ—¶åŒ…å«ç½®ä¿¡åº¦å€¼ï¼Œåªæœ‰ç½®ä¿¡åº¦ >= 0.5 çš„å…³é”®ç‚¹æ‰ä¼šè¢«è¿”å›ã€‚
            - è¯¥å±æ€§ä½¿ç”¨ LRU ç¼“å­˜æ¥æé«˜é‡å¤è®¿é—®æ—¶çš„æ€§èƒ½ã€‚
        """
        return self.data[..., :2]

    @property
    @lru_cache(maxsize=1)
    def xyn(self):
        """
        è¿”å›ç›¸å¯¹äºåŸå§‹å›¾åƒå°ºå¯¸çš„å½’ä¸€åŒ–å…³é”®ç‚¹åæ ‡ (x, y)ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä¸€ä¸ªå¼ é‡æˆ–æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (N, K, 2)ï¼ŒåŒ…å«å½’ä¸€åŒ–çš„å…³é”®ç‚¹åæ ‡ï¼Œ
                å…¶ä¸­ N æ˜¯å®ä¾‹çš„æ•°é‡ï¼ŒK æ˜¯å…³é”®ç‚¹çš„æ•°é‡ï¼Œæœ€åä¸€ç»´åŒ…å«å½’ä¸€åŒ–åçš„ [x, y] å€¼ï¼ŒèŒƒå›´ä¸º [0, 1]ã€‚

        ç¤ºä¾‹:
            >>> keypoints = Keypoints(torch.rand(1, 17, 2), orig_shape=(480, 640))
            >>> normalized_kpts = keypoints.xyn
            >>> print(normalized_kpts.shape)
            torch.Size([1, 17, 2])
        """
        xy = self.xy.clone() if isinstance(self.xy, torch.Tensor) else np.copy(self.xy)
        xy[..., 0] /= self.orig_shape[1]
        xy[..., 1] /= self.orig_shape[0]
        return xy

    @property
    @lru_cache(maxsize=1)
    def conf(self):
        """
        è¿”å›æ¯ä¸ªå…³é”®ç‚¹çš„ç½®ä¿¡åº¦å€¼ã€‚

        è¿”å›:
            (torch.Tensor | None): å¦‚æœå¯ç”¨ï¼Œè¿”å›åŒ…å«æ¯ä¸ªå…³é”®ç‚¹ç½®ä¿¡åº¦åˆ†æ•°çš„å¼ é‡ï¼Œ
                å¦åˆ™è¿”å› Noneã€‚å½¢çŠ¶ä¸º (num_detections, num_keypoints) å¯¹äºæ‰¹å¤„ç†æ•°æ®ï¼Œ
                æˆ– (num_keypoints,) å¯¹äºå•ä¸ªæ£€æµ‹ã€‚

        ç¤ºä¾‹:
            >>> keypoints = Keypoints(torch.rand(1, 17, 3), orig_shape=(640, 640))  # 1 ä¸ªæ£€æµ‹ï¼Œ17 ä¸ªå…³é”®ç‚¹
            >>> conf = keypoints.conf
            >>> print(conf.shape)  # torch.Size([1, 17])
        """
        return self.data[..., 2] if self.has_visible else None


class Probs(BaseTensor):
    """
    ä¸€ä¸ªç”¨äºå­˜å‚¨å’Œæ“ä½œåˆ†ç±»æ¦‚ç‡çš„ç±»ã€‚

    è¯¥ç±»æ‰©å±•äº† BaseTensorï¼Œå¹¶æä¾›äº†è®¿é—®å’Œæ“ä½œåˆ†ç±»æ¦‚ç‡çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ top-1 å’Œ top-5 çš„é¢„æµ‹ã€‚

    å±æ€§:
        data (torch.Tensor | numpy.ndarray): åŒ…å«åˆ†ç±»æ¦‚ç‡çš„åŸå§‹å¼ é‡æˆ–æ•°ç»„ã€‚
        orig_shape (tuple | None): åŸå§‹å›¾åƒçš„å½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚åœ¨æ­¤ç±»ä¸­æœªä½¿ç”¨ï¼Œä½†ä¸ºäº†ä¸å…¶ä»–ç»“æœç±»çš„ä¸€è‡´æ€§è€Œä¿ç•™ã€‚
        top1 (int): å…·æœ‰æœ€é«˜æ¦‚ç‡çš„ç±»åˆ«çš„ç´¢å¼•ã€‚
        top5 (List[int]): æŒ‰æ¦‚ç‡æ’åºçš„å‰ 5 ä¸ªç±»åˆ«çš„ç´¢å¼•ã€‚
        top1conf (torch.Tensor | numpy.ndarray): top 1 ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
        top5conf (torch.Tensor | numpy.ndarray): top 5 ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

    æ–¹æ³•:
        cpu(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡ç§»è‡³ CPU å†…å­˜çš„æ¦‚ç‡å¼ é‡å‰¯æœ¬ã€‚
        numpy(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡è½¬æ¢ä¸º numpy æ•°ç»„çš„æ¦‚ç‡å¼ é‡å‰¯æœ¬ã€‚
        cuda(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡ç§»è‡³ GPU å†…å­˜çš„æ¦‚ç‡å¼ é‡å‰¯æœ¬ã€‚
        to(*args, **kwargs): è¿”å›ä¸€ä¸ªå°†å¼ é‡ç§»è‡³æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹çš„æ¦‚ç‡å¼ é‡å‰¯æœ¬ã€‚

    ç¤ºä¾‹:
        >>> probs = torch.tensor([0.1, 0.3, 0.6])
        >>> p = Probs(probs)
        >>> print(p.top1)
        2
        >>> print(p.top5)
        [2, 1, 0]
        >>> print(p.top1conf)
        tensor(0.6000)
        >>> print(p.top5conf)
        tensor([0.6000, 0.3000, 0.1000])
    """

    def __init__(self, probs, orig_shape=None) -> None:
        """
        ä½¿ç”¨åˆ†ç±»æ¦‚ç‡åˆå§‹åŒ– Probs ç±»ã€‚

        è¯¥ç±»å­˜å‚¨å’Œç®¡ç†åˆ†ç±»æ¦‚ç‡ï¼Œæä¾›ä¾¿æ·çš„è®¿é—®æ–¹å¼æ¥æŸ¥çœ‹ top é¢„æµ‹å’Œå®ƒä»¬çš„ç½®ä¿¡åº¦ã€‚

        å‚æ•°:
            probs (torch.Tensor | np.ndarray): ä¸€ä¸ª 1D çš„å¼ é‡æˆ–æ•°ç»„ï¼Œè¡¨ç¤ºåˆ†ç±»æ¦‚ç‡ã€‚
            orig_shape (tuple | None): åŸå§‹å›¾åƒçš„å½¢çŠ¶ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚åœ¨æ­¤ç±»ä¸­æœªä½¿ç”¨ï¼Œä½†ä¸ºäº†ä¸å…¶ä»–ç»“æœç±»çš„ä¸€è‡´æ€§è€Œä¿ç•™ã€‚

        å±æ€§:
            data (torch.Tensor | np.ndarray): åŒ…å«åˆ†ç±»æ¦‚ç‡çš„åŸå§‹å¼ é‡æˆ–æ•°ç»„ã€‚
            top1 (int): top 1 ç±»åˆ«çš„ç´¢å¼•ã€‚
            top5 (List[int]): top 5 ç±»åˆ«çš„ç´¢å¼•ã€‚
            top1conf (torch.Tensor | np.ndarray): top 1 ç±»åˆ«çš„ç½®ä¿¡åº¦ã€‚
            top5conf (torch.Tensor | np.ndarray): top 5 ç±»åˆ«çš„ç½®ä¿¡åº¦ã€‚

        ç¤ºä¾‹:
            >>> import torch
            >>> probs = torch.tensor([0.1, 0.3, 0.2, 0.4])
            >>> p = Probs(probs)
            >>> print(p.top1)
            3
            >>> print(p.top1conf)
            tensor(0.4000)
            >>> print(p.top5)
            [3, 1, 2, 0]
        """
        super().__init__(probs, orig_shape)

    @property
    @lru_cache(maxsize=1)
    def top1(self):
        """
        è¿”å›å…·æœ‰æœ€é«˜æ¦‚ç‡çš„ç±»åˆ«çš„ç´¢å¼•ã€‚

        è¿”å›:
            (int): å…·æœ‰æœ€é«˜æ¦‚ç‡çš„ç±»åˆ«çš„ç´¢å¼•ã€‚

        ç¤ºä¾‹:
            >>> probs = Probs(torch.tensor([0.1, 0.3, 0.6]))
            >>> probs.top1
            2
        """
        return int(self.data.argmax())

    @property
    @lru_cache(maxsize=1)
    def top5(self):
        """
        è¿”å› top 5 ç±»åˆ«çš„æ¦‚ç‡çš„ç´¢å¼•ã€‚

        è¿”å›:
            (List[int]): ä¸€ä¸ªåŒ…å«æŒ‰æ¦‚ç‡é™åºæ’åˆ—çš„ top 5 ç±»åˆ«çš„ç´¢å¼•åˆ—è¡¨ã€‚

        ç¤ºä¾‹:
            >>> probs = Probs(torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5]))
            >>> print(probs.top5)
            [4, 3, 2, 1, 0]
        """
        return (-self.data).argsort(0)[:5].tolist()  # è¿™ç§æ–¹å¼é€‚ç”¨äº torch å’Œ numpyã€‚

    @property
    @lru_cache(maxsize=1)
    def top1conf(self):
        """
        è¿”å›æœ€é«˜æ¦‚ç‡ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        è¯¥å±æ€§è·å–åˆ†ç±»ç»“æœä¸­å…·æœ‰æœ€é«˜é¢„æµ‹æ¦‚ç‡çš„ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆæ¦‚ç‡ï¼‰ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): åŒ…å« top 1 ç±»åˆ«ç½®ä¿¡åº¦åˆ†æ•°çš„å¼ é‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")  # å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»
            >>> probs = results[0].probs  # è·å–åˆ†ç±»æ¦‚ç‡
            >>> top1_confidence = probs.top1conf  # è·å– top 1 ç±»åˆ«çš„ç½®ä¿¡åº¦
            >>> print(f"Top 1 ç±»åˆ«ç½®ä¿¡åº¦: {top1_confidence.item():.4f}")
        """
        return self.data[self.top1]

    @property
    @lru_cache(maxsize=1)
    def top5conf(self):
        """
        è¿”å› top 5 åˆ†ç±»é¢„æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        è¯¥å±æ€§è·å–æ¨¡å‹é¢„æµ‹çš„ top 5 ç±»åˆ«çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚å®ƒæä¾›äº†ä¸€ç§å¿«é€Ÿè®¿é—®æœ€æœ‰å¯èƒ½çš„ç±»åˆ«é¢„æµ‹
        åŠå…¶ç›¸å…³ç½®ä¿¡åº¦çš„æ–¹æ³•ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä¸€ä¸ªåŒ…å« top 5 é¢„æµ‹ç±»åˆ«ç½®ä¿¡åº¦åˆ†æ•°çš„å¼ é‡æˆ–æ•°ç»„ï¼Œ
                æŒ‰æ¦‚ç‡é™åºæ’åˆ—ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> probs = results[0].probs
            >>> top5_conf = probs.top5conf
            >>> print(top5_conf)  # æ‰“å° top 5 ç±»åˆ«çš„ç½®ä¿¡åº¦
        """
        return self.data[self.top5]


class OBB(BaseTensor):
    """
    ç”¨äºå­˜å‚¨å’Œæ“ä½œå®šå‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰çš„ç±»ã€‚

    è¯¥ç±»æä¾›äº†å¤„ç†å®šå‘è¾¹ç•Œæ¡†çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬åœ¨ä¸åŒæ ¼å¼ä¹‹é—´çš„è½¬æ¢ã€å½’ä¸€åŒ–ä»¥åŠè®¿é—®æ¡†çš„å„ç§å±æ€§ã€‚

    å±æ€§:
        data (torch.Tensor): åŒ…å«è¾¹ç•Œæ¡†åæ ‡å’Œç›¸å…³æ•°æ®çš„åŸå§‹ OBB å¼ é‡ã€‚
        orig_shape (tuple): åŸå§‹å›¾åƒå¤§å°ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚
        is_track (bool): æŒ‡ç¤ºæ¡†æ•°æ®ä¸­æ˜¯å¦åŒ…å«è·Ÿè¸ª IDã€‚
        xywhr (torch.Tensor | numpy.ndarray): ä»¥ [x_center, y_center, width, height, rotation] æ ¼å¼è¡¨ç¤ºçš„æ¡†ã€‚
        conf (torch.Tensor | numpy.ndarray): æ¯ä¸ªæ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
        cls (torch.Tensor | numpy.ndarray): æ¯ä¸ªæ¡†çš„ç±»åˆ«æ ‡ç­¾ã€‚
        id (torch.Tensor | numpy.ndarray): æ¯ä¸ªæ¡†çš„è·Ÿè¸ª IDï¼ˆå¦‚æœæœ‰ï¼‰ã€‚
        xyxyxyxy (torch.Tensor | numpy.ndarray): ä»¥ 8 ç‚¹ [x1, y1, x2, y2, x3, y3, x4, y4] æ ¼å¼è¡¨ç¤ºçš„æ¡†ã€‚
        xyxyxyxyn (torch.Tensor | numpy.ndarray): ç›¸å¯¹äºåŸå§‹å›¾åƒå°ºå¯¸çš„å½’ä¸€åŒ– 8 ç‚¹åæ ‡ã€‚
        xyxy (torch.Tensor | numpy.ndarray): ä»¥ [x1, y1, x2, y2] æ ¼å¼è¡¨ç¤ºçš„è½´å¯¹é½è¾¹ç•Œæ¡†ã€‚

    æ–¹æ³•:
        cpu(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡ç§»è‡³ CPU å†…å­˜çš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚
        numpy(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡è½¬æ¢ä¸º numpy æ•°ç»„çš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚
        cuda(): è¿”å›ä¸€ä¸ªå°†æ‰€æœ‰å¼ é‡ç§»è‡³ GPU å†…å­˜çš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚
        to(*args, **kwargs): è¿”å›ä¸€ä¸ªå°†å¼ é‡ç§»è‡³æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹çš„ OBB å¯¹è±¡å‰¯æœ¬ã€‚

    ç¤ºä¾‹:
        >>> boxes = torch.tensor([[100, 50, 150, 100, 30, 0.9, 0]])  # xywhr, conf, cls
        >>> obb = OBB(boxes, orig_shape=(480, 640))
        >>> print(obb.xyxyxyxy)
        >>> print(obb.conf)
        >>> print(obb.cls)
    """

    def __init__(self, boxes, orig_shape) -> None:
        """
        ä½¿ç”¨å®šå‘è¾¹ç•Œæ¡†æ•°æ®å’ŒåŸå§‹å›¾åƒå½¢çŠ¶åˆå§‹åŒ– OBBï¼ˆå®šå‘è¾¹ç•Œæ¡†ï¼‰å®ä¾‹ã€‚

        è¯¥ç±»ç”¨äºå­˜å‚¨å’Œæ“ä½œç”¨äºç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„å®šå‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰ã€‚å®ƒæä¾›äº†å¤šç§å±æ€§å’Œæ–¹æ³•æ¥è®¿é—®å’Œè½¬æ¢ OBB æ•°æ®ã€‚

        å‚æ•°:
            boxes (torch.Tensor | numpy.ndarray): åŒ…å«æ£€æµ‹æ¡†çš„å¼ é‡æˆ– numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (num_boxes, 7) æˆ– (num_boxes, 8)ã€‚
                æœ€åä¸¤åˆ—åŒ…å«ç½®ä¿¡åº¦å’Œç±»åˆ«å€¼ã€‚å¦‚æœå­˜åœ¨ï¼Œå€’æ•°ç¬¬ä¸‰åˆ—åŒ…å«è·Ÿè¸ª IDï¼Œç¬¬äº”åˆ—åŒ…å«æ—‹è½¬è§’åº¦ã€‚
            orig_shape (Tuple[int, int]): åŸå§‹å›¾åƒå¤§å°ï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦)ã€‚

        å±æ€§:
            data (torch.Tensor | numpy.ndarray): åŸå§‹ OBB å¼ é‡ã€‚
            orig_shape (Tuple[int, int]): åŸå§‹å›¾åƒå½¢çŠ¶ã€‚
            is_track (bool): æ˜¯å¦åŒ…å«è·Ÿè¸ª IDã€‚

        å¼‚å¸¸:
            AssertionError: å¦‚æœæ¯ä¸ªæ¡†çš„å€¼æ•°é‡ä¸æ˜¯ 7 æˆ– 8ã€‚

        ç¤ºä¾‹:
            >>> import torch
            >>> boxes = torch.rand(3, 7)  # 3 ä¸ªæ¡†ï¼Œæ¯ä¸ªæ¡†æœ‰ 7 ä¸ªå€¼
            >>> orig_shape = (640, 480)
            >>> obb = OBB(boxes, orig_shape)
            >>> print(obb.xywhr)  # è®¿é—® xywhr æ ¼å¼çš„æ¡†
        """
        if boxes.ndim == 1:
            boxes = boxes[None, :]
        n = boxes.shape[-1]
        assert n in {7, 8}, f"æœŸæœ›æ¯ä¸ªæ¡†æœ‰ 7 æˆ– 8 ä¸ªå€¼ï¼Œä½†å¾—åˆ°çš„æ˜¯ {n}"  # xywh, rotation, track_id, conf, cls
        super().__init__(boxes, orig_shape)
        self.is_track = n == 8
        self.orig_shape = orig_shape

    @property
    def xywhr(self):
        """
        è¿”å› [x_center, y_center, width, height, rotation] æ ¼å¼çš„æ¡†ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä¸€ä¸ªåŒ…å«å®šå‘è¾¹ç•Œæ¡†çš„å¼ é‡æˆ– numpy æ•°ç»„ï¼Œæ ¼å¼ä¸º [x_center, y_center, width, height, rotation]ã€‚
                å½¢çŠ¶ä¸º (N, 5)ï¼Œå…¶ä¸­ N æ˜¯æ¡†çš„æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> obb = results[0].obb
            >>> xywhr = obb.xywhr
            >>> print(xywhr.shape)
            torch.Size([3, 5])
        """
        return self.data[:, :5]

    @property
    def conf(self):
        """
        è¿”å›å®šå‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

        è¯¥å±æ€§è·å–ä¸æ¯ä¸ª OBB æ£€æµ‹ç›¸å…³çš„ç½®ä¿¡åº¦å€¼ã€‚ç½®ä¿¡åº¦åˆ†æ•°è¡¨ç¤ºæ¨¡å‹å¯¹æ£€æµ‹çš„å¯ä¿¡åº¦ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): å½¢çŠ¶ä¸º (N,) çš„å¼ é‡æˆ– numpy æ•°ç»„ï¼ŒåŒ…å« N ä¸ªæ£€æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°ï¼Œ
                æ¯ä¸ªåˆ†æ•°çš„èŒƒå›´ä¸º [0, 1]ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> obb_result = results[0].obb
            >>> confidence_scores = obb_result.conf
            >>> print(confidence_scores)
        """
        return self.data[:, -2]

    @property
    def cls(self):
        """
        è¿”å›å®šå‘è¾¹ç•Œæ¡†çš„ç±»åˆ«å€¼ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä¸€ä¸ªåŒ…å«æ¯ä¸ªå®šå‘è¾¹ç•Œæ¡†ç±»åˆ«å€¼çš„å¼ é‡æˆ– numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (N,)ï¼Œ
                å…¶ä¸­ N æ˜¯æ¡†çš„æ•°é‡ã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg")
            >>> result = results[0]
            >>> obb = result.obb
            >>> class_values = obb.cls
            >>> print(class_values)
        """
        return self.data[:, -1]

    @property
    def id(self):
        """
        è¿”å›å®šå‘è¾¹ç•Œæ¡†çš„è·Ÿè¸ª IDï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray | None): ä¸€ä¸ªåŒ…å«æ¯ä¸ªå®šå‘è¾¹ç•Œæ¡†çš„è·Ÿè¸ª ID çš„å¼ é‡æˆ– numpy æ•°ç»„ã€‚
                å¦‚æœæ²¡æœ‰è·Ÿè¸ª IDï¼Œåˆ™è¿”å› Noneã€‚

        ç¤ºä¾‹:
            >>> results = model("image.jpg", tracker=True)  # ä½¿ç”¨è·Ÿè¸ªè¿è¡Œæ¨ç†
            >>> for result in results:
            ...     if result.obb is not None:
            ...         track_ids = result.obb.id
            ...         if track_ids is not None:
            ...             print(f"è·Ÿè¸ª ID: {track_ids}")
        """
        return self.data[:, -3] if self.is_track else None

    @property
    @lru_cache(maxsize=2)
    def xyxyxyxy(self):
        """
        å°† OBB æ ¼å¼è½¬æ¢ä¸º 8 ç‚¹ï¼ˆxyxyxyxyï¼‰åæ ‡æ ¼å¼ï¼Œç”¨äºæ—‹è½¬çš„è¾¹ç•Œæ¡†ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä»¥ xyxyxyxy æ ¼å¼è¡¨ç¤ºçš„æ—‹è½¬è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º (N, 4, 2)ï¼Œå…¶ä¸­ N æ˜¯æ¡†çš„æ•°é‡ã€‚
                æ¯ä¸ªæ¡†ç”± 4 ä¸ªç‚¹ (x, y) è¡¨ç¤ºï¼Œä»å·¦ä¸Šè§’å¼€å§‹ï¼ŒæŒ‰é¡ºæ—¶é’ˆæ–¹å‘æ’åˆ—ã€‚

        ç¤ºä¾‹:
            >>> obb = OBB(torch.tensor([[100, 100, 50, 30, 0.5, 0.9, 0]]), orig_shape=(640, 640))
            >>> xyxyxyxy = obb.xyxyxyxy
            >>> print(xyxyxyxy.shape)
            torch.Size([1, 4, 2])
        """
        return ops.xywhr2xyxyxyxy(self.xywhr)

    @property
    @lru_cache(maxsize=2)
    def xyxyxyxyn(self):
        """
        å°†æ—‹è½¬çš„è¾¹ç•Œæ¡†è½¬æ¢ä¸ºå½’ä¸€åŒ–çš„ xyxyxyxy æ ¼å¼ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä»¥ xyxyxyxy æ ¼å¼è¡¨ç¤ºçš„å½’ä¸€åŒ–æ—‹è½¬è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º (N, 4, 2)ï¼Œ
                å…¶ä¸­ N æ˜¯æ¡†çš„æ•°é‡ã€‚æ¯ä¸ªæ¡†ç”± 4 ä¸ªç‚¹ (x, y) è¡¨ç¤ºï¼Œç›¸å¯¹äºåŸå§‹å›¾åƒå°ºå¯¸å½’ä¸€åŒ–ã€‚

        ç¤ºä¾‹:
            >>> obb = OBB(torch.rand(10, 7), orig_shape=(640, 480))  # 10 ä¸ªéšæœº OBB
            >>> normalized_boxes = obb.xyxyxyxyn
            >>> print(normalized_boxes.shape)
            torch.Size([10, 4, 2])
        """
        xyxyxyxyn = self.xyxyxyxy.clone() if isinstance(self.xyxyxyxy, torch.Tensor) else np.copy(self.xyxyxyxy)
        xyxyxyxyn[..., 0] /= self.orig_shape[1]
        xyxyxyxyn[..., 1] /= self.orig_shape[0]
        return xyxyxyxyn

    @property
    @lru_cache(maxsize=2)
    def xyxy(self):
        """
        å°†å®šå‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰è½¬æ¢ä¸ºè½´å¯¹é½çš„è¾¹ç•Œæ¡†ï¼Œè¿”å› xyxy æ ¼å¼ã€‚

        è¯¥å±æ€§è®¡ç®—æ¯ä¸ªå®šå‘è¾¹ç•Œæ¡†çš„æœ€å°åŒ…å›´çŸ©å½¢ï¼Œå¹¶å°†å…¶è¿”å›ä¸º xyxy æ ¼å¼ï¼ˆx1, y1, x2, y2ï¼‰ã€‚
        è¿™æ˜¯éœ€è¦ä¸éæ—‹è½¬æ¡†è®¡ç®— IoU ç­‰æ“ä½œæ—¶éå¸¸æœ‰ç”¨çš„ã€‚

        è¿”å›:
            (torch.Tensor | numpy.ndarray): ä»¥ xyxy æ ¼å¼è¡¨ç¤ºçš„è½´å¯¹é½è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º (N, 4)ï¼Œå…¶ä¸­ N æ˜¯æ¡†çš„æ•°é‡ã€‚
                æ¯è¡ŒåŒ…å« [x1, y1, x2, y2] åæ ‡ã€‚

        ç¤ºä¾‹:
            >>> import torch
            >>> from ultralytics import YOLO
            >>> model = YOLO("yolov8n-obb.pt")
            >>> results = model("path/to/image.jpg")
            >>> for result in results:
            ...     obb = result.obb
            ...     if obb is not None:
            ...         xyxy_boxes = obb.xyxy
            ...         print(xyxy_boxes.shape)  # (N, 4)

        æ³¨æ„:
            - è¯¥æ–¹æ³•é€šè¿‡æœ€å°åŒ…å›´çŸ©å½¢è¿‘ä¼¼ OBBã€‚
            - è¿”å›çš„æ ¼å¼å…¼å®¹æ ‡å‡†ç›®æ ‡æ£€æµ‹æŒ‡æ ‡å’Œå¯è§†åŒ–å·¥å…·ã€‚
            - è¯¥å±æ€§ä½¿ç”¨ç¼“å­˜æ¥æé«˜é‡å¤è®¿é—®çš„æ€§èƒ½ã€‚
        """
        x = self.xyxyxyxy[..., 0]
        y = self.xyxyxyxy[..., 1]
        return (
            torch.stack([x.amin(1), y.amin(1), x.amax(1), y.amax(1)], -1)
            if isinstance(x, torch.Tensor)
            else np.stack([x.min(1), y.min(1), x.max(1), y.max(1)], -1)
        )
