# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

# --------------------------------------------------------
# TinyViT æ¨¡å‹æ¶æ„
# ç‰ˆæƒæ‰€æœ‰ (c) 2022 Microsoft
# æ”¹ç¼–è‡ª LeViT å’Œ Swin Transformer
#   LeViT: (https://github.com/facebookresearch/levit)
#   Swin: (https://github.com/microsoft/swin-transformer)
# æ„å»º TinyViT æ¨¡å‹
# --------------------------------------------------------

import itertools
from typing import Tuple

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.checkpoint as checkpoint

from ultralytics.nn.modules import LayerNorm2d
from ultralytics.utils.instance import to_2tuple


class Conv2d_BN(torch.nn.Sequential):
    """
    ä¸€ä¸ªé¡ºåºå®¹å™¨ï¼Œå…ˆæ‰§è¡Œ 2D å·ç§¯ï¼Œå†æ‰§è¡Œæ‰¹é‡å½’ä¸€åŒ–ã€‚

    å±æ€§:
        c (torch.nn.Conv2d): 2D å·ç§¯å±‚ã€‚
        bn (torch.nn.BatchNorm2d): æ‰¹é‡å½’ä¸€åŒ–å±‚ã€‚

    æ–¹æ³•:
        __init__: ç”¨æŒ‡å®šçš„å‚æ•°åˆå§‹åŒ– Conv2d_BNã€‚

    å‚æ•°:
        a (int): è¾“å…¥é€šé“æ•°ã€‚
        b (int): è¾“å‡ºé€šé“æ•°ã€‚
        ks (int): å·ç§¯æ ¸å¤§å°ã€‚é»˜è®¤å€¼ä¸º 1ã€‚
        stride (int): å·ç§¯æ­¥å¹…ã€‚é»˜è®¤å€¼ä¸º 1ã€‚
        pad (int): å·ç§¯å¡«å……ã€‚é»˜è®¤å€¼ä¸º 0ã€‚
        dilation (int): å·ç§¯è†¨èƒ€å› å­ã€‚é»˜è®¤å€¼ä¸º 1ã€‚
        groups (int): å·ç§¯çš„ç»„æ•°ã€‚é»˜è®¤å€¼ä¸º 1ã€‚
        bn_weight_init (float): æ‰¹é‡å½’ä¸€åŒ–æƒé‡çš„åˆå§‹å€¼ã€‚é»˜è®¤å€¼ä¸º 1ã€‚

    ç¤ºä¾‹:
        >>> conv_bn = Conv2d_BN(3, 64, ks=3, stride=1, pad=1)
        >>> input_tensor = torch.randn(1, 3, 224, 224)
        >>> output = conv_bn(input_tensor)
        >>> print(output.shape)
    """

    def __init__(self, a, b, ks=1, stride=1, pad=0, dilation=1, groups=1, bn_weight_init=1):
        """ç”¨ 2D å·ç§¯å’Œæ‰¹é‡å½’ä¸€åŒ–åˆå§‹åŒ–ä¸€ä¸ªé¡ºåºå®¹å™¨ã€‚"""
        super().__init__()
        self.add_module("c", torch.nn.Conv2d(a, b, ks, stride, pad, dilation, groups, bias=False))
        bn = torch.nn.BatchNorm2d(b)
        torch.nn.init.constant_(bn.weight, bn_weight_init)
        torch.nn.init.constant_(bn.bias, 0)
        self.add_module("bn", bn)


class PatchEmbed(nn.Module):
    """
    å°†å›¾åƒåµŒå…¥ä¸ºè¡¥ä¸ï¼Œå¹¶å°†å®ƒä»¬æŠ•å½±åˆ°æŒ‡å®šçš„åµŒå…¥ç»´åº¦ã€‚

    å±æ€§:
        patches_resolution (Tuple[int, int]): åµŒå…¥åçš„è¡¥ä¸åˆ†è¾¨ç‡ã€‚
        num_patches (int): è¡¥ä¸æ€»æ•°ã€‚
        in_chans (int): è¾“å…¥é€šé“æ•°ã€‚
        embed_dim (int): åµŒå…¥ç»´åº¦ã€‚
        seq (nn.Sequential): ç”¨äºè¡¥ä¸åµŒå…¥çš„å·ç§¯å’Œæ¿€æ´»å±‚çš„åºåˆ—ã€‚

    æ–¹æ³•:
        forward: é€šè¿‡è¡¥ä¸åµŒå…¥åºåˆ—å¤„ç†è¾“å…¥å¼ é‡ã€‚

    ç¤ºä¾‹:
        >>> import torch
        >>> patch_embed = PatchEmbed(in_chans=3, embed_dim=96, resolution=224, activation=nn.GELU)
        >>> x = torch.randn(1, 3, 224, 224)
        >>> output = patch_embed(x)
        >>> print(output.shape)
    """

    def __init__(self, in_chans, embed_dim, resolution, activation):
        """é€šè¿‡å·ç§¯å±‚åˆå§‹åŒ–è¡¥ä¸åµŒå…¥ï¼Œç”¨äºå°†å›¾åƒè½¬æ¢ä¸ºè¡¥ä¸å¹¶è¿›è¡ŒæŠ•å½±ã€‚"""
        super().__init__()
        img_size: Tuple[int, int] = to_2tuple(resolution)
        self.patches_resolution = (img_size[0] // 4, img_size[1] // 4)
        self.num_patches = self.patches_resolution[0] * self.patches_resolution[1]
        self.in_chans = in_chans
        self.embed_dim = embed_dim
        n = embed_dim
        self.seq = nn.Sequential(
            Conv2d_BN(in_chans, n // 2, 3, 2, 1),
            activation(),
            Conv2d_BN(n // 2, n, 3, 2, 1),
        )

    def forward(self, x):
        """é€šè¿‡è¡¥ä¸åµŒå…¥åºåˆ—å¤„ç†è¾“å…¥å¼ é‡ï¼Œå°†å›¾åƒè½¬æ¢ä¸ºè¡¥ä¸åµŒå…¥ã€‚"""
        return self.seq(x)


class MBConv(nn.Module):
    """
    ç§»åŠ¨å€’ç½®ç“¶é¢ˆå·ç§¯å±‚ï¼ˆMBConvï¼‰ï¼Œæ˜¯ EfficientNet æ¶æ„çš„ä¸€éƒ¨åˆ†ã€‚

    å±æ€§:
        in_chans (int): è¾“å…¥é€šé“æ•°ã€‚
        hidden_chans (int): éšè—é€šé“æ•°ã€‚
        out_chans (int): è¾“å‡ºé€šé“æ•°ã€‚
        conv1 (Conv2d_BN): ç¬¬ä¸€ä¸ªå·ç§¯å±‚ã€‚
        act1 (nn.Module): ç¬¬ä¸€ä¸ªæ¿€æ´»å‡½æ•°ã€‚
        conv2 (Conv2d_BN): æ·±åº¦å·ç§¯å±‚ã€‚
        act2 (nn.Module): ç¬¬äºŒä¸ªæ¿€æ´»å‡½æ•°ã€‚
        conv3 (Conv2d_BN): æœ€åçš„å·ç§¯å±‚ã€‚
        act3 (nn.Module): ç¬¬ä¸‰ä¸ªæ¿€æ´»å‡½æ•°ã€‚
        drop_path (nn.Module): Drop path å±‚ï¼ˆæ¨ç†æ—¶ä¸ºæ’ç­‰æ˜ å°„ï¼‰ã€‚

    æ–¹æ³•:
        forward: æ‰§è¡Œ MBConv å±‚çš„å‰å‘ä¼ æ’­ã€‚

    ç¤ºä¾‹:
        >>> in_chans, out_chans = 32, 64
        >>> mbconv = MBConv(in_chans, out_chans, expand_ratio=4, activation=nn.ReLU, drop_path=0.1)
        >>> x = torch.randn(1, in_chans, 56, 56)
        >>> output = mbconv(x)
        >>> print(output.shape)
        torch.Size([1, 64, 56, 56])
    """

    def __init__(self, in_chans, out_chans, expand_ratio, activation, drop_path):
        """ç”¨æŒ‡å®šçš„è¾“å…¥/è¾“å‡ºé€šé“ã€æ‰©å±•æ¯”ä¾‹å’Œæ¿€æ´»å‡½æ•°åˆå§‹åŒ– MBConv å±‚ã€‚"""
        super().__init__()
        self.in_chans = in_chans
        self.hidden_chans = int(in_chans * expand_ratio)
        self.out_chans = out_chans

        self.conv1 = Conv2d_BN(in_chans, self.hidden_chans, ks=1)
        self.act1 = activation()

        self.conv2 = Conv2d_BN(self.hidden_chans, self.hidden_chans, ks=3, stride=1, pad=1, groups=self.hidden_chans)
        self.act2 = activation()

        self.conv3 = Conv2d_BN(self.hidden_chans, out_chans, ks=1, bn_weight_init=0.0)
        self.act3 = activation()

        # æ³¨æ„ï¼š`DropPath` ä»…åœ¨è®­ç»ƒæ—¶éœ€è¦ã€‚
        # self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
        self.drop_path = nn.Identity()

    def forward(self, x):
        """å®ç° MBConv çš„å‰å‘ä¼ æ’­ï¼Œåº”ç”¨å·ç§¯å’Œè·³è·ƒè¿æ¥ã€‚"""
        shortcut = x
        x = self.conv1(x)
        x = self.act1(x)
        x = self.conv2(x)
        x = self.act2(x)
        x = self.conv3(x)
        x = self.drop_path(x)
        x += shortcut
        return self.act3(x)

1
class PatchMerging(nn.Module):
    """
    åœ¨ç‰¹å¾å›¾ä¸­åˆå¹¶ç›¸é‚»çš„è¡¥ä¸å¹¶æŠ•å½±åˆ°ä¸€ä¸ªæ–°çš„ç»´åº¦ã€‚

    è¯¥ç±»å®ç°äº†ä¸€ä¸ªè¡¥ä¸åˆå¹¶æ“ä½œï¼Œé€šè¿‡ç»„åˆç©ºé—´ä¿¡æ¯å¹¶è°ƒæ•´ç‰¹å¾ç»´åº¦æ¥å®ç°ã€‚å®ƒä½¿ç”¨ä¸€ç³»åˆ—çš„å·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ–æ¥å®Œæˆè¿™ä¸€æ“ä½œã€‚

    å±æ€§è¯´æ˜:
        input_resolution (Tuple[int, int]): è¾“å…¥ç‰¹å¾å›¾çš„åˆ†è¾¨ç‡ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚
        dim (int): è¾“å…¥ç‰¹å¾å›¾çš„ç»´åº¦ã€‚
        out_dim (int): åˆå¹¶å’ŒæŠ•å½±åçš„è¾“å‡ºç»´åº¦ã€‚
        act (nn.Module): å·ç§¯ä¹‹é—´ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ã€‚
        conv1 (Conv2d_BN): ç¬¬ä¸€ä¸ªå·ç§¯å±‚ï¼Œç”¨äºç»´åº¦æŠ•å½±ã€‚
        conv2 (Conv2d_BN): ç¬¬äºŒä¸ªå·ç§¯å±‚ï¼Œç”¨äºç©ºé—´åˆå¹¶ã€‚
        conv3 (Conv2d_BN): ç¬¬ä¸‰ä¸ªå·ç§¯å±‚ï¼Œç”¨äºæœ€ç»ˆçš„æŠ•å½±ã€‚

    æ–¹æ³•è¯´æ˜:
        forward: å°†è¡¥ä¸åˆå¹¶æ“ä½œåº”ç”¨äºè¾“å…¥å¼ é‡ã€‚

    ç¤ºä¾‹ç”¨æ³•:
        >>> input_resolution = (56, 56)
        >>> patch_merging = PatchMerging(input_resolution, dim=64, out_dim=128, activation=nn.ReLU)
        >>> x = torch.randn(4, 64, 56, 56)
        >>> output = patch_merging(x)
        >>> print(output.shape)
    """

    def __init__(self, input_resolution, dim, out_dim, activation):
        """åˆå§‹åŒ– PatchMerging æ¨¡å—ï¼Œç”¨äºåœ¨ç‰¹å¾å›¾ä¸­åˆå¹¶å’ŒæŠ•å½±ç›¸é‚»çš„è¡¥ä¸ã€‚"""
        super().__init__()

        self.input_resolution = input_resolution
        self.dim = dim
        self.out_dim = out_dim
        self.act = activation()
        self.conv1 = Conv2d_BN(dim, out_dim, 1, 1, 0)
        stride_c = 1 if out_dim in {320, 448, 576} else 2
        self.conv2 = Conv2d_BN(out_dim, out_dim, 3, stride_c, 1, groups=out_dim)
        self.conv3 = Conv2d_BN(out_dim, out_dim, 1, 1, 0)

    def forward(self, x):
        """å°†è¡¥ä¸åˆå¹¶å’Œç»´åº¦æŠ•å½±åº”ç”¨äºè¾“å…¥ç‰¹å¾å›¾ã€‚"""
        if x.ndim == 3:
            H, W = self.input_resolution
            B = len(x)
            # (B, C, H, W)
            x = x.view(B, H, W, -1).permute(0, 3, 1, 2)

        x = self.conv1(x)
        x = self.act(x)

        x = self.conv2(x)
        x = self.act(x)
        x = self.conv3(x)
        return x.flatten(2).transpose(1, 2)


class ConvLayer(nn.Module):
    """
    ç‰¹å¾æå–çš„å·ç§¯å±‚ï¼ŒåŒ…å«å¤šä¸ª MobileNetV3 é£æ ¼çš„å€’æ®‹å·®å·ç§¯ï¼ˆMBConvï¼‰ã€‚

    è¯¥å±‚å¯ä»¥é€‰æ‹©æ€§åœ°å¯¹è¾“å‡ºåº”ç”¨ä¸‹é‡‡æ ·æ“ä½œï¼Œå¹¶æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹æŠ€æœ¯ã€‚

    å±æ€§è¯´æ˜:
        dim (int): è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ã€‚
        input_resolution (Tuple[int, int]): è¾“å…¥å›¾åƒçš„åˆ†è¾¨ç‡ã€‚
        depth (int): MBConv å±‚çš„æ•°é‡ã€‚
        use_checkpoint (bool): æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ã€‚
        blocks (nn.ModuleList): MBConv å±‚çš„åˆ—è¡¨ã€‚
        downsample (Optional[Callable]): ç”¨äºä¸‹é‡‡æ ·è¾“å‡ºçš„å‡½æ•°ã€‚

    æ–¹æ³•è¯´æ˜:
        forward: é€šè¿‡å·ç§¯å±‚å¤„ç†è¾“å…¥ã€‚

    ç¤ºä¾‹ç”¨æ³•:
        >>> input_tensor = torch.randn(1, 64, 56, 56)
        >>> conv_layer = ConvLayer(64, (56, 56), depth=3, activation=nn.ReLU)
        >>> output = conv_layer(input_tensor)
        >>> print(output.shape)
    """

    def __init__(
        self,
        dim,
        input_resolution,
        depth,
        activation,
        drop_path=0.0,
        downsample=None,
        use_checkpoint=False,
        out_dim=None,
        conv_expand_ratio=4.0,
    ):
        """
        åˆå§‹åŒ– ConvLayerï¼Œé…ç½®ç»™å®šçš„ç»´åº¦å’Œè®¾ç½®ã€‚

        è¯¥å±‚ç”±å¤šä¸ª MobileNetV3 é£æ ¼çš„å€’æ®‹å·®å·ç§¯ï¼ˆMBConvï¼‰ç»„æˆï¼Œå¹¶å¯ä»¥é€‰æ‹©æ€§åœ°å¯¹è¾“å‡ºåº”ç”¨ä¸‹é‡‡æ ·ã€‚

        å‚æ•°è¯´æ˜:
            dim (int): è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ã€‚
            input_resolution (Tuple[int, int]): è¾“å…¥å›¾åƒçš„åˆ†è¾¨ç‡ã€‚
            depth (int): MBConv å±‚çš„æ•°é‡ã€‚
            activation (Callable): æ¯ä¸ªå·ç§¯åçš„æ¿€æ´»å‡½æ•°ã€‚
            drop_path (float | List[float]): Drop path çš„æ¯”ç‡ã€‚å¯ä»¥æ˜¯å•ä¸€æµ®åŠ¨å€¼ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªæµ®åŠ¨å€¼åˆ—è¡¨ï¼ˆå¯¹åº”æ¯ä¸ªMBConvï¼‰ã€‚
            downsample (Optional[Callable]): ç”¨äºä¸‹é‡‡æ ·è¾“å‡ºçš„å‡½æ•°ã€‚è‹¥ä¸º Noneï¼Œåˆ™è·³è¿‡ä¸‹é‡‡æ ·ã€‚
            use_checkpoint (bool): æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ã€‚
            out_dim (Optional[int]): è¾“å‡ºçš„ç»´åº¦ã€‚è‹¥ä¸º Noneï¼Œåˆ™ä¸ `dim` ç›¸åŒã€‚
            conv_expand_ratio (float): MBConv å±‚çš„æ‰©å±•æ¯”ä¾‹ã€‚

        ç¤ºä¾‹ç”¨æ³•:
            >>> input_tensor = torch.randn(1, 64, 56, 56)
            >>> conv_layer = ConvLayer(64, (56, 56), depth=3, activation=nn.ReLU)
            >>> output = conv_layer(input_tensor)
            >>> print(output.shape)
        """
        super().__init__()
        self.dim = dim
        self.input_resolution = input_resolution
        self.depth = depth
        self.use_checkpoint = use_checkpoint

        # æ„å»º MBConv å±‚
        self.blocks = nn.ModuleList(
            [
                MBConv(
                    dim,
                    dim,
                    conv_expand_ratio,
                    activation,
                    drop_path[i] if isinstance(drop_path, list) else drop_path,
                )
                for i in range(depth)
            ]
        )

        # è¡¥ä¸åˆå¹¶å±‚
        self.downsample = (
            None
            if downsample is None
            else downsample(input_resolution, dim=dim, out_dim=out_dim, activation=activation)
        )

    def forward(self, x):
        """é€šè¿‡å·ç§¯å±‚å¤„ç†è¾“å…¥ï¼Œåº”ç”¨ MBConv å±‚å’Œå¯é€‰çš„ä¸‹é‡‡æ ·æ“ä½œã€‚"""
        for blk in self.blocks:
            x = checkpoint.checkpoint(blk, x) if self.use_checkpoint else blk(x)
        return x if self.downsample is None else self.downsample(x)
1

class Mlp(nn.Module):
    """
    å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¨¡å—ï¼Œç”¨äº transformer æ¶æ„ã€‚

    è¯¥æ¨¡å—åº”ç”¨å±‚å½’ä¸€åŒ–ã€ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼ˆä¸­é—´æœ‰æ¿€æ´»å‡½æ•°ï¼‰ï¼Œå¹¶ä½¿ç”¨ä¸¢å¼ƒå±‚ã€‚é€šå¸¸ç”¨äºåŸºäº Transformer çš„æ¶æ„ä¸­ã€‚

    å±æ€§ï¼š
        norm (nn.LayerNorm): åº”ç”¨äºè¾“å…¥çš„å±‚å½’ä¸€åŒ–ã€‚
        fc1 (nn.Linear): ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ã€‚
        fc2 (nn.Linear): ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ã€‚
        act (nn.Module): åº”ç”¨äºç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚åçš„æ¿€æ´»å‡½æ•°ã€‚
        drop (nn.Dropout): åº”ç”¨äºæ¿€æ´»å‡½æ•°åçš„ä¸¢å¼ƒå±‚ã€‚

    æ–¹æ³•ï¼š
        forward: å¯¹è¾“å…¥å¼ é‡åº”ç”¨ MLP æ“ä½œã€‚

    ç¤ºä¾‹:
        >>> import torch
        >>> from torch import nn
        >>> mlp = Mlp(in_features=256, hidden_features=512, out_features=256, act_layer=nn.GELU, drop=0.1)
        >>> x = torch.randn(32, 100, 256)
        >>> output = mlp(x)
        >>> print(output.shape)
        torch.Size([32, 100, 256])
    """

    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.0):
        """åˆå§‹åŒ–ä¸€ä¸ªå…·æœ‰å¯é…ç½®è¾“å…¥ã€éšè—å’Œè¾“å‡ºç»´åº¦çš„å¤šå±‚æ„ŸçŸ¥å™¨ã€‚"""
        super().__init__()
        out_features = out_features or in_features
        hidden_features = hidden_features or in_features
        self.norm = nn.LayerNorm(in_features)
        self.fc1 = nn.Linear(in_features, hidden_features)
        self.fc2 = nn.Linear(hidden_features, out_features)
        self.act = act_layer()
        self.drop = nn.Dropout(drop)

    def forward(self, x):
        """åº”ç”¨ MLP æ“ä½œï¼šå±‚å½’ä¸€åŒ–ã€å…¨è¿æ¥å±‚ã€æ¿€æ´»å‡½æ•°å’Œä¸¢å¼ƒå±‚ã€‚"""
        x = self.norm(x)
        x = self.fc1(x)
        x = self.act(x)
        x = self.drop(x)
        x = self.fc2(x)
        return self.drop(x)


class Attention(torch.nn.Module):
    """
    å…·æœ‰ç©ºé—´æ„ŸçŸ¥å’Œå¯è®­ç»ƒæ³¨æ„åŠ›åç½®çš„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ã€‚

    è¯¥æ¨¡å—å®ç°äº†ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ”¯æŒç©ºé—´æ„ŸçŸ¥ï¼ŒåŸºäºç©ºé—´åˆ†è¾¨ç‡åº”ç”¨æ³¨æ„åŠ›åç½®ã€‚å®ƒåŒ…æ‹¬æ¯ä¸ªå”¯ä¸€çš„ç©ºé—´ä½ç½®åç§»çš„å¯è®­ç»ƒæ³¨æ„åŠ›åç½®ã€‚

    å±æ€§ï¼š
        num_heads (int): æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€‚
        scale (float): æ³¨æ„åŠ›åˆ†æ•°çš„ç¼©æ”¾å› å­ã€‚
        key_dim (int): é”®ï¼ˆkeyï¼‰å’ŒæŸ¥è¯¢ï¼ˆqueryï¼‰çš„ç»´åº¦ã€‚
        nh_kd (int): æ³¨æ„åŠ›å¤´æ•°å’Œé”®ç»´åº¦çš„ä¹˜ç§¯ã€‚
        d (int): å€¼ï¼ˆvalueï¼‰å‘é‡çš„ç»´åº¦ã€‚
        dh (int): å€¼ç»´åº¦å’Œæ³¨æ„åŠ›å¤´æ•°çš„ä¹˜ç§¯ã€‚
        attn_ratio (float): å½±å“å€¼å‘é‡ç»´åº¦çš„æ³¨æ„åŠ›æ¯”ç‡ã€‚
        norm (nn.LayerNorm): åº”ç”¨äºè¾“å…¥çš„å±‚å½’ä¸€åŒ–ã€‚
        qkv (nn.Linear): ç”¨äºè®¡ç®—æŸ¥è¯¢ã€é”®å’Œå€¼æŠ•å½±çš„çº¿æ€§å±‚ã€‚
        proj (nn.Linear): ç”¨äºæœ€ç»ˆæŠ•å½±çš„çº¿æ€§å±‚ã€‚
        attention_biases (nn.Parameter): å¯å­¦ä¹ çš„æ³¨æ„åŠ›åç½®ã€‚
        attention_bias_idxs (Tensor): æ³¨æ„åŠ›åç½®çš„ç´¢å¼•ã€‚
        ab (Tensor): æ¨ç†è¿‡ç¨‹ä¸­ç¼“å­˜çš„æ³¨æ„åŠ›åç½®ï¼Œè®­ç»ƒæ—¶åˆ é™¤ã€‚

    æ–¹æ³•ï¼š
        train: è®¾ç½®æ¨¡å—ä¸ºè®­ç»ƒæ¨¡å¼å¹¶å¤„ç† 'ab' å±æ€§ã€‚
        forward: æ‰§è¡Œæ³¨æ„åŠ›æœºåˆ¶çš„å‰å‘ä¼ æ’­ã€‚

    ç¤ºä¾‹:
        >>> attn = Attention(dim=256, key_dim=64, num_heads=8, resolution=(14, 14))
        >>> x = torch.randn(1, 196, 256)
        >>> output = attn(x)
        >>> print(output.shape)
        torch.Size([1, 196, 256])
    """

    def __init__(
        self,
        dim,
        key_dim,
        num_heads=8,
        attn_ratio=4,
        resolution=(14, 14),
    ):
        """
        åˆå§‹åŒ–å…·æœ‰ç©ºé—´æ„ŸçŸ¥çš„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ã€‚

        è¯¥æ¨¡å—å®ç°äº†ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ”¯æŒç©ºé—´æ„ŸçŸ¥ï¼ŒåŸºäºç©ºé—´åˆ†è¾¨ç‡åº”ç”¨æ³¨æ„åŠ›åç½®ã€‚å®ƒåŒ…æ‹¬æ¯ä¸ªå”¯ä¸€çš„ç©ºé—´ä½ç½®åç§»çš„å¯è®­ç»ƒæ³¨æ„åŠ›åç½®ã€‚

        å‚æ•°ï¼š
            dim (int): è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ã€‚
            key_dim (int): é”®å’ŒæŸ¥è¯¢çš„ç»´åº¦ã€‚
            num_heads (int): æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼Œé»˜è®¤æ˜¯ 8ã€‚
            attn_ratio (float): æ³¨æ„åŠ›æ¯”ç‡ï¼Œå½±å“å€¼å‘é‡çš„ç»´åº¦ï¼Œé»˜è®¤æ˜¯ 4ã€‚
            resolution (Tuple[int, int]): è¾“å…¥ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œé»˜è®¤æ˜¯ (14, 14)ã€‚

        å¼‚å¸¸ï¼š
            AssertionError: å¦‚æœ 'resolution' ä¸æ˜¯é•¿åº¦ä¸º 2 çš„å…ƒç»„ã€‚

        ç¤ºä¾‹:
            >>> attn = Attention(dim=256, key_dim=64, num_heads=8, resolution=(14, 14))
            >>> x = torch.randn(1, 196, 256)
            >>> output = attn(x)
            >>> print(output.shape)
            torch.Size([1, 196, 256])
        """
        super().__init__()

        assert isinstance(resolution, tuple) and len(resolution) == 2, "'resolution' å‚æ•°ä¸æ˜¯é•¿åº¦ä¸º 2 çš„å…ƒç»„"
        self.num_heads = num_heads
        self.scale = key_dim**-0.5
        self.key_dim = key_dim
        self.nh_kd = nh_kd = key_dim * num_heads
        self.d = int(attn_ratio * key_dim)
        self.dh = int(attn_ratio * key_dim) * num_heads
        self.attn_ratio = attn_ratio
        h = self.dh + nh_kd * 2

        self.norm = nn.LayerNorm(dim)
        self.qkv = nn.Linear(dim, h)
        self.proj = nn.Linear(self.dh, dim)

        points = list(itertools.product(range(resolution[0]), range(resolution[1])))
        N = len(points)
        attention_offsets = {}
        idxs = []
        for p1 in points:
            for p2 in points:
                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))
                if offset not in attention_offsets:
                    attention_offsets[offset] = len(attention_offsets)
                idxs.append(attention_offsets[offset])
        self.attention_biases = torch.nn.Parameter(torch.zeros(num_heads, len(attention_offsets)))
        self.register_buffer("attention_bias_idxs", torch.LongTensor(idxs).view(N, N), persistent=False)

    @torch.no_grad()
    def train(self, mode=True):
        """æ‰§è¡Œå…·æœ‰ç©ºé—´æ„ŸçŸ¥å’Œå¯è®­ç»ƒæ³¨æ„åŠ›åç½®çš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ã€‚"""
        super().train(mode)
        if mode and hasattr(self, "ab"):
            del self.ab
        else:
            self.ab = self.attention_biases[:, self.attention_bias_idxs]

    def forward(self, x):  # x
        """åº”ç”¨å…·æœ‰ç©ºé—´æ„ŸçŸ¥å’Œå¯è®­ç»ƒæ³¨æ„åŠ›åå·®çš„å¤šå¤´è‡ªæ³¨æ„åŠ›ã€‚"""
        B, N, _ = x.shape  # B, N, C

        # å½’ä¸€åŒ–
        x = self.norm(x)

        qkv = self.qkv(x)
        # (B, N, num_heads, d)
        q, k, v = qkv.view(B, N, self.num_heads, -1).split([self.key_dim, self.key_dim, self.d], dim=3)
        # (B, num_heads, N, d)
        q = q.permute(0, 2, 1, 3)
        k = k.permute(0, 2, 1, 3)
        v = v.permute(0, 2, 1, 3)
        self.ab = self.ab.to(self.attention_biases.device)

        attn = (q @ k.transpose(-2, -1)) * self.scale + (
            self.attention_biases[:, self.attention_bias_idxs] if self.training else self.ab
        )
        attn = attn.softmax(dim=-1)
        x = (attn @ v).transpose(1, 2).reshape(B, N, self.dh)
        return self.proj(x)


class TinyViTBlock(nn.Module):
    """
    TinyViT å—ï¼Œåº”ç”¨è‡ªæ³¨æ„åŠ›å’Œå±€éƒ¨å·ç§¯äºè¾“å…¥ã€‚

    è¯¥å—æ˜¯ TinyViT æ¶æ„çš„å…³é”®ç»„ä»¶ï¼Œç»“åˆè‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå±€éƒ¨å·ç§¯ï¼Œ
    é«˜æ•ˆå¤„ç†è¾“å…¥ç‰¹å¾ã€‚

    å±æ€§ï¼š
        dim (int): è¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ã€‚
        input_resolution (Tuple[int, int]): è¾“å…¥ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ã€‚
        num_heads (int): æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€‚
        window_size (int): æ³¨æ„åŠ›çª—å£çš„å¤§å°ã€‚
        mlp_ratio (float): MLP éšè—å±‚ç»´åº¦ä¸åµŒå…¥ç»´åº¦çš„æ¯”ä¾‹ã€‚
        drop_path (nn.Module): éšæœºæ·±åº¦å±‚ï¼Œæ¨ç†æ—¶ä¸ºæ’ç­‰å‡½æ•°ã€‚
        attn (Attention): è‡ªæ³¨æ„åŠ›æ¨¡å—ã€‚
        mlp (Mlp): å¤šå±‚æ„ŸçŸ¥æœºæ¨¡å—ã€‚
        local_conv (Conv2d_BN): æ·±åº¦å·ç§¯çš„å±€éƒ¨å·ç§¯å±‚ã€‚

    æ–¹æ³•ï¼š
        forward: é€šè¿‡ TinyViT å—å¤„ç†è¾“å…¥ã€‚
        extra_repr: è¿”å›åŒ…å«å—å‚æ•°çš„é¢å¤–ä¿¡æ¯çš„å­—ç¬¦ä¸²ã€‚

    ç¤ºä¾‹ï¼š
        >>> input_tensor = torch.randn(1, 196, 192)
        >>> block = TinyViTBlock(dim=192, input_resolution=(14, 14), num_heads=3)
        >>> output = block(input_tensor)
        >>> print(output.shape)
        torch.Size([1, 196, 192])
    """

    def __init__(
        self,
        dim,
        input_resolution,
        num_heads,
        window_size=7,
        mlp_ratio=4.0,
        drop=0.0,
        drop_path=0.0,
        local_conv_size=3,
        activation=nn.GELU,
    ):
        """
        åˆå§‹åŒ– TinyViT å—ï¼ŒåŒ…å«è‡ªæ³¨æ„åŠ›å’Œå±€éƒ¨å·ç§¯ã€‚

        è¯¥å—æ˜¯ TinyViT æ¶æ„çš„å…³é”®ç»„ä»¶ï¼Œç»“åˆè‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå±€éƒ¨å·ç§¯ï¼Œ
        é«˜æ•ˆå¤„ç†è¾“å…¥ç‰¹å¾ã€‚

        å‚æ•°ï¼š
            dim (int): è¾“å…¥å’Œè¾“å‡ºç‰¹å¾çš„ç»´åº¦ã€‚
            input_resolution (Tuple[int, int]): è¾“å…¥ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚
            num_heads (int): æ³¨æ„åŠ›å¤´çš„æ•°é‡ã€‚
            window_size (int): æ³¨æ„åŠ›çª—å£çš„å¤§å°ã€‚å¿…é¡»å¤§äº 0ã€‚
            mlp_ratio (float): MLP éšè—å±‚ç»´åº¦ä¸åµŒå…¥ç»´åº¦çš„æ¯”ä¾‹ã€‚
            drop (float): Dropout æ¯”ä¾‹ã€‚
            drop_path (float): éšæœºæ·±åº¦æ¯”ç‡ã€‚
            local_conv_size (int): å±€éƒ¨å·ç§¯çš„å·ç§¯æ ¸å¤§å°ã€‚
            activation (torch.nn.Module): MLP çš„æ¿€æ´»å‡½æ•°ã€‚

        å¼•å‘ï¼š
            AssertionError: å¦‚æœ window_size ä¸å¤§äº 0ã€‚
            AssertionError: å¦‚æœ dim ä¸èƒ½è¢« num_heads æ•´é™¤ã€‚

        ç¤ºä¾‹ï¼š
            >>> block = TinyViTBlock(dim=192, input_resolution=(14, 14), num_heads=3)
            >>> input_tensor = torch.randn(1, 196, 192)
            >>> output = block(input_tensor)
            >>> print(output.shape)
            torch.Size([1, 196, 192])
        """
        super().__init__()
        self.dim = dim
        self.input_resolution = input_resolution
        self.num_heads = num_heads
        assert window_size > 0, "window_size å¿…é¡»å¤§äº 0"
        self.window_size = window_size
        self.mlp_ratio = mlp_ratio

        # æ³¨æ„ï¼š`DropPath` ä»…åœ¨è®­ç»ƒæ—¶éœ€è¦ã€‚
        # self.drop_path = DropPath(drop_path) å¦‚æœ drop_path > 0. å¦åˆ™ä¸º nn.Identity()
        self.drop_path = nn.Identity()

        assert dim % num_heads == 0, "dim å¿…é¡»èƒ½è¢« num_heads æ•´é™¤"
        head_dim = dim // num_heads

        window_resolution = (window_size, window_size)
        self.attn = Attention(dim, head_dim, num_heads, attn_ratio=1, resolution=window_resolution)

        mlp_hidden_dim = int(dim * mlp_ratio)
        mlp_activation = activation
        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=mlp_activation, drop=drop)

        pad = local_conv_size // 2
        self.local_conv = Conv2d_BN(dim, dim, ks=local_conv_size, stride=1, pad=pad, groups=dim)

    def forward(self, x):
        """åº”ç”¨è‡ªæ³¨æ„åŠ›ã€å±€éƒ¨å·ç§¯å’Œ MLP æ“ä½œåˆ°è¾“å…¥å¼ é‡ä¸Šã€‚"""
        h, w = self.input_resolution
        b, hw, c = x.shape  # batch, height*width, channels
        assert hw == h * w, "è¾“å…¥ç‰¹å¾çš„å°ºå¯¸ä¸æ­£ç¡®"
        res_x = x
        if h == self.window_size and w == self.window_size:
            x = self.attn(x)
        else:
            x = x.view(b, h, w, c)
            pad_b = (self.window_size - h % self.window_size) % self.window_size
            pad_r = (self.window_size - w % self.window_size) % self.window_size
            padding = pad_b > 0 or pad_r > 0
            if padding:
                x = F.pad(x, (0, 0, 0, pad_r, 0, pad_b))

            pH, pW = h + pad_b, w + pad_r
            nH = pH // self.window_size
            nW = pW // self.window_size

            # çª—å£åˆ†å‰²
            x = (
                x.view(b, nH, self.window_size, nW, self.window_size, c)
                .transpose(2, 3)
                .reshape(b * nH * nW, self.window_size * self.window_size, c)
            )
            x = self.attn(x)

            # çª—å£åè½¬
            x = x.view(b, nH, nW, self.window_size, self.window_size, c).transpose(2, 3).reshape(b, pH, pW, c)
            if padding:
                x = x[:, :h, :w].contiguous()

            x = x.view(b, hw, c)

        x = res_x + self.drop_path(x)
        x = x.transpose(1, 2).reshape(b, c, h, w)
        x = self.local_conv(x)
        x = x.view(b, c, hw).transpose(1, 2)

        return x + self.drop_path(self.mlp(x))

    def extra_repr(self) -> str:
        """
        è¿”å› TinyViTBlock å‚æ•°çš„å­—ç¬¦ä¸²è¡¨ç¤ºã€‚

        è¯¥æ–¹æ³•æä¾›äº†ä¸€ä¸ªæ ¼å¼åŒ–çš„å­—ç¬¦ä¸²ï¼ŒåŒ…å« TinyViTBlock çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶ç»´åº¦ã€è¾“å…¥åˆ†è¾¨ç‡ã€æ³¨æ„åŠ›å¤´æ•°ã€çª—å£å¤§å°å’Œ MLP æ¯”ç‡ã€‚

        è¿”å›:
            (str): åŒ…å«å—å‚æ•°çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ã€‚

        ç¤ºä¾‹:
            >>> block = TinyViTBlock(dim=192, input_resolution=(14, 14), num_heads=3, window_size=7, mlp_ratio=4.0)
            >>> print(block.extra_repr())
            dim=192, input_resolution=(14, 14), num_heads=3, window_size=7, mlp_ratio=4.0
        """
        return (
            f"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, "
            f"window_size={self.window_size}, mlp_ratio={self.mlp_ratio}"
        )


class BasicLayer(nn.Module):
    """
    TinyViT æ¶æ„ä¸­çš„åŸºæœ¬å±‚ï¼Œè¡¨ç¤ºä¸€ä¸ªé˜¶æ®µçš„å±‚ã€‚

    è¯¥ç±»è¡¨ç¤º TinyViT æ¨¡å‹ä¸­çš„å•ä¸ªå±‚ï¼Œç”±å¤šä¸ª TinyViT å—å’Œä¸€ä¸ªå¯é€‰çš„ä¸‹é‡‡æ ·æ“ä½œç»„æˆã€‚

    å±æ€§:
        dim (int): è¾“å…¥å’Œè¾“å‡ºç‰¹å¾çš„ç»´åº¦ã€‚
        input_resolution (Tuple[int, int]): è¾“å…¥ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ã€‚
        depth (int): è¯¥å±‚ä¸­çš„ TinyViT å—æ•°ã€‚
        use_checkpoint (bool): æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ã€‚
        blocks (nn.ModuleList): ç»„æˆè¯¥å±‚çš„ TinyViT å—åˆ—è¡¨ã€‚
        downsample (nn.Module | None): å±‚æœ«çš„ä¸‹é‡‡æ ·å±‚ï¼ˆå¦‚æœæŒ‡å®šï¼‰ã€‚

    æ–¹æ³•:
        forward: é€šè¿‡è¯¥å±‚çš„å—å’Œå¯é€‰çš„ä¸‹é‡‡æ ·å¤„ç†è¾“å…¥ã€‚
        extra_repr: è¿”å›åŒ…å«è¯¥å±‚å‚æ•°çš„å­—ç¬¦ä¸²ä»¥ä¾›æ‰“å°ã€‚

    ç¤ºä¾‹:
        >>> input_tensor = torch.randn(1, 3136, 192)
        >>> layer = BasicLayer(dim=192, input_resolution=(56, 56), depth=2, num_heads=3, window_size=7)
        >>> output = layer(input_tensor)
        >>> print(output.shape)
        torch.Size([1, 784, 384])
    """

    def __init__(
        self,
        dim,
        input_resolution,
        depth,
        num_heads,
        window_size,
        mlp_ratio=4.0,
        drop=0.0,
        drop_path=0.0,
        downsample=None,
        use_checkpoint=False,
        local_conv_size=3,
        activation=nn.GELU,
        out_dim=None,
    ):
        """
        åˆå§‹åŒ– TinyViT æ¶æ„ä¸­çš„ BasicLayerã€‚

        è¯¥å±‚ç”±å¤šä¸ª TinyViT å—å’Œä¸€ä¸ªå¯é€‰çš„ä¸‹é‡‡æ ·æ“ä½œç»„æˆï¼Œæ—¨åœ¨å¤„ç†ç‰¹å®šåˆ†è¾¨ç‡å’Œç»´åº¦çš„ç‰¹å¾å›¾ã€‚

        å‚æ•°:
            dim (int): è¾“å…¥å’Œè¾“å‡ºç‰¹å¾çš„ç»´åº¦ã€‚
            input_resolution (Tuple[int, int]): è¾“å…¥ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚
            depth (int): è¯¥å±‚ä¸­çš„ TinyViT å—æ•°ã€‚
            num_heads (int): æ¯ä¸ª TinyViT å—ä¸­çš„æ³¨æ„åŠ›å¤´æ•°ã€‚
            window_size (int): ç”¨äºæ³¨æ„åŠ›è®¡ç®—çš„å±€éƒ¨çª—å£å¤§å°ã€‚
            mlp_ratio (float): MLP éšè—ç»´åº¦ä¸åµŒå…¥ç»´åº¦çš„æ¯”ç‡ã€‚
            drop (float): Dropout æ¯”ä¾‹ã€‚
            drop_path (float | List[float]): éšæœºæ·±åº¦ç‡ã€‚å¯ä»¥æ˜¯ä¸€ä¸ªæµ®åŠ¨å€¼ï¼Œæˆ–æ¯ä¸ªå—çš„æµ®åŠ¨åˆ—è¡¨ã€‚
            downsample (nn.Module | None): è¯¥å±‚æœ«çš„ä¸‹é‡‡æ ·å±‚ã€‚None è¡¨ç¤ºè·³è¿‡ä¸‹é‡‡æ ·ã€‚
            use_checkpoint (bool): æ˜¯å¦ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ã€‚
            local_conv_size (int): æ¯ä¸ª TinyViT å—ä¸­çš„å±€éƒ¨å·ç§¯çš„å·ç§¯æ ¸å¤§å°ã€‚
            activation (nn.Module): ç”¨äº MLP çš„æ¿€æ´»å‡½æ•°ã€‚
            out_dim (int | None): ä¸‹é‡‡æ ·åçš„è¾“å‡ºç»´åº¦ã€‚å¦‚æœä¸º Noneï¼Œåˆ™ä¸ `dim` ç›¸åŒã€‚

        æŠ›å‡º:
            ValueError: å¦‚æœ `drop_path` ä¸ºåˆ—è¡¨ä¸”å…¶é•¿åº¦ä¸ `depth` ä¸åŒ¹é…ã€‚

        ç¤ºä¾‹:
            >>> layer = BasicLayer(dim=96, input_resolution=(56, 56), depth=2, num_heads=3, window_size=7)
            >>> x = torch.randn(1, 56 * 56, 96)
            >>> output = layer(x)
            >>> print(output.shape)
        """
        super().__init__()
        self.dim = dim
        self.input_resolution = input_resolution
        self.depth = depth
        self.use_checkpoint = use_checkpoint

        # æ„å»ºå—
        self.blocks = nn.ModuleList(
            [
                TinyViTBlock(
                    dim=dim,
                    input_resolution=input_resolution,
                    num_heads=num_heads,
                    window_size=window_size,
                    mlp_ratio=mlp_ratio,
                    drop=drop,
                    drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,
                    local_conv_size=local_conv_size,
                    activation=activation,
                )
                for i in range(depth)
            ]
        )

        # è¡¥ä¸åˆå¹¶å±‚
        self.downsample = (
            None
            if downsample is None
            else downsample(input_resolution, dim=dim, out_dim=out_dim, activation=activation)
        )

    def forward(self, x):
        """é€šè¿‡ TinyViT å—å’Œå¯é€‰çš„ä¸‹é‡‡æ ·å¤„ç†è¾“å…¥ã€‚"""
        for blk in self.blocks:
            x = checkpoint.checkpoint(blk, x) if self.use_checkpoint else blk(x)
        return x if self.downsample is None else self.downsample(x)

    def extra_repr(self) -> str:
        """è¿”å›åŒ…å«è¯¥å±‚å‚æ•°çš„å­—ç¬¦ä¸²ï¼Œä»¥ä¾›æ‰“å°ã€‚"""
        return f"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}"


class TinyViT(nn.Module):
    """
    TinyViT: ä¸€ç§ç´§å‡‘çš„è§†è§‰ Transformer æ¶æ„ï¼Œç”¨äºé«˜æ•ˆçš„å›¾åƒåˆ†ç±»å’Œç‰¹å¾æå–ã€‚

    è¯¥ç±»å®ç°äº† TinyViT æ¨¡å‹ï¼Œå®ƒç»“åˆäº†è§†è§‰ Transformer å’Œå·ç§¯ç¥ç»ç½‘ç»œçš„å…ƒç´ ï¼Œä»¥æé«˜è§†è§‰ä»»åŠ¡çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚

    å±æ€§è¯´æ˜:
        img_size (int): è¾“å…¥å›¾åƒçš„å¤§å°ã€‚
        num_classes (int): åˆ†ç±»çš„ç±»åˆ«æ•°ã€‚
        depths (List[int]): æ¯ä¸ªé˜¶æ®µçš„å—æ•°é‡ã€‚
        num_layers (int): ç½‘ç»œä¸­çš„æ€»å±‚æ•°ã€‚
        mlp_ratio (float): MLP éšè—ç»´åº¦ä¸åµŒå…¥ç»´åº¦çš„æ¯”ç‡ã€‚
        patch_embed (PatchEmbed): ç”¨äºè¡¥ä¸åµŒå…¥çš„æ¨¡å—ã€‚
        patches_resolution (Tuple[int, int]): åµŒå…¥è¡¥ä¸çš„åˆ†è¾¨ç‡ã€‚
        layers (nn.ModuleList): ç½‘ç»œå±‚çš„åˆ—è¡¨ã€‚
        norm_head (nn.LayerNorm): ç”¨äºåˆ†ç±»å¤´çš„å±‚å½’ä¸€åŒ–ã€‚
        head (nn.Linear): æœ€ç»ˆåˆ†ç±»çš„çº¿æ€§å±‚ã€‚
        neck (nn.Sequential): ç”¨äºç‰¹å¾ç²¾ç‚¼çš„ Neck æ¨¡å—ã€‚

    æ–¹æ³•è¯´æ˜:
        set_layer_lr_decay: è®¾ç½®æŒ‰å±‚æ¬¡çš„å­¦ä¹ ç‡è¡°å‡ã€‚
        _init_weights: åˆå§‹åŒ–çº¿æ€§å±‚å’Œå½’ä¸€åŒ–å±‚çš„æƒé‡ã€‚
        no_weight_decay_keywords: è¿”å›ä¸ä½¿ç”¨æƒé‡è¡°å‡çš„å‚æ•°å…³é”®å­—ã€‚
        forward_features: é€šè¿‡ç‰¹å¾æå–å±‚å¤„ç†è¾“å…¥ã€‚
        forward: é€šè¿‡æ•´ä¸ªç½‘ç»œè¿›è¡Œå‰å‘ä¼ æ’­ã€‚

    ç¤ºä¾‹ç”¨æ³•:
        >>> model = TinyViT(img_size=224, num_classes=1000)
        >>> x = torch.randn(1, 3, 224, 224)
        >>> features = model.forward_features(x)
        >>> print(features.shape)
        torch.Size([1, 256, 64, 64])
    """

    def __init__(
        self,
        img_size=224,
        in_chans=3,
        num_classes=1000,
        embed_dims=(96, 192, 384, 768),
        depths=(2, 2, 6, 2),
        num_heads=(3, 6, 12, 24),
        window_sizes=(7, 7, 14, 7),
        mlp_ratio=4.0,
        drop_rate=0.0,
        drop_path_rate=0.1,
        use_checkpoint=False,
        mbconv_expand_ratio=4.0,
        local_conv_size=3,
        layer_lr_decay=1.0,
    ):
        """
        åˆå§‹åŒ– TinyViT æ¨¡å‹ã€‚

        è¯¥æ„é€ å‡½æ•°è®¾ç½®äº† TinyViT æ¶æ„ï¼ŒåŒ…æ‹¬è¡¥ä¸åµŒå…¥ã€å¤šä¸ªæ³¨æ„åŠ›å’Œå·ç§¯å—å±‚ï¼Œä»¥åŠåˆ†ç±»å¤´ã€‚

        å‚æ•°è¯´æ˜:
            img_size (int): è¾“å…¥å›¾åƒçš„å¤§å°ï¼Œé»˜è®¤ä¸º 224ã€‚
            in_chans (int): è¾“å…¥é€šé“çš„æ•°é‡ï¼Œé»˜è®¤ä¸º 3ã€‚
            num_classes (int): åˆ†ç±»çš„ç±»åˆ«æ•°ï¼Œé»˜è®¤ä¸º 1000ã€‚
            embed_dims (Tuple[int, int, int, int]): æ¯ä¸ªé˜¶æ®µçš„åµŒå…¥ç»´åº¦ï¼Œé»˜è®¤ä¸º (96, 192, 384, 768)ã€‚
            depths (Tuple[int, int, int, int]): æ¯ä¸ªé˜¶æ®µçš„å—æ•°é‡ï¼Œé»˜è®¤ä¸º (2, 2, 6, 2)ã€‚
            num_heads (Tuple[int, int, int, int]): æ¯ä¸ªé˜¶æ®µçš„æ³¨æ„åŠ›å¤´æ•°ï¼Œé»˜è®¤ä¸º (3, 6, 12, 24)ã€‚
            window_sizes (Tuple[int, int, int, int]): æ¯ä¸ªé˜¶æ®µçš„çª—å£å¤§å°ï¼Œé»˜è®¤ä¸º (7, 7, 14, 7)ã€‚
            mlp_ratio (float): MLP éšè—ç»´åº¦ä¸åµŒå…¥ç»´åº¦çš„æ¯”ç‡ï¼Œé»˜è®¤ä¸º 4.0ã€‚
            drop_rate (float): Dropout æ¯”ç‡ï¼Œé»˜è®¤ä¸º 0.0ã€‚
            drop_path_rate (float): éšæœºæ·±åº¦æ¯”ç‡ï¼Œé»˜è®¤ä¸º 0.1ã€‚
            use_checkpoint (bool): æ˜¯å¦ä½¿ç”¨æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ï¼Œé»˜è®¤ä¸º Falseã€‚
            mbconv_expand_ratio (float): MBConv å±‚çš„æ‰©å±•æ¯”ä¾‹ï¼Œé»˜è®¤ä¸º 4.0ã€‚
            local_conv_size (int): å±€éƒ¨å·ç§¯çš„æ ¸å¤§å°ï¼Œé»˜è®¤ä¸º 3ã€‚
            layer_lr_decay (float): å±‚æ¬¡å­¦ä¹ ç‡è¡°å‡å› å­ï¼Œé»˜è®¤ä¸º 1.0ã€‚

        ç¤ºä¾‹ç”¨æ³•:
            >>> model = TinyViT(img_size=224, num_classes=1000)
            >>> x = torch.randn(1, 3, 224, 224)
            >>> output = model(x)
            >>> print(output.shape)
            torch.Size([1, 1000])
        """
        super().__init__()
        self.img_size = img_size
        self.num_classes = num_classes
        self.depths = depths
        self.num_layers = len(depths)
        self.mlp_ratio = mlp_ratio

        activation = nn.GELU

        self.patch_embed = PatchEmbed(
            in_chans=in_chans, embed_dim=embed_dims[0], resolution=img_size, activation=activation
        )

        patches_resolution = self.patch_embed.patches_resolution
        self.patches_resolution = patches_resolution

        # éšæœºæ·±åº¦
        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # éšæœºæ·±åº¦è¡°å‡è§„åˆ™

        # æ„å»ºå±‚
        self.layers = nn.ModuleList()
        for i_layer in range(self.num_layers):
            kwargs = dict(
                dim=embed_dims[i_layer],
                input_resolution=(
                    patches_resolution[0] // (2 ** (i_layer - 1 if i_layer == 3 else i_layer)),
                    patches_resolution[1] // (2 ** (i_layer - 1 if i_layer == 3 else i_layer)),
                ),
                depth=depths[i_layer],
                drop_path=dpr[sum(depths[:i_layer]) : sum(depths[: i_layer + 1])],
                downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,
                use_checkpoint=use_checkpoint,
                out_dim=embed_dims[min(i_layer + 1, len(embed_dims) - 1)],
                activation=activation,
            )
            if i_layer == 0:
                layer = ConvLayer(conv_expand_ratio=mbconv_expand_ratio, **kwargs)
            else:
                layer = BasicLayer(
                    num_heads=num_heads[i_layer],
                    window_size=window_sizes[i_layer],
                    mlp_ratio=self.mlp_ratio,
                    drop=drop_rate,
                    local_conv_size=local_conv_size,
                    **kwargs,
                )
            self.layers.append(layer)

        # åˆ†ç±»å¤´
        self.norm_head = nn.LayerNorm(embed_dims[-1])
        self.head = nn.Linear(embed_dims[-1], num_classes) if num_classes > 0 else torch.nn.Identity()

        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)
        self.set_layer_lr_decay(layer_lr_decay)
        self.neck = nn.Sequential(
            nn.Conv2d(
                embed_dims[-1],
                256,
                kernel_size=1,
                bias=False,
            ),
            LayerNorm2d(256),
            nn.Conv2d(
                256,
                256,
                kernel_size=3,
                padding=1,
                bias=False,
            ),
            LayerNorm2d(256),
        )

    def set_layer_lr_decay(self, layer_lr_decay):
        """ä¸º TinyViT æ¨¡å‹è®¾ç½®æŒ‰å±‚æ¬¡çš„å­¦ä¹ ç‡è¡°å‡ã€‚"""
        decay_rate = layer_lr_decay

        # å±‚ -> å—ï¼ˆæ·±åº¦ï¼‰
        depth = sum(self.depths)
        lr_scales = [decay_rate ** (depth - i - 1) for i in range(depth)]

        def _set_lr_scale(m, scale):
            """æ ¹æ®å±‚çš„æ·±åº¦ä¸ºæ¨¡å‹ä¸­çš„æ¯ä¸€å±‚è®¾ç½®å­¦ä¹ ç‡ç¼©æ”¾ã€‚"""
            for p in m.parameters():
                p.lr_scale = scale

        self.patch_embed.apply(lambda x: _set_lr_scale(x, lr_scales[0]))
        i = 0
        for layer in self.layers:
            for block in layer.blocks:
                block.apply(lambda x: _set_lr_scale(x, lr_scales[i]))
                i += 1
            if layer.downsample is not None:
                layer.downsample.apply(lambda x: _set_lr_scale(x, lr_scales[i - 1]))
        assert i == depth
        for m in [self.norm_head, self.head]:
            m.apply(lambda x: _set_lr_scale(x, lr_scales[-1]))

        for k, p in self.named_parameters():
            p.param_name = k

        def _check_lr_scale(m):
            """æ£€æŸ¥æ¨¡å—çš„å‚æ•°ä¸­æ˜¯å¦å­˜åœ¨å­¦ä¹ ç‡ç¼©æ”¾å±æ€§ã€‚"""
            for p in m.parameters():
                assert hasattr(p, "lr_scale"), p.param_name

        self.apply(_check_lr_scale)

    @staticmethod
    def _init_weights(m):
        """åˆå§‹åŒ– TinyViT æ¨¡å‹ä¸­çš„çº¿æ€§å±‚å’Œå½’ä¸€åŒ–å±‚çš„æƒé‡ã€‚"""
        if isinstance(m, nn.Linear):
            # æ³¨æ„ï¼šè¿™ä¸ªåˆå§‹åŒ–ä»…åœ¨è®­ç»ƒæ—¶éœ€è¦ã€‚
            # trunc_normal_(m.weight, std=.02)
            if m.bias is not None:
                nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.LayerNorm):
            nn.init.constant_(m.bias, 0)
            nn.init.constant_(m.weight, 1.0)

    @torch.jit.ignore
    def no_weight_decay_keywords(self):
        """è¿”å›ä¸€ç»„ä¸åº”è¯¥ä½¿ç”¨æƒé‡è¡°å‡çš„å‚æ•°å…³é”®è¯ã€‚"""
        return {"attention_biases"}

    def forward_features(self, x):
        """é€šè¿‡ç‰¹å¾æå–å±‚å¤„ç†è¾“å…¥ï¼Œè¿”å›ç©ºé—´ç‰¹å¾ã€‚"""
        x = self.patch_embed(x)  # x è¾“å…¥å½¢çŠ¶ä¸º (N, C, H, W)

        x = self.layers[0](x)
        start_i = 1

        for i in range(start_i, len(self.layers)):
            layer = self.layers[i]
            x = layer(x)
        batch, _, channel = x.shape
        x = x.view(batch, self.patches_resolution[0] // 4, self.patches_resolution[1] // 4, channel)
        x = x.permute(0, 3, 1, 2)
        return self.neck(x)

    def forward(self, x):
        """æ‰§è¡Œ TinyViT æ¨¡å‹çš„å‰å‘ä¼ æ’­ï¼Œä»è¾“å…¥å›¾åƒä¸­æå–ç‰¹å¾ã€‚"""
        return self.forward_features(x)

    def set_imgsz(self, imgsz=[1024, 1024]):
        """
        è®¾ç½®å›¾åƒå°ºå¯¸ï¼Œä½¿æ¨¡å‹å…¼å®¹ä¸åŒçš„å›¾åƒå°ºå¯¸ã€‚

        å‚æ•°ï¼š
            imgsz (Tuple[int, int]): è¾“å…¥å›¾åƒçš„å°ºå¯¸ã€‚
        """
        imgsz = [s // 4 for s in imgsz]
        self.patches_resolution = imgsz
        for i, layer in enumerate(self.layers):
            input_resolution = (
                imgsz[0] // (2 ** (i - 1 if i == 3 else i)),
                imgsz[1] // (2 ** (i - 1 if i == 3 else i)),
            )
            layer.input_resolution = input_resolution
            if layer.downsample is not None:
                layer.downsample.input_resolution = input_resolution
            if isinstance(layer, BasicLayer):
                for b in layer.blocks:
                    b.input_resolution = input_resolution
