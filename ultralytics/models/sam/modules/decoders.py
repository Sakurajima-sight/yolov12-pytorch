# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from typing import List, Optional, Tuple, Type

import torch
from torch import nn

from ultralytics.nn.modules import MLP, LayerNorm2d


class MaskDecoder(nn.Module):
    """
    ç”¨äºç”Ÿæˆæ©ç åŠå…¶ç›¸å…³è´¨é‡è¯„åˆ†çš„è§£ç æ¨¡å—ï¼Œé‡‡ç”¨ Transformer æ¶æ„ã€‚

    è¯¥ç±»æ¥æ”¶å›¾åƒå’Œæç¤ºçš„åµŒå…¥ï¼Œé€šè¿‡ Transformer è¿›è¡Œå¤„ç†ï¼Œä»è€Œé¢„æµ‹æ©ç å’Œç›¸åº”çš„è´¨é‡åˆ†æ•°ã€‚

    å±æ€§:
        transformer_dim (int): Transformer æ¨¡å—çš„é€šé“ç»´åº¦ã€‚
        transformer (nn.Module): ç”¨äºæ©ç é¢„æµ‹çš„ Transformer æ¨¡å—ã€‚
        num_multimask_outputs (int): ç”¨äºæ©ç æ­§ä¹‰æ¶ˆè§£æ—¶éœ€è¦é¢„æµ‹çš„æ©ç æ•°é‡ã€‚
        iou_token (nn.Embedding): ç”¨äº IoUï¼ˆäº¤å¹¶æ¯”ï¼‰è¯„åˆ†çš„åµŒå…¥ã€‚
        num_mask_tokens (int): æ©ç  token çš„æ•°é‡ã€‚
        mask_tokens (nn.Embedding): æ©ç  token çš„åµŒå…¥ã€‚
        output_upscaling (nn.Sequential): ç”¨äºä¸Šé‡‡æ ·è¾“å‡ºçš„ç¥ç»ç½‘ç»œæ¨¡å—ã€‚
        output_hypernetworks_mlps (nn.ModuleList): ç”¨äºç”Ÿæˆæ©ç çš„è¶…ç½‘ç»œ MLP åˆ—è¡¨ã€‚
        iou_prediction_head (nn.Module): ç”¨äºé¢„æµ‹æ©ç è´¨é‡ï¼ˆIoU åˆ†æ•°ï¼‰çš„ MLP æ¨¡å—ã€‚

    æ–¹æ³•:
        forward: ç»™å®šå›¾åƒå’Œæç¤ºåµŒå…¥åè¿›è¡Œæ©ç é¢„æµ‹ã€‚
        predict_masks: æ©ç é¢„æµ‹çš„å†…éƒ¨æ–¹æ³•ã€‚

    ç¤ºä¾‹:
        >>> decoder = MaskDecoder(transformer_dim=256, transformer=transformer_module)
        >>> masks, iou_pred = decoder(
        ...     image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, multimask_output=True
        ... )
        >>> print(f"Predicted masks shape: {masks.shape}, IoU predictions shape: {iou_pred.shape}")
    """

    def __init__(
        self,
        transformer_dim: int,
        transformer: nn.Module,
        num_multimask_outputs: int = 3,
        activation: Type[nn.Module] = nn.GELU,
        iou_head_depth: int = 3,
        iou_head_hidden_dim: int = 256,
    ) -> None:
        """
        åˆå§‹åŒ– MaskDecoder æ¨¡å—ï¼Œç”¨äºç”Ÿæˆæ©ç åŠå…¶è´¨é‡åˆ†æ•°ã€‚

        å‚æ•°:
            transformer_dim (int): Transformer æ¨¡å—çš„é€šé“ç»´åº¦ã€‚
            transformer (nn.Module): ç”¨äºæ©ç é¢„æµ‹çš„ Transformer æ¨¡å—ã€‚
            num_multimask_outputs (int): ç”¨äºæ©ç æ­§ä¹‰å¤„ç†æ—¶è¦è¾“å‡ºçš„æ©ç æ•°é‡ã€‚
            activation (Type[nn.Module]): ç”¨äºä¸Šé‡‡æ ·é˜¶æ®µçš„æ¿€æ´»å‡½æ•°ç±»å‹ã€‚
            iou_head_depth (int): ç”¨äºé¢„æµ‹æ©ç è´¨é‡çš„ MLP çš„æ·±åº¦ã€‚
            iou_head_hidden_dim (int): ç”¨äºé¢„æµ‹æ©ç è´¨é‡çš„ MLP çš„éšè—å±‚ç»´åº¦ã€‚

        ç¤ºä¾‹:
            >>> transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=256, nhead=8), num_layers=6)
            >>> decoder = MaskDecoder(transformer_dim=256, transformer=transformer)
            >>> print(decoder)
        """
        super().__init__()
        self.transformer_dim = transformer_dim
        self.transformer = transformer

        self.num_multimask_outputs = num_multimask_outputs

        self.iou_token = nn.Embedding(1, transformer_dim)
        self.num_mask_tokens = num_multimask_outputs + 1
        self.mask_tokens = nn.Embedding(self.num_mask_tokens, transformer_dim)

        self.output_upscaling = nn.Sequential(
            nn.ConvTranspose2d(transformer_dim, transformer_dim // 4, kernel_size=2, stride=2),
            LayerNorm2d(transformer_dim // 4),
            activation(),
            nn.ConvTranspose2d(transformer_dim // 4, transformer_dim // 8, kernel_size=2, stride=2),
            activation(),
        )
        self.output_hypernetworks_mlps = nn.ModuleList(
            [MLP(transformer_dim, transformer_dim, transformer_dim // 8, 3) for _ in range(self.num_mask_tokens)]
        )

        self.iou_prediction_head = MLP(transformer_dim, iou_head_hidden_dim, self.num_mask_tokens, iou_head_depth)

    def forward(
        self,
        image_embeddings: torch.Tensor,
        image_pe: torch.Tensor,
        sparse_prompt_embeddings: torch.Tensor,
        dense_prompt_embeddings: torch.Tensor,
        multimask_output: bool,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ ¹æ®å›¾åƒå’Œæç¤ºåµŒå…¥é¢„æµ‹æ©ç ã€‚

        å‚æ•°:
            image_embeddings (torch.Tensor): æ¥è‡ªå›¾åƒç¼–ç å™¨çš„å›¾åƒåµŒå…¥ã€‚
            image_pe (torch.Tensor): ä¸ image_embeddings å½¢çŠ¶ç›¸åŒçš„ä½ç½®ç¼–ç ã€‚
            sparse_prompt_embeddings (torch.Tensor): ç‚¹å’Œæ¡†çš„æç¤ºåµŒå…¥ã€‚
            dense_prompt_embeddings (torch.Tensor): æ©ç æç¤ºçš„ç¨ å¯†åµŒå…¥ã€‚
            multimask_output (bool): æ˜¯å¦è¾“å‡ºå¤šä¸ªæ©ç ï¼ˆç”¨äºæ©ç æ­§ä¹‰æ¶ˆè§£ï¼‰ã€‚

        è¿”å›:
            Tuple[torch.Tensor, torch.Tensor]: è¿”å›ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
                - masks (torch.Tensor): æ‰¹å¤„ç†çš„é¢„æµ‹æ©ç ã€‚
                - iou_pred (torch.Tensor): æ‰¹å¤„ç†çš„æ©ç è´¨é‡é¢„æµ‹ç»“æœï¼ˆIoU åˆ†æ•°ï¼‰ã€‚

        ç¤ºä¾‹:
            >>> decoder = MaskDecoder(transformer_dim=256, transformer=transformer_module)
            >>> image_emb = torch.rand(1, 256, 64, 64)
            >>> image_pe = torch.rand(1, 256, 64, 64)
            >>> sparse_emb = torch.rand(1, 2, 256)
            >>> dense_emb = torch.rand(1, 256, 64, 64)
            >>> masks, iou_pred = decoder(image_emb, image_pe, sparse_emb, dense_emb, multimask_output=True)
            >>> print(f"Masks shape: {masks.shape}, IoU predictions shape: {iou_pred.shape}")
        """
        masks, iou_pred = self.predict_masks(
            image_embeddings=image_embeddings,
            image_pe=image_pe,
            sparse_prompt_embeddings=sparse_prompt_embeddings,
            dense_prompt_embeddings=dense_prompt_embeddings,
        )

        # æ ¹æ®æ˜¯å¦å¯ç”¨å¤šæ©ç è¾“å‡ºï¼Œé€‰æ‹©å¯¹åº”çš„æ©ç åˆ‡ç‰‡
        mask_slice = slice(1, None) if multimask_output else slice(0, 1)
        masks = masks[:, mask_slice, :, :]
        iou_pred = iou_pred[:, mask_slice]

        # è¿”å›è¾“å‡ºç»“æœ
        return masks, iou_pred

    def predict_masks(
        self,
        image_embeddings: torch.Tensor,
        image_pe: torch.Tensor,
        sparse_prompt_embeddings: torch.Tensor,
        dense_prompt_embeddings: torch.Tensor,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """é€šè¿‡ Transformer æ¶æ„ï¼Œä½¿ç”¨å›¾åƒå’Œæç¤ºåµŒå…¥é¢„æµ‹æ©ç å’Œè´¨é‡å¾—åˆ†ã€‚"""
        
        # æ‹¼æ¥è¾“å‡º token
        output_tokens = torch.cat([self.iou_token.weight, self.mask_tokens.weight], dim=0)
        output_tokens = output_tokens.unsqueeze(0).expand(sparse_prompt_embeddings.shape[0], -1, -1)
        tokens = torch.cat((output_tokens, sparse_prompt_embeddings), dim=1)

        # åœ¨ batch ç»´åº¦ä¸Šæ‰©å±•æ¯å¼ å›¾åƒçš„æ•°æ®ï¼Œä»¥é€‚é…æ¯ä¸ªæ©ç çš„å¤„ç†
        src = torch.repeat_interleave(image_embeddings, tokens.shape[0], dim=0)
        src = src + dense_prompt_embeddings
        pos_src = torch.repeat_interleave(image_pe, tokens.shape[0], dim=0)
        b, c, h, w = src.shape

        # è¾“å…¥ Transformer æ¨¡å‹è¿›è¡Œå¤„ç†
        hs, src = self.transformer(src, pos_src, tokens)
        iou_token_out = hs[:, 0, :]
        mask_tokens_out = hs[:, 1 : (1 + self.num_mask_tokens), :]

        # å¯¹æ©ç åµŒå…¥è¿›è¡Œä¸Šé‡‡æ ·ï¼Œå¹¶ä½¿ç”¨æ©ç  token é¢„æµ‹æ©ç 
        src = src.transpose(1, 2).view(b, c, h, w)
        upscaled_embedding = self.output_upscaling(src)
        hyper_in_list: List[torch.Tensor] = [
            self.output_hypernetworks_mlps[i](mask_tokens_out[:, i, :]) for i in range(self.num_mask_tokens)
        ]
        hyper_in = torch.stack(hyper_in_list, dim=1)
        b, c, h, w = upscaled_embedding.shape
        masks = (hyper_in @ upscaled_embedding.view(b, c, h * w)).view(b, -1, h, w)

        # ç”Ÿæˆæ©ç è´¨é‡çš„é¢„æµ‹ç»“æœ
        iou_pred = self.iou_prediction_head(iou_token_out)

        return masks, iou_pred


class SAM2MaskDecoder(nn.Module):
    """
    åŸºäº Transformer çš„è§£ç å™¨ï¼Œç”¨äºä»å›¾åƒå’Œæç¤ºåµŒå…¥ä¸­é¢„æµ‹å®ä¾‹åˆ†å‰²æ©ç ã€‚

    è¯¥ç±»æ‰©å±•äº† MaskDecoder çš„åŠŸèƒ½ï¼Œé›†æˆäº†è¯¸å¦‚é«˜åˆ†è¾¨ç‡ç‰¹å¾å¤„ç†ã€åŠ¨æ€å¤šæ©ç è¾“å‡ºã€
    å¯¹è±¡å¾—åˆ†é¢„æµ‹ç­‰é™„åŠ ç‰¹æ€§ã€‚

    å±æ€§è¯´æ˜:
        transformer_dim (int): Transformer çš„é€šé“ç»´åº¦ã€‚
        transformer (nn.Module): ç”¨äºæ©ç é¢„æµ‹çš„ Transformer æ¨¡å—ã€‚
        num_multimask_outputs (int): åœ¨å¤šæ©ç åˆ¤æ­§æ—¶æ‰€é¢„æµ‹çš„æ©ç æ•°é‡ã€‚
        iou_token (nn.Embedding): IOU token çš„åµŒå…¥è¡¨ç¤ºã€‚
        num_mask_tokens (int): æ©ç  token çš„æ€»æ•°é‡ã€‚
        mask_tokens (nn.Embedding): æ©ç  token çš„åµŒå…¥è¡¨ç¤ºã€‚
        pred_obj_scores (bool): æ˜¯å¦é¢„æµ‹å¯¹è±¡å¾—åˆ†ã€‚
        obj_score_token (nn.Embedding): å¯¹è±¡å¾—åˆ† token çš„åµŒå…¥è¡¨ç¤ºã€‚
        use_multimask_token_for_obj_ptr (bool): æ˜¯å¦ä½¿ç”¨å¤šæ©ç  token ä½œä¸ºå¯¹è±¡æŒ‡é’ˆã€‚
        output_upscaling (nn.Sequential): è¾“å‡ºä¸Šé‡‡æ ·å±‚ã€‚
        use_high_res_features (bool): æ˜¯å¦ä½¿ç”¨é«˜åˆ†è¾¨ç‡ç‰¹å¾ã€‚
        conv_s0 (nn.Conv2d): ç”¨äºå¤„ç†é«˜åˆ†è¾¨ç‡ç‰¹å¾ï¼ˆå°ºåº¦ s0ï¼‰çš„å·ç§¯å±‚ã€‚
        conv_s1 (nn.Conv2d): ç”¨äºå¤„ç†é«˜åˆ†è¾¨ç‡ç‰¹å¾ï¼ˆå°ºåº¦ s1ï¼‰çš„å·ç§¯å±‚ã€‚
        output_hypernetworks_mlps (nn.ModuleList): è¾“å‡ºè¶…ç½‘ç»œä½¿ç”¨çš„ MLP åˆ—è¡¨ã€‚
        iou_prediction_head (MLP): IOU é¢„æµ‹ç”¨çš„å¤šå±‚æ„ŸçŸ¥æœºã€‚
        pred_obj_score_head (nn.Linear | MLP): å¯¹è±¡å¾—åˆ†é¢„æµ‹çš„çº¿æ€§å±‚æˆ– MLPã€‚
        dynamic_multimask_via_stability (bool): æ˜¯å¦åŸºäºç¨³å®šæ€§åŠ¨æ€é€‰æ‹©å¤šæ©ç ã€‚
        dynamic_multimask_stability_delta (float): å¤šæ©ç ç¨³å®šæ€§åˆ¤æ–­çš„ delta å€¼ã€‚
        dynamic_multimask_stability_thresh (float): å¤šæ©ç ç¨³å®šæ€§çš„é˜ˆå€¼ã€‚

    æ–¹æ³•è¯´æ˜:
        forward: ç»™å®šå›¾åƒå’Œæç¤ºåµŒå…¥ï¼Œé¢„æµ‹æ©ç ã€‚
        predict_masks: ä»å›¾åƒå’Œæç¤ºåµŒå…¥ä¸­é¢„æµ‹å®ä¾‹åˆ†å‰²æ©ç ã€‚
        _get_stability_scores: è®¡ç®—ä¸åŒé˜ˆå€¼é—´ IoU å¾—åˆ†ä»¥è¯„ä¼°æ©ç ç¨³å®šæ€§ã€‚
        _dynamic_multimask_via_stability: åŠ¨æ€é€‰æ‹©æœ€ç¨³å®šçš„æ©ç è¾“å‡ºã€‚

    ç¤ºä¾‹ç”¨æ³•:
        >>> image_embeddings = torch.rand(1, 256, 64, 64)
        >>> image_pe = torch.rand(1, 256, 64, 64)
        >>> sparse_prompt_embeddings = torch.rand(1, 2, 256)
        >>> dense_prompt_embeddings = torch.rand(1, 256, 64, 64)
        >>> decoder = SAM2MaskDecoder(256, transformer)
        >>> masks, iou_pred, sam_tokens_out, obj_score_logits = decoder.forward(
        ...     image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, True, False
        ... )
    """

def __init__(
    self,
    transformer_dim: int,
    transformer: nn.Module,
    num_multimask_outputs: int = 3,
    activation: Type[nn.Module] = nn.GELU,
    iou_head_depth: int = 3,
    iou_head_hidden_dim: int = 256,
    use_high_res_features: bool = False,
    iou_prediction_use_sigmoid=False,
    dynamic_multimask_via_stability=False,
    dynamic_multimask_stability_delta=0.05,
    dynamic_multimask_stability_thresh=0.98,
    pred_obj_scores: bool = False,
    pred_obj_scores_mlp: bool = False,
    use_multimask_token_for_obj_ptr: bool = False,
) -> None:
    """
    åˆå§‹åŒ– SAM2MaskDecoder æ¨¡å—ï¼Œç”¨äºé¢„æµ‹å®ä¾‹åˆ†å‰²æ©ç ã€‚

    è¯¥è§£ç å™¨åœ¨åŸå§‹ MaskDecoder çš„åŸºç¡€ä¸Šè¿›è¡Œäº†æ‰©å±•ï¼Œå¢åŠ äº†é«˜åˆ†è¾¨ç‡ç‰¹å¾å¤„ç†ã€
    åŠ¨æ€å¤šæ©ç è¾“å‡ºå’Œç›®æ ‡å¾—åˆ†é¢„æµ‹ç­‰åŠŸèƒ½ã€‚

    å‚æ•°è¯´æ˜:
        transformer_dim (int): Transformer çš„é€šé“ç»´åº¦ã€‚
        transformer (nn.Module): ç”¨äºé¢„æµ‹æ©ç çš„ Transformer æ¨¡å—ã€‚
        num_multimask_outputs (int): åœ¨æ©ç æ­§ä¹‰æ—¶ç”Ÿæˆçš„æ©ç æ•°é‡ã€‚
        activation (Type[nn.Module]): åœ¨ä¸Šé‡‡æ ·æ©ç æ—¶æ‰€ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ç±»å‹ã€‚
        iou_head_depth (int): ç”¨äºé¢„æµ‹æ©ç è´¨é‡çš„ MLP æ·±åº¦ã€‚
        iou_head_hidden_dim (int): ç”¨äºé¢„æµ‹æ©ç è´¨é‡çš„ MLP çš„éšè—å±‚ç»´åº¦ã€‚
        use_high_res_features (bool): æ˜¯å¦ä½¿ç”¨é«˜åˆ†è¾¨ç‡ç‰¹å¾ã€‚
        iou_prediction_use_sigmoid (bool): æ˜¯å¦å¯¹ IOU é¢„æµ‹ä½¿ç”¨ Sigmoid æ¿€æ´»ã€‚
        dynamic_multimask_via_stability (bool): æ˜¯å¦å¯ç”¨é€šè¿‡ç¨³å®šæ€§åˆ†æ•°çš„åŠ¨æ€å¤šæ©ç æœºåˆ¶ã€‚
        dynamic_multimask_stability_delta (float): ç”¨äºåˆ¤æ–­æ©ç ç¨³å®šæ€§çš„å¢é‡é˜ˆå€¼ã€‚
        dynamic_multimask_stability_thresh (float): æ©ç ç¨³å®šæ€§çš„åˆ¤æ–­é˜ˆå€¼ã€‚
        pred_obj_scores (bool): æ˜¯å¦é¢„æµ‹ç›®æ ‡å¾—åˆ†ã€‚
        pred_obj_scores_mlp (bool): æ˜¯å¦é€šè¿‡ MLP ç»“æ„æ¥é¢„æµ‹ç›®æ ‡å¾—åˆ†ã€‚
        use_multimask_token_for_obj_ptr (bool): æ˜¯å¦åœ¨ç›®æ ‡æŒ‡é’ˆä¸­ä½¿ç”¨å¤šæ©ç  tokenã€‚

    ä½¿ç”¨ç¤ºä¾‹:
        >>> transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=256, nhead=8), num_layers=6)
        >>> decoder = SAM2MaskDecoder(transformer_dim=256, transformer=transformer)
        >>> print(decoder)
    """
    super().__init__()
    self.transformer_dim = transformer_dim
    self.transformer = transformer

    self.num_multimask_outputs = num_multimask_outputs

    # ç”¨äº IOU é¢„æµ‹çš„åµŒå…¥ token
    self.iou_token = nn.Embedding(1, transformer_dim)
    self.num_mask_tokens = num_multimask_outputs + 1
    self.mask_tokens = nn.Embedding(self.num_mask_tokens, transformer_dim)

    self.pred_obj_scores = pred_obj_scores
    if self.pred_obj_scores:
        # å¦‚æœéœ€è¦é¢„æµ‹ç›®æ ‡å¾—åˆ†ï¼Œåˆ™æ·»åŠ ç›®æ ‡å¾—åˆ† token
        self.obj_score_token = nn.Embedding(1, transformer_dim)
    self.use_multimask_token_for_obj_ptr = use_multimask_token_for_obj_ptr

    # æ©ç ç‰¹å¾çš„ä¸Šé‡‡æ ·æ¨¡å—
    self.output_upscaling = nn.Sequential(
        nn.ConvTranspose2d(transformer_dim, transformer_dim // 4, kernel_size=2, stride=2),
        LayerNorm2d(transformer_dim // 4),
        activation(),
        nn.ConvTranspose2d(transformer_dim // 4, transformer_dim // 8, kernel_size=2, stride=2),
        activation(),
    )

    self.use_high_res_features = use_high_res_features
    if use_high_res_features:
        # å½“å¯ç”¨é«˜åˆ†è¾¨ç‡ç‰¹å¾æ—¶ï¼Œæ·»åŠ é¢å¤–å·ç§¯å±‚å°†å…¶å¯¹é½ç»´åº¦
        self.conv_s0 = nn.Conv2d(transformer_dim, transformer_dim // 8, kernel_size=1, stride=1)
        self.conv_s1 = nn.Conv2d(transformer_dim, transformer_dim // 4, kernel_size=1, stride=1)

    # æ¯ä¸ªæ©ç  token å¯¹åº”ä¸€ä¸ª hypernetwork çš„ MLPï¼Œç”¨äºä» token ç”Ÿæˆæ©ç å‚æ•°
    self.output_hypernetworks_mlps = nn.ModuleList(
        [MLP(transformer_dim, transformer_dim, transformer_dim // 8, 3) for _ in range(self.num_mask_tokens)]
    )

    # ç”¨äºé¢„æµ‹æ©ç è´¨é‡ï¼ˆå¦‚ IOUï¼‰çš„ MLP å¤´
    self.iou_prediction_head = MLP(
        transformer_dim,
        iou_head_hidden_dim,
        self.num_mask_tokens,
        iou_head_depth,
        sigmoid=iou_prediction_use_sigmoid,
    )

    if self.pred_obj_scores:
        # å¯é€‰ç›®æ ‡å¾—åˆ†é¢„æµ‹æ¨¡å—ï¼ˆçº¿æ€§æˆ– MLPï¼‰
        self.pred_obj_score_head = nn.Linear(transformer_dim, 1)
        if pred_obj_scores_mlp:
            self.pred_obj_score_head = MLP(transformer_dim, transformer_dim, 1, 3)

    # å¦‚æœä»…è¾“å‡ºå•ä¸€æ©ç ï¼Œå¯ä»¥åœ¨ç¨³å®šæ€§åˆ†æ•°è¿‡ä½æ—¶åŠ¨æ€å›é€€è‡³æœ€ç¨³å®šçš„å¤šæ©ç  token
    self.dynamic_multimask_via_stability = dynamic_multimask_via_stability
    self.dynamic_multimask_stability_delta = dynamic_multimask_stability_delta
    self.dynamic_multimask_stability_thresh = dynamic_multimask_stability_thresh

    def forward(
        self,
        image_embeddings: torch.Tensor,
        image_pe: torch.Tensor,
        sparse_prompt_embeddings: torch.Tensor,
        dense_prompt_embeddings: torch.Tensor,
        multimask_output: bool,
        repeat_image: bool,
        high_res_features: Optional[List[torch.Tensor]] = None,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ç»™å®šå›¾åƒå’Œæç¤ºçš„åµŒå…¥ï¼Œé¢„æµ‹åˆ†å‰²æ©ç ã€‚

        å‚æ•°:
            image_embeddings (torch.Tensor): æ¥è‡ªå›¾åƒç¼–ç å™¨çš„å›¾åƒåµŒå…¥ï¼Œå½¢çŠ¶ä¸º (B, C, H, W)ã€‚
            image_pe (torch.Tensor): ä½ç½®ç¼–ç ï¼Œä¸ image_embeddings å½¢çŠ¶ç›¸åŒ (B, C, H, W)ã€‚
            sparse_prompt_embeddings (torch.Tensor): ç¨€ç–æç¤ºï¼ˆå¦‚ç‚¹å’Œæ¡†ï¼‰çš„åµŒå…¥ï¼Œå½¢çŠ¶ä¸º (B, N, C)ã€‚
            dense_prompt_embeddings (torch.Tensor): å¯†é›†æç¤ºï¼ˆå¦‚æ©ç ï¼‰çš„åµŒå…¥ï¼Œå½¢çŠ¶ä¸º (B, C, H, W)ã€‚
            multimask_output (bool): æ˜¯å¦è¾“å‡ºå¤šä¸ªæ©ç ã€‚
            repeat_image (bool): æ˜¯å¦é‡å¤å›¾åƒåµŒå…¥ï¼ˆç”¨äºæ‰¹æ¬¡ç»´åº¦æ‰©å±•ï¼‰ã€‚
            high_res_features (List[torch.Tensor] | None): å¯é€‰çš„é«˜åˆ†è¾¨ç‡ç‰¹å¾ã€‚

        è¿”å›:
            (Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]): è¿”å›ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ï¼š
                - masks (torch.Tensor): æ‰¹æ¬¡é¢„æµ‹çš„æ©ç ï¼Œå½¢çŠ¶ä¸º (B, N, H, W)ã€‚
                - iou_pred (torch.Tensor): æ©ç è´¨é‡çš„é¢„æµ‹ç»“æœï¼Œå½¢çŠ¶ä¸º (B, N)ã€‚
                - sam_tokens_out (torch.Tensor): ç”¨äºæ©ç è¾“å‡ºçš„ SAM tokenï¼Œå½¢çŠ¶ä¸º (B, N, C)ã€‚
                - object_score_logits (torch.Tensor): å¯¹è±¡å¾—åˆ†çš„ logitsï¼Œå½¢çŠ¶ä¸º (B, 1)ã€‚

        ç¤ºä¾‹:
            >>> image_embeddings = torch.rand(1, 256, 64, 64)
            >>> image_pe = torch.rand(1, 256, 64, 64)
            >>> sparse_prompt_embeddings = torch.rand(1, 2, 256)
            >>> dense_prompt_embeddings = torch.rand(1, 256, 64, 64)
            >>> decoder = SAM2MaskDecoder(256, transformer)
            >>> masks, iou_pred, sam_tokens_out, obj_score_logits = decoder.forward(
            ...     image_embeddings, image_pe, sparse_prompt_embeddings, dense_prompt_embeddings, True, False
            ... )
        """
        masks, iou_pred, mask_tokens_out, object_score_logits = self.predict_masks(
            image_embeddings=image_embeddings,
            image_pe=image_pe,
            sparse_prompt_embeddings=sparse_prompt_embeddings,
            dense_prompt_embeddings=dense_prompt_embeddings,
            repeat_image=repeat_image,
            high_res_features=high_res_features,
        )

        # æ ¹æ® multimask_output å‚æ•°é€‰æ‹©æ­£ç¡®çš„æ©ç 
        if multimask_output:
            masks = masks[:, 1:, :, :]
            iou_pred = iou_pred[:, 1:]
        elif self.dynamic_multimask_via_stability and not self.training:
            masks, iou_pred = self._dynamic_multimask_via_stability(masks, iou_pred)
        else:
            masks = masks[:, 0:1, :, :]
            iou_pred = iou_pred[:, 0:1]

        if multimask_output and self.use_multimask_token_for_obj_ptr:
            sam_tokens_out = mask_tokens_out[:, 1:]  # å½¢çŠ¶ [b, 3, c]
        else:
            # é€‰æ‹©æ©ç è¾“å‡ºçš„ tokenã€‚åœ¨è¿™é‡Œæˆ‘ä»¬æ€»æ˜¯ä½¿ç”¨å•ä¸ªæ©ç è¾“å‡ºçš„ tokenã€‚
            # åœ¨æµ‹è¯•é˜¶æ®µï¼Œå³ä½¿å¯ç”¨äº† multimask_output=Trueï¼ˆä¾‹å¦‚å•å‡»åè¿½è¸ªï¼‰ï¼Œ
            # æˆ‘ä»¬ä»ç„¶å–å•ä¸ªæ©ç  tokenã€‚è¿™æ˜¯å› ä¸ºåœ¨è®­ç»ƒæ—¶æˆ‘ä»¬é€šå¸¸æ˜¯å¤šæ¬¡ç‚¹å‡»çš„è¿½è¸ªè®­ç»ƒï¼Œ
            # æ‰€ä»¥å†å² token å§‹ç»ˆæ˜¯å•æ©ç  tokenï¼ˆæˆ‘ä»¬ä¼šå°†å…¶è§†ä¸º object-memory tokenï¼‰ã€‚
            sam_tokens_out = mask_tokens_out[:, 0:1]  # å½¢çŠ¶ [b, 1, c]

        # è¿”å›æœ€ç»ˆè¾“å‡º
        return masks, iou_pred, sam_tokens_out, object_score_logits


    def predict_masks(
        self,
        image_embeddings: torch.Tensor,
        image_pe: torch.Tensor,
        sparse_prompt_embeddings: torch.Tensor,
        dense_prompt_embeddings: torch.Tensor,
        repeat_image: bool,
        high_res_features: Optional[List[torch.Tensor]] = None,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """ä½¿ç”¨ Transformer ä»å›¾åƒå’Œæç¤ºåµŒå…¥ä¸­é¢„æµ‹å®ä¾‹åˆ†å‰²æ©ç ã€‚"""
        
        # æ‹¼æ¥è¾“å‡ºç”¨çš„ token
        s = 0
        if self.pred_obj_scores:
            output_tokens = torch.cat(
                [
                    self.obj_score_token.weight,  # å¯¹è±¡å¾—åˆ† token
                    self.iou_token.weight,        # IOU é¢„æµ‹ token
                    self.mask_tokens.weight,      # æ©ç  token
                ],
                dim=0,
            )
            s = 1
        else:
            output_tokens = torch.cat([self.iou_token.weight, self.mask_tokens.weight], dim=0)

        # å°† token æ‰©å±•åˆ° batch ç»´åº¦
        output_tokens = output_tokens.unsqueeze(0).expand(sparse_prompt_embeddings.size(0), -1, -1)
        tokens = torch.cat((output_tokens, sparse_prompt_embeddings), dim=1)

        # å¦‚æœéœ€è¦ï¼Œåœ¨ batch ç»´åº¦ä¸Šå¤åˆ¶å›¾åƒåµŒå…¥ï¼ˆæŒ‰ token é‡å¤ï¼‰
        if repeat_image:
            src = torch.repeat_interleave(image_embeddings, tokens.shape[0], dim=0)
        else:
            assert image_embeddings.shape[0] == tokens.shape[0]
            src = image_embeddings
        src = src + dense_prompt_embeddings

        # éªŒè¯ä½ç½®ç¼–ç çš„ batch ç»´åº¦
        assert image_pe.size(0) == 1, "image_pe çš„ batch ç»´åº¦åº”ä¸º 1ï¼ˆç”± get_dense_pe() æä¾›ï¼‰"
        pos_src = torch.repeat_interleave(image_pe, tokens.shape[0], dim=0)
        b, c, h, w = src.shape

        # è¿è¡Œ Transformer
        hs, src = self.transformer(src, pos_src, tokens)
        iou_token_out = hs[:, s, :]  # IOU token çš„è¾“å‡º
        mask_tokens_out = hs[:, s + 1 : (s + 1 + self.num_mask_tokens), :]  # æ©ç  token çš„è¾“å‡º

        # å°†åµŒå…¥ä¸Šé‡‡æ ·ï¼Œå¹¶ä½¿ç”¨æ©ç  token é¢„æµ‹æ©ç 
        src = src.transpose(1, 2).view(b, c, h, w)
        if not self.use_high_res_features:
            upscaled_embedding = self.output_upscaling(src)
        else:
            dc1, ln1, act1, dc2, act2 = self.output_upscaling
            feat_s0, feat_s1 = high_res_features
            upscaled_embedding = act1(ln1(dc1(src) + feat_s1))
            upscaled_embedding = act2(dc2(upscaled_embedding) + feat_s0)

        # ä½¿ç”¨è¶…ç½‘ç»œï¼ˆhypernetworkï¼‰ç”Ÿæˆæ©ç é¢„æµ‹æƒé‡
        hyper_in_list: List[torch.Tensor] = [
            self.output_hypernetworks_mlps[i](mask_tokens_out[:, i, :]) for i in range(self.num_mask_tokens)
        ]
        hyper_in = torch.stack(hyper_in_list, dim=1)
        b, c, h, w = upscaled_embedding.shape
        masks = (hyper_in @ upscaled_embedding.view(b, c, h * w)).view(b, -1, h, w)

        # ç”Ÿæˆæ©ç è´¨é‡é¢„æµ‹ï¼ˆIOUï¼‰
        iou_pred = self.iou_prediction_head(iou_token_out)
        if self.pred_obj_scores:
            assert s == 1
            object_score_logits = self.pred_obj_score_head(hs[:, 0, :])
        else:
            # å¯¹è±¡å¾—åˆ† logits â€”â€” é»˜è®¤è®¾ä¸º 10.0ï¼Œå‡è®¾å¯¹è±¡ä¸€å®šå­˜åœ¨ï¼Œsigmoid(10)=1
            object_score_logits = 10.0 * iou_pred.new_ones(iou_pred.shape[0], 1)

        return masks, iou_pred, mask_tokens_out, object_score_logits

    def _get_stability_scores(self, mask_logits):
        """æ ¹æ®ä¸Šé™å’Œä¸‹é™é˜ˆå€¼ä¹‹é—´çš„ IoU è®¡ç®—æ©ç ç¨³å®šæ€§è¯„åˆ†ã€‚"""
        mask_logits = mask_logits.flatten(-2)
        stability_delta = self.dynamic_multimask_stability_delta
        area_i = torch.sum(mask_logits > stability_delta, dim=-1).float()
        area_u = torch.sum(mask_logits > -stability_delta, dim=-1).float()
        return torch.where(area_u > 0, area_i / area_u, 1.0)

    def _dynamic_multimask_via_stability(self, all_mask_logits, all_iou_scores):
        """
        åŸºäºç¨³å®šæ€§è¯„åˆ†å’Œ IoU é¢„æµ‹åŠ¨æ€é€‰æ‹©æœ€ç¨³å®šçš„æ©ç è¾“å‡ºã€‚

        è¯¥æ–¹æ³•åœ¨è¾“å‡ºå•ä¸€æ©ç æ—¶ä½¿ç”¨ã€‚å¦‚æœå½“å‰å•ä¸€æ©ç è¾“å‡ºçš„ç¨³å®šæ€§è¯„åˆ†ï¼ˆåŸºäºè¾“å‡º token 0ï¼‰ä½äºé˜ˆå€¼ï¼Œ
        åˆ™ä»å¤šæ©ç è¾“å‡ºï¼ˆåŸºäºè¾“å‡º token 1-3ï¼‰ä¸­é€‰æ‹©å…·æœ‰æœ€é«˜é¢„æµ‹ IoU åˆ†æ•°çš„æ©ç ã€‚è¿™æ ·å¯ä»¥ç¡®ä¿åœ¨ç‚¹å‡»å’Œè¿½è¸ªåœºæ™¯ä¸­è·å¾—æœ‰æ•ˆçš„æ©ç ã€‚

        å‚æ•°:
            all_mask_logits (torch.Tensor): æ‰€æœ‰é¢„æµ‹æ©ç çš„ logitsï¼Œå½¢çŠ¶ä¸º (B, N, H, W)ï¼Œå…¶ä¸­ B æ˜¯æ‰¹é‡å¤§å°ï¼ŒN æ˜¯æ©ç æ•°é‡ï¼ˆé€šå¸¸ä¸º 4ï¼‰ï¼ŒH å’Œ W æ˜¯æ©ç çš„ç»´åº¦ã€‚
            all_iou_scores (torch.Tensor): æ‰€æœ‰æ©ç çš„é¢„æµ‹ IoU åˆ†æ•°ï¼Œå½¢çŠ¶ä¸º (B, N)ã€‚

        è¿”å›:
            (Tuple[torch.Tensor, torch.Tensor]):
                - mask_logits_out (torch.Tensor): é€‰ä¸­çš„æ©ç  logitsï¼Œå½¢çŠ¶ä¸º (B, 1, H, W)ã€‚
                - iou_scores_out (torch.Tensor): é€‰ä¸­çš„ IoU åˆ†æ•°ï¼Œå½¢çŠ¶ä¸º (B, 1)ã€‚

        ç¤ºä¾‹:
            >>> decoder = SAM2MaskDecoder(...)
            >>> all_mask_logits = torch.rand(2, 4, 256, 256)  # 2 å¼ å›¾åƒï¼Œæ¯å¼ å›¾åƒ 4 ä¸ªæ©ç 
            >>> all_iou_scores = torch.rand(2, 4)
            >>> mask_logits, iou_scores = decoder._dynamic_multimask_via_stability(all_mask_logits, all_iou_scores)
            >>> print(mask_logits.shape, iou_scores.shape)
            torch.Size([2, 1, 256, 256]) torch.Size([2, 1])
        """
        # ä»å¤šæ©ç è¾“å‡º tokenï¼ˆ1~3ï¼‰ä¸­é€‰æ‹©æœ€ä½³æ©ç 
        multimask_logits = all_mask_logits[:, 1:, :, :]
        multimask_iou_scores = all_iou_scores[:, 1:]
        best_scores_inds = torch.argmax(multimask_iou_scores, dim=-1)
        batch_inds = torch.arange(multimask_iou_scores.size(0), device=all_iou_scores.device)
        best_multimask_logits = multimask_logits[batch_inds, best_scores_inds]
        best_multimask_logits = best_multimask_logits.unsqueeze(1)
        best_multimask_iou_scores = multimask_iou_scores[batch_inds, best_scores_inds]
        best_multimask_iou_scores = best_multimask_iou_scores.unsqueeze(1)

        # æ¥è‡ªå•ä¸€æ©ç è¾“å‡º token 0 åŠå…¶ç¨³å®šæ€§è¯„åˆ†
        singlemask_logits = all_mask_logits[:, 0:1, :, :]
        singlemask_iou_scores = all_iou_scores[:, 0:1]
        stability_scores = self._get_stability_scores(singlemask_logits)
        is_stable = stability_scores >= self.dynamic_multimask_stability_thresh

        # å¦‚æœç¨³å®šæ€§è¯„åˆ†è¾ƒä½ï¼Œåˆ™åŠ¨æ€å›é€€åˆ°æœ€ä½³å¤šæ©ç è¾“å‡ºã€‚
        mask_logits_out = torch.where(
            is_stable[..., None, None].expand_as(singlemask_logits),
            singlemask_logits,
            best_multimask_logits,
        )
        iou_scores_out = torch.where(
            is_stable.expand_as(singlemask_iou_scores),
            singlemask_iou_scores,
            best_multimask_iou_scores,
        )
        return mask_logits_out, iou_scores_out
