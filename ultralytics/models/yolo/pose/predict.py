# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from ultralytics.engine.results import Results
from ultralytics.models.yolo.detect.predict import DetectionPredictor
from ultralytics.utils import DEFAULT_CFG, LOGGER, ops


class PosePredictor(DetectionPredictor):
    """
    åŸºäºå§¿æ€ä¼°è®¡æ¨¡å‹çš„é¢„æµ‹å™¨ç±»ï¼Œç»§æ‰¿è‡ª DetectionPredictorã€‚

    ç¤ºä¾‹ï¼š
        ```python
        from ultralytics.utils import ASSETS
        from ultralytics.models.yolo.pose import PosePredictor

        args = dict(model="yolov8n-pose.pt", source=ASSETS)
        predictor = PosePredictor(overrides=args)
        predictor.predict_cli()
        ```
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """åˆå§‹åŒ– PosePredictorï¼Œå°†ä»»åŠ¡ç±»å‹è®¾ç½®ä¸º 'pose'ï¼Œå¹¶åœ¨è®¾å¤‡ä¸º 'mps' æ—¶ç»™å‡ºè­¦å‘Šä¿¡æ¯ã€‚"""
        super().__init__(cfg, overrides, _callbacks)
        self.args.task = "pose"  # è®¾ç½®ä»»åŠ¡ä¸ºå§¿æ€ä¼°è®¡
        if isinstance(self.args.device, str) and self.args.device.lower() == "mps":
            LOGGER.warning(
                "âš ï¸ è­¦å‘Šï¼šApple MPS å­˜åœ¨å·²çŸ¥çš„ Pose æ¨¡å‹ bugï¼Œå»ºè®®ä½¿ç”¨ 'device=cpu'ã€‚"
                "è¯¦æƒ…å‚è§ï¼šhttps://github.com/ultralytics/ultralytics/issues/4031ã€‚"
            )

    def postprocess(self, preds, img, orig_imgs):
        """å¯¹è¾“å…¥å›¾åƒæˆ–å›¾åƒåˆ—è¡¨çš„é¢„æµ‹ç»“æœè¿›è¡Œåå¤„ç†ï¼Œå¹¶è¿”å›æ£€æµ‹ç»“æœã€‚"""
        preds = ops.non_max_suppression(
            preds,
            self.args.conf,                # ç½®ä¿¡åº¦é˜ˆå€¼
            self.args.iou,                 # IOU é˜ˆå€¼
            agnostic=self.args.agnostic_nms,  # æ˜¯å¦ç±»åˆ«æ— å…³çš„NMS
            max_det=self.args.max_det,     # æœ€å¤§æ£€æµ‹ç›®æ ‡æ•°
            classes=self.args.classes,     # é™å®šæ£€æµ‹çš„ç±»åˆ«
            nc=len(self.model.names),      # ç±»åˆ«æ€»æ•°
        )

        # å¦‚æœåŸå§‹å›¾åƒä¸æ˜¯åˆ—è¡¨ï¼ˆè¯´æ˜æ˜¯Tensoræ ¼å¼ï¼‰ï¼Œè½¬æ¢ä¸ºNumPyæ•°ç»„æ ¼å¼
        if not isinstance(orig_imgs, list):
            orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)

        results = []
        for pred, orig_img, img_path in zip(preds, orig_imgs, self.batch[0]):
            # å°†é¢„æµ‹æ¡†ä»æ¨¡å‹è¾“å…¥å¤§å°æ˜ å°„å›åŸå›¾å¤§å°ï¼Œå¹¶å››èˆäº”å…¥ä¸ºæ•´æ•°åƒç´ 
            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], orig_img.shape).round()
            # æå–å…³é”®ç‚¹ä¿¡æ¯å¹¶è°ƒæ•´å¤§å°
            pred_kpts = pred[:, 6:].view(len(pred), *self.model.kpt_shape) if len(pred) else pred[:, 6:]
            pred_kpts = ops.scale_coords(img.shape[2:], pred_kpts, orig_img.shape)
            # æ„é€ ç»“æœå¯¹è±¡å¹¶æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            results.append(
                Results(orig_img, path=img_path, names=self.model.names, boxes=pred[:, :6], keypoints=pred_kpts)
            )
        return results
