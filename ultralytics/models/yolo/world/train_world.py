# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from ultralytics.data import YOLOConcatDataset, build_grounding, build_yolo_dataset
from ultralytics.data.utils import check_det_dataset
from ultralytics.models.yolo.world import WorldTrainer
from ultralytics.utils import DEFAULT_CFG
from ultralytics.utils.torch_utils import de_parallel


class WorldTrainerFromScratch(WorldTrainer):
    """
    ä¸€ä¸ªç»§æ‰¿è‡ª WorldTrainer çš„è®­ç»ƒå™¨ç±»ï¼Œç”¨äºåœ¨å¼€æ”¾é›†æ•°æ®é›†ä¸Šä»é›¶å¼€å§‹è®­ç»ƒ YOLO-World æ¨¡å‹ã€‚

    ç¤ºä¾‹ï¼š
        ```python
        from ultralytics.models.yolo.world.train_world import WorldTrainerFromScratch
        from ultralytics import YOLOWorld

        data = dict(
            train=dict(
                yolo_data=["Objects365.yaml"],
                grounding_data=[
                    dict(
                        img_path="../datasets/flickr30k/images",
                        json_file="../datasets/flickr30k/final_flickr_separateGT_train.json",
                    ),
                    dict(
                        img_path="../datasets/GQA/images",
                        json_file="../datasets/GQA/final_mixed_train_no_coco.json",
                    ),
                ],
            ),
            val=dict(yolo_data=["lvis.yaml"]),
        )

        model = YOLOWorld("yolov8s-worldv2.yaml")
        model.train(data=data, trainer=WorldTrainerFromScratch)
        ```
    """

    def __init__(self, cfg=DEFAULT_CFG, overrides=None, _callbacks=None):
        """ä½¿ç”¨æŒ‡å®šå‚æ•°åˆå§‹åŒ– WorldTrainer å®ä¾‹ã€‚"""
        if overrides is None:
            overrides = {}
        super().__init__(cfg, overrides, _callbacks)

    def build_dataset(self, img_path, mode="train", batch=None):
        """
        æ„å»º YOLO æ•°æ®é›†ã€‚

        å‚æ•°ï¼š
            img_path (List[str] | str): åŒ…å«å›¾åƒçš„è·¯å¾„ã€‚
            mode (str): æ¨¡å¼ä¸º `train` æˆ– `val`ï¼Œæ”¯æŒä¸ºä¸åŒæ¨¡å¼å®šåˆ¶ä¸åŒçš„æ•°æ®å¢å¼ºæ–¹å¼ã€‚
            batch (int, optional): æ‰¹å¤§å°ï¼Œç”¨äº `rect` é•¿å®½æ¯”æ’åˆ—æ¨¡å¼ï¼Œé»˜è®¤å€¼ä¸º Noneã€‚
        """
        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)
        if mode != "train":
            return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == "val", stride=gs)
        dataset = [
            build_yolo_dataset(self.args, im_path, batch, self.data, stride=gs, multi_modal=True)
            if isinstance(im_path, str)
            else build_grounding(self.args, im_path["img_path"], im_path["json_file"], batch, stride=gs)
            for im_path in img_path
        ]
        return YOLOConcatDataset(dataset) if len(dataset) > 1 else dataset[0]

    def get_dataset(self):
        """
        ä» data å­—å…¸ä¸­æå– train å’Œ val è·¯å¾„ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ã€‚

        å¦‚æœæ•°æ®æ ¼å¼ä¸ç¬¦åˆé¢„æœŸï¼Œå°†è¿”å› Noneã€‚
        """
        final_data = {}
        data_yaml = self.args.data
        assert data_yaml.get("train", False), "æœªæ‰¾åˆ°è®­ç»ƒé›†é…ç½®ï¼ˆtrain dataset not foundï¼‰"  # å¦‚ object365.yaml
        assert data_yaml.get("val", False), "æœªæ‰¾åˆ°éªŒè¯é›†é…ç½®ï¼ˆvalidation dataset not foundï¼‰"  # å¦‚ lvis.yaml
        data = {k: [check_det_dataset(d) for d in v.get("yolo_data", [])] for k, v in data_yaml.items()}
        assert len(data["val"]) == 1, f"å½“å‰ä»…æ”¯æŒä¸€ä¸ªéªŒè¯é›†ï¼Œä½†æ¥æ”¶åˆ° {len(data['val'])} ä¸ªã€‚"
        val_split = "minival" if "lvis" in data["val"][0]["val"] else "val"
        for d in data["val"]:
            if d.get("minival") is None:  # é’ˆå¯¹ lvis æ•°æ®é›†
                continue
            d["minival"] = str(d["path"] / d["minival"])
        for s in ["train", "val"]:
            final_data[s] = [d["train" if s == "train" else val_split] for d in data[s]]
            # å¦‚æœå­˜åœ¨ grounding æ•°æ®åˆ™ä¿å­˜
            grounding_data = data_yaml[s].get("grounding_data")
            if grounding_data is None:
                continue
            grounding_data = grounding_data if isinstance(grounding_data, list) else [grounding_data]
            for g in grounding_data:
                assert isinstance(g, dict), f"Grounding æ•°æ®åº”ä¸ºå­—å…¸æ ¼å¼ï¼Œä½†å¾—åˆ°çš„æ˜¯ {type(g)}"
            final_data[s] += grounding_data
        # æ³¨æ„ï¼šä¸ºç¡®ä¿è®­ç»ƒæµç¨‹æ­£å¸¸ï¼Œå¿…é¡»è®¾ç½®ç±»åˆ«æ•°é‡ `nc` å’Œç±»åˆ«åç§° `names`
        final_data["nc"] = data["val"][0]["nc"]
        final_data["names"] = data["val"][0]["names"]
        self.data = final_data
        return final_data["train"], final_data["val"][0]

    def plot_training_labels(self):
        """ä¸ç»˜åˆ¶è®­ç»ƒæ ‡ç­¾å›¾ï¼ˆè·³è¿‡è¯¥æ­¥éª¤ï¼‰ã€‚"""
        pass

    def final_eval(self):
        """æ‰§è¡Œ YOLO-World æ¨¡å‹çš„æœ€ç»ˆè¯„ä¼°å’ŒéªŒè¯è¿‡ç¨‹ã€‚"""
        val = self.args.data["val"]["yolo_data"][0]
        self.validator.args.data = val
        self.validator.args.split = "minival" if isinstance(val, str) and "lvis" in val else "val"
        return super().final_eval()
