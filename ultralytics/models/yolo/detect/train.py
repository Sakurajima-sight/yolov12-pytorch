# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import math
import random
from copy import copy

import numpy as np
import torch.nn as nn

from ultralytics.data import build_dataloader, build_yolo_dataset
from ultralytics.engine.trainer import BaseTrainer
from ultralytics.models import yolo
from ultralytics.nn.tasks import DetectionModel
from ultralytics.utils import LOGGER, RANK
from ultralytics.utils.plotting import plot_images, plot_labels, plot_results
from ultralytics.utils.torch_utils import de_parallel, torch_distributed_zero_first


class DetectionTrainer(BaseTrainer):
    """
    ä¸€ä¸ªç”¨äºåŸºäºæ£€æµ‹æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„ç±»ï¼Œç»§æ‰¿è‡ª BaseTrainerã€‚

    ç¤ºä¾‹ï¼š
        ```python
        from ultralytics.models.yolo.detect import DetectionTrainer

        args = dict(model="yolo11n.pt", data="coco8.yaml", epochs=3)
        trainer = DetectionTrainer(overrides=args)
        trainer.train()
        ```
    """

    def build_dataset(self, img_path, mode="train", batch=None):
        """
        æ„å»º YOLO æ•°æ®é›†ã€‚

        å‚æ•°ï¼š
            img_path (str): åŒ…å«å›¾åƒçš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
            mode (str): æ¨¡å¼ï¼Œ"train" æˆ– "val"ï¼Œç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰æ¯ç§æ¨¡å¼çš„æ•°æ®å¢å¼ºã€‚
            batch (int, optional): æ‰¹æ¬¡å¤§å°ï¼Œç”¨äºå¯ç”¨ `rect` æ¨¡å¼æ—¶ã€‚é»˜è®¤å€¼ä¸º Noneã€‚
        """
        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)
        return build_yolo_dataset(self.args, img_path, batch, self.data, mode=mode, rect=mode == "val", stride=gs)

    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode="train"):
        """æ„å»ºå¹¶è¿”å› dataloaderã€‚"""
        assert mode in {"train", "val"}, f"æ¨¡å¼å¿…é¡»ä¸º 'train' æˆ– 'val'ï¼Œå½“å‰ä¸º {mode}ã€‚"
        with torch_distributed_zero_first(rank):  # å¦‚æœä½¿ç”¨ DDPï¼Œåˆ™åªåˆå§‹åŒ–ä¸€æ¬¡ .cache æ–‡ä»¶
            dataset = self.build_dataset(dataset_path, mode, batch_size)
        shuffle = mode == "train"
        if getattr(dataset, "rect", False) and shuffle:
            LOGGER.warning("âš ï¸ è­¦å‘Šï¼šå½“ rect=True æ—¶ä¸ Dataloader çš„ shuffle ä¸å…¼å®¹ï¼Œè‡ªåŠ¨è®¾ç½® shuffle=False")
            shuffle = False
        workers = self.args.workers if mode == "train" else self.args.workers * 2
        return build_dataloader(dataset, batch_size, workers, shuffle, rank)  # è¿”å› dataloader

    def preprocess_batch(self, batch):
        """å¯¹å›¾åƒæ‰¹æ¬¡è¿›è¡Œé¢„å¤„ç†ï¼šç¼©æ”¾å¹¶è½¬æ¢ä¸º floatã€‚"""
        batch["img"] = batch["img"].to(self.device, non_blocking=True).float() / 255
        if self.args.multi_scale:
            imgs = batch["img"]
            sz = (
                random.randrange(int(self.args.imgsz * 0.5), int(self.args.imgsz * 1.5 + self.stride))
                // self.stride
                * self.stride
            )  # æ–°çš„è¾“å…¥å°ºå¯¸
            sf = sz / max(imgs.shape[2:])  # ç¼©æ”¾å› å­
            if sf != 1:
                ns = [
                    math.ceil(x * sf / self.stride) * self.stride for x in imgs.shape[2:]
                ]  # æ–°å½¢çŠ¶ï¼ˆæ‰©å±•ä¸º stride çš„å€æ•°ï¼‰
                imgs = nn.functional.interpolate(imgs, size=ns, mode="bilinear", align_corners=False)
            batch["img"] = imgs
        return batch

    def set_model_attributes(self):
        """è®¾ç½®æ¨¡å‹çš„åŸºæœ¬å±æ€§ï¼Œå¦‚ç±»åˆ«æ•°é‡ã€ç±»åˆ«åç§°ã€è®­ç»ƒå‚æ•°ç­‰ã€‚"""
        # Nl = de_parallel(self.model).model[-1].nl  # æ£€æµ‹å¤´æ•°é‡ï¼ˆç”¨äºç¼©æ”¾è¶…å‚ï¼‰
        # self.args.box *= 3 / nl  # æ ¹æ®å±‚æ•°ç¼©æ”¾ box æŸå¤±
        # self.args.cls *= self.data["nc"] / 80 * 3 / nl  # æ ¹æ®ç±»åˆ«æ•°å’Œå±‚æ•°ç¼©æ”¾ cls æŸå¤±
        # self.args.cls *= (self.args.imgsz / 640) ** 2 * 3 / nl  # æ ¹æ®å›¾åƒå°ºå¯¸å’Œå±‚æ•°ç¼©æ”¾ cls æŸå¤±
        self.model.nc = self.data["nc"]  # å°†ç±»åˆ«æ•°é™„åŠ åˆ°æ¨¡å‹ä¸Š
        self.model.names = self.data["names"]  # å°†ç±»åˆ«åç§°é™„åŠ åˆ°æ¨¡å‹ä¸Š
        self.model.args = self.args  # å°†è®­ç»ƒå‚æ•°é™„åŠ åˆ°æ¨¡å‹ä¸Š
        # TODO: self.model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc

    def get_model(self, cfg=None, weights=None, verbose=True):
        """è¿”å›ä¸€ä¸ª YOLO æ£€æµ‹æ¨¡å‹ã€‚"""
        model = DetectionModel(cfg, nc=self.data["nc"], verbose=verbose and RANK == -1)
        if weights:
            model.load(weights)
        return model

    def get_validator(self):
        """è¿”å› YOLO æ¨¡å‹çš„ DetectionValidator ç”¨äºéªŒè¯è¯„ä¼°ã€‚"""
        self.loss_names = "box_loss", "cls_loss", "dfl_loss"
        return yolo.detect.DetectionValidator(
            self.test_loader, save_dir=self.save_dir, args=copy(self.args), _callbacks=self.callbacks
        )

    def label_loss_items(self, loss_items=None, prefix="train"):
        """
        è¿”å›ä¸€ä¸ªå¸¦æ ‡ç­¾çš„è®­ç»ƒæŸå¤±é¡¹å­—å…¸ã€‚

        åˆ†ç±»ä»»åŠ¡ä¸éœ€è¦ï¼Œä½†æ£€æµ‹å’Œåˆ†å‰²ä»»åŠ¡éœ€è¦ã€‚
        """
        keys = [f"{prefix}/{x}" for x in self.loss_names]
        if loss_items is not None:
            loss_items = [round(float(x), 5) for x in loss_items]  # å°† tensor è½¬æ¢ä¸ºä¿ç•™äº”ä½å°æ•°çš„ float
            return dict(zip(keys, loss_items))
        else:
            return keys

    def progress_string(self):
        """è¿”å›ä¸€ä¸ªæ ¼å¼åŒ–çš„è®­ç»ƒè¿›åº¦å­—ç¬¦ä¸²ï¼ŒåŒ…å« epochã€GPU ä½¿ç”¨ã€lossã€ç›®æ ‡æ•°ã€å›¾åƒå°ºå¯¸ç­‰ä¿¡æ¯ã€‚"""
        return ("\n" + "%11s" * (4 + len(self.loss_names))) % (
            "Epoch",
            "GPU_mem",
            *self.loss_names,
            "Instances",
            "Size",
        )

    def plot_training_samples(self, batch, ni):
        """ç»˜åˆ¶è®­ç»ƒæ ·æœ¬åŠå…¶æ ‡æ³¨ä¿¡æ¯ã€‚"""
        plot_images(
            images=batch["img"],
            batch_idx=batch["batch_idx"],
            cls=batch["cls"].squeeze(-1),
            bboxes=batch["bboxes"],
            paths=batch["im_file"],
            fname=self.save_dir / f"train_batch{ni}.jpg",
            on_plot=self.on_plot,
        )

    def plot_metrics(self):
        """æ ¹æ® CSV æ–‡ä»¶ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡å›¾ã€‚"""
        plot_results(file=self.csv, on_plot=self.on_plot)  # ä¿å­˜ç»“æœå›¾ results.png

    def plot_training_labels(self):
        """åˆ›å»ºä¸€ä¸ªå¸¦æœ‰æ ‡æ³¨ä¿¡æ¯çš„è®­ç»ƒæ ‡ç­¾å¯è§†åŒ–å›¾ï¼Œç”¨äºå±•ç¤º YOLO æ¨¡å‹è®­ç»ƒæ•°æ®åˆ†å¸ƒã€‚"""
        boxes = np.concatenate([lb["bboxes"] for lb in self.train_loader.dataset.labels], 0)
        cls = np.concatenate([lb["cls"] for lb in self.train_loader.dataset.labels], 0)
        plot_labels(boxes, cls.squeeze(), names=self.data["names"], save_dir=self.save_dir, on_plot=self.on_plot)

    def auto_batch(self):
        """æ ¹æ®æ¨¡å‹æ˜¾å­˜å ç”¨è‡ªåŠ¨ä¼°ç®—æœ€ä¼˜æ‰¹é‡å¤§å°ã€‚"""
        train_dataset = self.build_dataset(self.trainset, mode="train", batch=16)
        # ä½¿ç”¨ mosaic æ•°æ®å¢å¼ºæ—¶éœ€è¦ä¹˜ä»¥ 4
        max_num_obj = max(len(label["cls"]) for label in train_dataset.labels) * 4
        return super().auto_batch(max_num_obj)
