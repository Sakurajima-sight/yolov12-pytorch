# Ultralytics ğŸš€ AGPL-3.0 è®¸å¯è¯ - https://ultralytics.com/license

import re
import shutil
import subprocess
from itertools import repeat
from multiprocessing.pool import ThreadPool
from pathlib import Path
from urllib import parse, request

import requests
import torch

from ultralytics.utils import LOGGER, TQDM, checks, clean_url, emojis, is_online, url2file

# å®šä¹‰ Ultralytics GitHub çš„èµ„äº§èµ„æºä»“åº“ï¼Œç»´æŠ¤åœ¨ https://github.com/ultralytics/assets
GITHUB_ASSETS_REPO = "ultralytics/assets"
GITHUB_ASSETS_NAMES = (
    [f"yolov8{k}{suffix}.pt" for k in "nsmlx" for suffix in ("", "-cls", "-seg", "-pose", "-obb", "-oiv7")]
    + [f"yolo11{k}{suffix}.pt" for k in "nsmlx" for suffix in ("", "-cls", "-seg", "-pose", "-obb")]
    + [f"yolov5{k}{resolution}u.pt" for k in "nsmlx" for resolution in ("", "6")]
    + [f"yolov3{k}u.pt" for k in ("", "-spp", "-tiny")]
    + [f"yolov8{k}-world.pt" for k in "smlx"]
    + [f"yolov8{k}-worldv2.pt" for k in "smlx"]
    + [f"yolov9{k}.pt" for k in "tsmce"]
    + [f"yolov10{k}.pt" for k in "nsmblx"]
    + [f"yolo_nas_{k}.pt" for k in "sml"]
    + [f"sam_{k}.pt" for k in "bl"]
    + [f"FastSAM-{k}.pt" for k in "sx"]
    + [f"rtdetr-{k}.pt" for k in "lx"]
    + ["mobile_sam.pt"]
    + ["calibration_image_sample_data_20x128x128x3_float32.npy.zip"]
)
GITHUB_ASSETS_STEMS = [Path(k).stem for k in GITHUB_ASSETS_NAMES]


def is_url(url, check=False):
    """
    åˆ¤æ–­ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯å¦ä¸º URLï¼Œå¹¶å¯é€‰åœ°æ£€æŸ¥è¯¥ URL æ˜¯å¦å¯è®¿é—®ã€‚

    å‚æ•°:
        url (str): è¦éªŒè¯çš„ URL å­—ç¬¦ä¸²ã€‚
        check (bool, å¯é€‰): å¦‚æœä¸º Trueï¼Œåˆ™é¢å¤–æ£€æŸ¥è¯¥ URL æ˜¯å¦åœ¨çº¿å¯è®¿é—®ã€‚
            é»˜è®¤ä¸º Falseã€‚

    è¿”å›:
        (bool): å¦‚æœæ˜¯æœ‰æ•ˆçš„ URLï¼Œåˆ™è¿”å› Trueã€‚å¦‚æœè®¾ç½®äº† checkï¼Œåˆ™è¿”å› URL åœ¨çº¿å¯è®¿é—®çš„åˆ¤æ–­ç»“æœã€‚
            å¦åˆ™è¿”å› Falseã€‚

    ç¤ºä¾‹:
        ```python
        valid = is_url("https://www.example.com")
        ```
    """
    try:
        url = str(url)
        result = parse.urlparse(url)
        assert all([result.scheme, result.netloc])  # æ£€æŸ¥æ˜¯å¦ä¸º URL
        if check:
            with request.urlopen(url) as response:
                return response.getcode() == 200  # æ£€æŸ¥æ˜¯å¦åœ¨çº¿å­˜åœ¨
        return True
    except Exception:
        return False


def delete_dsstore(path, files_to_delete=(".DS_Store", "__MACOSX")):
    """
    åˆ é™¤æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰ ".DS_Store" æ–‡ä»¶ã€‚

    å‚æ•°:
        path (str, å¯é€‰): è¦åˆ é™¤ ".DS_Store" æ–‡ä»¶çš„ç›®å½•è·¯å¾„ã€‚
        files_to_delete (tuple): è¦åˆ é™¤çš„æ–‡ä»¶åã€‚

    ç¤ºä¾‹:
        ```python
        from ultralytics.utils.downloads import delete_dsstore

        delete_dsstore("path/to/dir")
        ```

    æ³¨æ„:
        ".DS_Store" æ–‡ä»¶æ˜¯è‹¹æœæ“ä½œç³»ç»Ÿåˆ›å»ºçš„ï¼Œç”¨äºå­˜å‚¨æ–‡ä»¶å¤¹å’Œæ–‡ä»¶çš„å…ƒæ•°æ®ã€‚
        å®ƒä»¬æ˜¯éšè—çš„ç³»ç»Ÿæ–‡ä»¶ï¼Œåœ¨è·¨å¹³å°ä¼ è¾“æ–‡ä»¶æ—¶å¯èƒ½ä¼šå¼•èµ·é—®é¢˜ã€‚
    """
    for file in files_to_delete:
        matches = list(Path(path).rglob(file))
        LOGGER.info(f"æ­£åœ¨åˆ é™¤ {file} æ–‡ä»¶: {matches}")
        for f in matches:
            f.unlink()


def zip_directory(directory, compress=True, exclude=(".DS_Store", "__MACOSX"), progress=True):
    """
    å‹ç¼©ç›®å½•å†…å®¹ä¸º zip æ–‡ä»¶ï¼Œæ’é™¤æ‰æ–‡ä»¶ååŒ…å« exclude ä¸­å­—ç¬¦ä¸²çš„æ–‡ä»¶ã€‚ç”Ÿæˆçš„ zip æ–‡ä»¶å°†å’Œç›®å½•åŒåï¼Œå¹¶ä¿å­˜åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚

    å‚æ•°:
        directory (str | Path): è¦å‹ç¼©çš„ç›®å½•è·¯å¾„ã€‚
        compress (bool): æ˜¯å¦è¿›è¡Œå‹ç¼©ï¼Œé»˜è®¤ä¸º Trueã€‚
        exclude (tuple, å¯é€‰): è¦æ’é™¤çš„æ–‡ä»¶åå­—ç¬¦ä¸²å…ƒç»„ã€‚é»˜è®¤ä¸º ('.DS_Store', '__MACOSX')ã€‚
        progress (bool, å¯é€‰): æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œé»˜è®¤ä¸º Trueã€‚

    è¿”å›:
        (Path): è¿”å›ç”Ÿæˆçš„ zip æ–‡ä»¶çš„è·¯å¾„ã€‚

    ç¤ºä¾‹:
        ```python
        from ultralytics.utils.downloads import zip_directory

        file = zip_directory("path/to/dir")
        ```
    """
    from zipfile import ZIP_DEFLATED, ZIP_STORED, ZipFile

    delete_dsstore(directory)
    directory = Path(directory)
    if not directory.is_dir():
        raise FileNotFoundError(f"ç›®å½• '{directory}' ä¸å­˜åœ¨ã€‚")

    # ç”Ÿæˆå¾…å‹ç¼©æ–‡ä»¶åˆ—è¡¨ï¼Œå¹¶ä½¿ç”¨è¿›åº¦æ¡è¿›è¡Œå‹ç¼©
    files_to_zip = [f for f in directory.rglob("*") if f.is_file() and all(x not in f.name for x in exclude)]
    zip_file = directory.with_suffix(".zip")
    compression = ZIP_DEFLATED if compress else ZIP_STORED
    with ZipFile(zip_file, "w", compression) as f:
        for file in TQDM(files_to_zip, desc=f"æ­£åœ¨å‹ç¼© {directory} åˆ° {zip_file}...", unit="file", disable=not progress):
            f.write(file, file.relative_to(directory))

    return zip_file  # è¿”å›å‹ç¼©åçš„ zip æ–‡ä»¶è·¯å¾„


def unzip_file(file, path=None, exclude=(".DS_Store", "__MACOSX"), exist_ok=False, progress=True):
    """
    è§£å‹ *.zip æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„ï¼Œæ’é™¤åŒ…å«æ’é™¤åˆ—è¡¨ä¸­å­—ç¬¦ä¸²çš„æ–‡ä»¶ã€‚

    å¦‚æœå‹ç¼©æ–‡ä»¶æ²¡æœ‰åŒ…å«å•ä¸ªé¡¶çº§ç›®å½•ï¼Œå‡½æ•°å°†åˆ›å»ºä¸€ä¸ªä¸å‹ç¼©æ–‡ä»¶åŒåï¼ˆä¸å¸¦æ‰©å±•åï¼‰çš„æ–°ç›®å½•æ¥æå–å…¶å†…å®¹ã€‚
    å¦‚æœæœªæä¾›è·¯å¾„ï¼Œå‡½æ•°å°†ä½¿ç”¨å‹ç¼©æ–‡ä»¶çš„çˆ¶ç›®å½•ä½œä¸ºé»˜è®¤è·¯å¾„ã€‚

    å‚æ•°ï¼š
        file (str | Path): è¦è§£å‹çš„å‹ç¼©æ–‡ä»¶è·¯å¾„ã€‚
        path (str, å¯é€‰): è§£å‹æ–‡ä»¶çš„ç›®æ ‡è·¯å¾„ã€‚å¦‚æœä¸º Noneï¼Œé»˜è®¤ä¸ºå‹ç¼©æ–‡ä»¶æ‰€åœ¨çš„çˆ¶ç›®å½•ã€‚
        exclude (tuple, å¯é€‰): è¦æ’é™¤çš„æ–‡ä»¶åå­—ç¬¦ä¸²å…ƒç»„ã€‚é»˜è®¤ä¸º ('.DS_Store', '__MACOSX')ã€‚
        exist_ok (bool, å¯é€‰): æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„å†…å®¹ã€‚å¦‚æœä¸º Falseï¼Œä¸”ç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œå‡½æ•°ä¼šè·³è¿‡è§£å‹ã€‚é»˜è®¤ä¸º Falseã€‚
        progress (bool, å¯é€‰): æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ã€‚é»˜è®¤ä¸º Trueã€‚

    å¼‚å¸¸ï¼š
        BadZipFile: å¦‚æœæä¾›çš„æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆçš„å‹ç¼©æ–‡ä»¶ã€‚

    è¿”å›ï¼š
        (Path): è§£å‹åçš„ç›®å½•è·¯å¾„ã€‚

    ç¤ºä¾‹ï¼š
        ```python
        from ultralytics.utils.downloads import unzip_file

        dir = unzip_file("path/to/file.zip")
        ```
    """
    from zipfile import BadZipFile, ZipFile, is_zipfile

    if not (Path(file).exists() and is_zipfile(file)):
        raise BadZipFile(f"æ–‡ä»¶ '{file}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯æœ‰æ•ˆçš„å‹ç¼©æ–‡ä»¶ã€‚")
    if path is None:
        path = Path(file).parent  # é»˜è®¤è·¯å¾„

    # è§£å‹æ–‡ä»¶å†…å®¹
    with ZipFile(file) as zipObj:
        files = [f for f in zipObj.namelist() if all(x not in f for x in exclude)]
        top_level_dirs = {Path(f).parts[0] for f in files}

        # å†³å®šæ˜¯å¦ç›´æ¥è§£å‹è¿˜æ˜¯è§£å‹åˆ°ä¸€ä¸ªç›®å½•ä¸­
        unzip_as_dir = len(top_level_dirs) == 1  # åˆ¤æ–­æ˜¯å¦æœ‰å•ä¸ªé¡¶çº§ç›®å½•
        if unzip_as_dir:
            # å‹ç¼©åŒ…åŒ…å« 1 ä¸ªé¡¶çº§ç›®å½•
            extract_path = path  # å³è§£å‹åˆ° ../datasets
            path = Path(path) / list(top_level_dirs)[0]  # å³è§£å‹åˆ° ../datasets/ ä¸‹çš„ coco8/ ç›®å½•
        else:
            # å‹ç¼©åŒ…åŒ…å«å¤šä¸ªé¡¶çº§æ–‡ä»¶
            path = extract_path = Path(path) / Path(file).stem  # å³è§£å‹å¤šä¸ªæ–‡ä»¶åˆ° ../datasets/coco8/

        # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å·²å­˜åœ¨ä¸”åŒ…å«æ–‡ä»¶
        if path.exists() and any(path.iterdir()) and not exist_ok:
            # å¦‚æœç›®å½•å­˜åœ¨ä¸”ä¸ä¸ºç©ºï¼Œè·³è¿‡è§£å‹ï¼Œç›´æ¥è¿”å›è·¯å¾„
            LOGGER.warning(f"è­¦å‘Š âš ï¸ è·³è¿‡è§£å‹ {file}ï¼Œå› ä¸ºç›®æ ‡ç›®å½• {path} ä¸ä¸ºç©ºã€‚")
            return path

        for f in TQDM(files, desc=f"æ­£åœ¨è§£å‹ {file} åˆ° {Path(path).resolve()}...", unit="file", disable=not progress):
            # ç¡®ä¿æ–‡ä»¶è·¯å¾„ä¸åŒ…å« "ä¸Šçº§ç›®å½•" æ¥é¿å…è·¯å¾„éå†å®‰å…¨æ¼æ´
            if ".." in Path(f).parts:
                LOGGER.warning(f"æ½œåœ¨ä¸å®‰å…¨çš„æ–‡ä»¶è·¯å¾„: {f}ï¼Œè·³è¿‡è§£å‹ã€‚")
                continue
            zipObj.extract(f, extract_path)

    return path  # è¿”å›è§£å‹ç›®å½•


def check_disk_space(url="https://ultralytics.com/assets/coco8.zip", path=Path.cwd(), sf=1.5, hard=True):
    """
    æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´æ¥ä¸‹è½½å¹¶å­˜å‚¨æ–‡ä»¶ã€‚

    å‚æ•°ï¼š
        url (str, å¯é€‰): æ–‡ä»¶çš„ URLã€‚é»˜è®¤ä¸º 'https://ultralytics.com/assets/coco8.zip'ã€‚
        path (str | Path, å¯é€‰): è¦æ£€æŸ¥å¯ç”¨ç©ºé—´çš„è·¯å¾„æˆ–ç£ç›˜ã€‚é»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•ã€‚
        sf (float, å¯é€‰): å®‰å…¨ç³»æ•°ï¼Œæ˜¯æ‰€éœ€ç©ºé—´çš„å€æ•°ã€‚é»˜è®¤ä¸º 1.5ã€‚
        hard (bool, å¯é€‰): ç£ç›˜ç©ºé—´ä¸è¶³æ—¶æ˜¯å¦æŠ›å‡ºé”™è¯¯ã€‚é»˜è®¤ä¸º Trueã€‚

    è¿”å›ï¼š
        (bool): å¦‚æœç£ç›˜ç©ºé—´è¶³å¤Ÿï¼Œè¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
    """
    try:
        r = requests.head(url)  # å“åº”
        assert r.status_code < 400, f"URL é”™è¯¯ {url}: {r.status_code} {r.reason}"  # æ£€æŸ¥å“åº”
    except Exception:
        return True  # è¯·æ±‚é—®é¢˜ï¼Œé»˜è®¤è¿”å› True

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    gib = 1 << 30  # æ¯ GiB çš„å­—èŠ‚æ•°
    data = int(r.headers.get("Content-Length", 0)) / gib  # æ–‡ä»¶å¤§å°ï¼ˆGBï¼‰
    total, used, free = (x / gib for x in shutil.disk_usage(path))  # è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯

    if data * sf < free:
        return True  # è¶³å¤Ÿç©ºé—´

    # ç©ºé—´ä¸è¶³
    text = (
        f"è­¦å‘Š âš ï¸ å¯ç”¨ç£ç›˜ç©ºé—´ {free:.1f} GB å°äº {data * sf:.3f} GBï¼Œ"
        f"è¯·é‡Šæ”¾ {data * sf - free:.1f} GB é¢å¤–ç£ç›˜ç©ºé—´åå†è¯•ã€‚"
    )
    if hard:
        raise MemoryError(text)
    LOGGER.warning(text)
    return False


def get_google_drive_file_info(link):
    """
    è·å–å¯åˆ†äº«çš„ Google Drive æ–‡ä»¶é“¾æ¥çš„ç›´æ¥ä¸‹è½½é“¾æ¥å’Œæ–‡ä»¶åã€‚

    å‚æ•°ï¼š
        link (str): Google Drive æ–‡ä»¶çš„å¯åˆ†äº«é“¾æ¥ã€‚

    è¿”å›ï¼š
        (str): Google Drive æ–‡ä»¶çš„ç›´æ¥ä¸‹è½½é“¾æ¥ã€‚
        (str): Google Drive æ–‡ä»¶çš„åŸå§‹æ–‡ä»¶åã€‚å¦‚æœæå–å¤±è´¥ï¼Œè¿”å› Noneã€‚

    ç¤ºä¾‹ï¼š
        ```python
        from ultralytics.utils.downloads import get_google_drive_file_info

        link = "https://drive.google.com/file/d/1cqT-cJgANNrhIHCrEufUYhQ4RqiWG_lJ/view?usp=drive_link"
        url, filename = get_google_drive_file_info(link)
        ```
    """
    file_id = link.split("/d/")[1].split("/view")[0]
    drive_url = f"https://drive.google.com/uc?export=download&id={file_id}"
    filename = None

    # å¯åŠ¨ä¼šè¯
    with requests.Session() as session:
        response = session.get(drive_url, stream=True)
        if "quota exceeded" in str(response.content.lower()):
            raise ConnectionError(
                emojis(
                    f"âŒ  Google Drive æ–‡ä»¶ä¸‹è½½é…é¢å·²æ»¡ã€‚"
                    f"è¯·ç¨åå†è¯•æˆ–æ‰‹åŠ¨ä¸‹è½½è¯¥æ–‡ä»¶ï¼Œé“¾æ¥ä¸º {link}ã€‚"
                )
            )
        for k, v in response.cookies.items():
            if k.startswith("download_warning"):
                drive_url += f"&confirm={v}"  # v æ˜¯ç¡®è®¤ token
        if cd := response.headers.get("content-disposition"):
            filename = re.findall('filename="(.+)"', cd)[0]
    return drive_url, filename


def safe_download(
    url,
    file=None,
    dir=None,
    unzip=True,
    delete=False,
    curl=False,
    retry=3,
    min_bytes=1e0,
    exist_ok=False,
    progress=True,
):
    """
    ä»URLä¸‹è½½æ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•ã€è§£å‹å’Œåˆ é™¤å·²ä¸‹è½½æ–‡ä»¶çš„é€‰é¡¹ã€‚

    å‚æ•°:
        url (str): è¦ä¸‹è½½çš„æ–‡ä»¶çš„URLã€‚
        file (str, å¯é€‰): ä¸‹è½½çš„æ–‡ä»¶åã€‚å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨URLçš„æ–‡ä»¶åã€‚
        dir (str, å¯é€‰): è¦ä¿å­˜ä¸‹è½½æ–‡ä»¶çš„ç›®å½•ã€‚å¦‚æœæœªæä¾›ï¼Œæ–‡ä»¶å°†ä¿å­˜åœ¨å½“å‰å·¥ä½œç›®å½•ä¸­ã€‚
        unzip (bool, å¯é€‰): æ˜¯å¦è§£å‹ä¸‹è½½çš„æ–‡ä»¶ã€‚é»˜è®¤ä¸ºTrueã€‚
        delete (bool, å¯é€‰): æ˜¯å¦åœ¨è§£å‹ååˆ é™¤ä¸‹è½½çš„æ–‡ä»¶ã€‚é»˜è®¤ä¸ºFalseã€‚
        curl (bool, å¯é€‰): æ˜¯å¦ä½¿ç”¨curlå‘½ä»¤è¡Œå·¥å…·è¿›è¡Œä¸‹è½½ã€‚é»˜è®¤ä¸ºFalseã€‚
        retry (int, å¯é€‰): ä¸‹è½½å¤±è´¥æ—¶é‡è¯•çš„æ¬¡æ•°ã€‚é»˜è®¤ä¸º3ã€‚
        min_bytes (float, å¯é€‰): ä¸‹è½½çš„æ–‡ä»¶å¿…é¡»å…·æœ‰çš„æœ€å°å­—èŠ‚æ•°ï¼Œæ‰èƒ½è®¤ä¸ºæ˜¯æˆåŠŸçš„ä¸‹è½½ã€‚é»˜è®¤ä¸º1E0ã€‚
        exist_ok (bool, å¯é€‰): è§£å‹æ—¶æ˜¯å¦è¦†ç›–ç°æœ‰å†…å®¹ã€‚é»˜è®¤ä¸ºFalseã€‚
        progress (bool, å¯é€‰): æ˜¯å¦åœ¨ä¸‹è½½æ—¶æ˜¾ç¤ºè¿›åº¦æ¡ã€‚é»˜è®¤ä¸ºTrueã€‚

    ç¤ºä¾‹:
        ```python
        from ultralytics.utils.downloads import safe_download

        link = "https://ultralytics.com/assets/bus.jpg"
        path = safe_download(link)
        ```
    """
    gdrive = url.startswith("https://drive.google.com/")  # æ£€æŸ¥æ˜¯å¦æ˜¯Google Driveé“¾æ¥
    if gdrive:
        url, file = get_google_drive_file_info(url)

    f = Path(dir or ".") / (file or url2file(url))  # å°†URLè½¬æ¢ä¸ºæ–‡ä»¶å
    if "://" not in str(url) and Path(url).is_file():  # æ£€æŸ¥URLæ˜¯å¦å­˜åœ¨ ('://' æ£€æŸ¥åœ¨Windows Python <3.10ä¸­éœ€è¦)
        f = Path(url)  # æ–‡ä»¶å
    elif not f.is_file():  # URLå’Œæ–‡ä»¶éƒ½ä¸å­˜åœ¨
        uri = (url if gdrive else clean_url(url)).replace(  # æ¸…ç†å’Œåˆ«ååŒ–çš„URL
            "https://github.com/ultralytics/assets/releases/download/v0.0.0/",
            "https://ultralytics.com/assets/",  # èµ„äº§åˆ«å
        )
        desc = f"æ­£åœ¨ä¸‹è½½ {uri} åˆ° '{f}'"
        LOGGER.info(f"{desc}...")
        f.parent.mkdir(parents=True, exist_ok=True)  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºç›®å½•
        check_disk_space(url, path=f.parent)
        for i in range(retry + 1):
            try:
                if curl or i > 0:  # ä½¿ç”¨curlä¸‹è½½å¹¶é‡è¯•
                    s = "sS" * (not progress)  # é™é»˜æ¨¡å¼
                    r = subprocess.run(["curl", "-#", f"-{s}L", url, "-o", f, "--retry", "3", "-C", "-"]).returncode
                    assert r == 0, f"Curlè¿”å›å€¼ {r}"
                else:  # ä½¿ç”¨urllibä¸‹è½½
                    method = "torch"
                    if method == "torch":
                        torch.hub.download_url_to_file(url, f, progress=progress)
                    else:
                        with request.urlopen(url) as response, TQDM(
                            total=int(response.getheader("Content-Length", 0)),
                            desc=desc,
                            disable=not progress,
                            unit="B",
                            unit_scale=True,
                            unit_divisor=1024,
                        ) as pbar:
                            with open(f, "wb") as f_opened:
                                for data in response:
                                    f_opened.write(data)
                                    pbar.update(len(data))

                if f.exists():
                    if f.stat().st_size > min_bytes:
                        break  # ä¸‹è½½æˆåŠŸ
                    f.unlink()  # åˆ é™¤éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶
            except Exception as e:
                if i == 0 and not is_online():
                    raise ConnectionError(emojis(f"âŒ  ä¸‹è½½å¤±è´¥ {uri}ï¼Œç¯å¢ƒä¸å¯åœ¨çº¿ã€‚")) from e
                elif i >= retry:
                    raise ConnectionError(emojis(f"âŒ  ä¸‹è½½å¤±è´¥ {uri}ï¼Œå·²è¾¾åˆ°é‡è¯•æ¬¡æ•°é™åˆ¶ã€‚")) from e
                LOGGER.warning(f"âš ï¸ ä¸‹è½½å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• {i + 1}/{retry} {uri}...")

    if unzip and f.exists() and f.suffix in {"", ".zip", ".tar", ".gz"}:
        from zipfile import is_zipfile

        unzip_dir = (dir or f.parent).resolve()  # å¦‚æœæä¾›äº†ç›®å½•ï¼Œåˆ™è§£å‹åˆ°è¯¥ç›®å½•ï¼Œå¦åˆ™åœ¨åŸåœ°è§£å‹
        if is_zipfile(f):
            unzip_dir = unzip_file(file=f, path=unzip_dir, exist_ok=exist_ok, progress=progress)  # è§£å‹
        elif f.suffix in {".tar", ".gz"}:
            LOGGER.info(f"æ­£åœ¨è§£å‹ {f} åˆ° {unzip_dir}...")
            subprocess.run(["tar", "xf" if f.suffix == ".tar" else "xfz", f, "--directory", unzip_dir], check=True)
        if delete:
            f.unlink()  # åˆ é™¤zipæ–‡ä»¶
        return unzip_dir


def get_github_assets(repo="ultralytics/assets", version="latest", retry=False):
    """
    ä»GitHubä»“åº“è·å–æŒ‡å®šç‰ˆæœ¬çš„æ ‡ç­¾å’Œèµ„äº§ã€‚å¦‚æœæœªæŒ‡å®šç‰ˆæœ¬ï¼Œå‡½æ•°å°†è·å–æœ€æ–°çš„å‘å¸ƒç‰ˆæœ¬çš„èµ„äº§ã€‚

    å‚æ•°:
        repo (str, å¯é€‰): GitHubä»“åº“ï¼Œæ ¼å¼ä¸º 'owner/repo'ã€‚é»˜è®¤ä¸º 'ultralytics/assets'ã€‚
        version (str, å¯é€‰): è¦è·å–èµ„äº§çš„å‘å¸ƒç‰ˆæœ¬ã€‚é»˜è®¤ä¸º 'latest'ã€‚
        retry (bool, å¯é€‰): ä¸‹è½½å¤±è´¥æ—¶æ˜¯å¦é‡è¯•ã€‚é»˜è®¤ä¸ºFalseã€‚

    è¿”å›:
        (tuple): è¿”å›ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«å‘å¸ƒæ ‡ç­¾å’Œèµ„äº§åç§°åˆ—è¡¨ã€‚

    ç¤ºä¾‹:
        ```python
        tag, assets = get_github_assets(repo="ultralytics/assets", version="latest")
        ```
    """
    if version != "latest":
        version = f"tags/{version}"  # å³ tags/v6.2
    url = f"https://api.github.com/repos/{repo}/releases/{version}"
    r = requests.get(url)  # GitHub APIè¯·æ±‚
    if r.status_code != 200 and r.reason != "rate limit exceeded" and retry:  # å¦‚æœå¤±è´¥å¹¶ä¸”ä¸æ˜¯403é™åˆ¶
        r = requests.get(url)  # é‡è¯•
    if r.status_code != 200:
        LOGGER.warning(f"âš ï¸ GitHubèµ„äº§æ£€æŸ¥å¤±è´¥ {url}: {r.status_code} {r.reason}")
        return "", []
    data = r.json()
    return data["tag_name"], [x["name"] for x in data["assets"]]  # è¿”å›æ ‡ç­¾å’Œèµ„äº§åç§°åˆ—è¡¨ï¼Œä¾‹å¦‚ ['yolov8n.pt', 'yolov8s.pt', ...]


def attempt_download_asset(file, repo="ultralytics/assets", release="v8.3.0", **kwargs):
    """
    å¦‚æœæœ¬åœ°æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œå°è¯•ä» GitHub å‘å¸ƒèµ„äº§ä¸­ä¸‹è½½æ–‡ä»¶ã€‚è¯¥å‡½æ•°é¦–å…ˆæ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰æ–‡ä»¶ï¼Œ
    å¦‚æœæ²¡æœ‰ï¼Œå†å°è¯•ä»æŒ‡å®šçš„ GitHub ä»“åº“å‘å¸ƒä¸­ä¸‹è½½æ–‡ä»¶ã€‚

    å‚æ•°:
        file (str | Path): è¦ä¸‹è½½çš„æ–‡ä»¶åæˆ–æ–‡ä»¶è·¯å¾„ã€‚
        repo (str, å¯é€‰): GitHub ä»“åº“ï¼Œæ ¼å¼ä¸º 'owner/repo'ã€‚é»˜è®¤ä¸º 'ultralytics/assets'ã€‚
        release (str, å¯é€‰): è¦ä¸‹è½½çš„å…·ä½“ç‰ˆæœ¬ã€‚é»˜è®¤ä¸º 'v8.3.0'ã€‚
        **kwargs (any): ä¸‹è½½è¿‡ç¨‹ä¸­å…¶ä»–å…³é”®å­—å‚æ•°ã€‚

    è¿”å›:
        (str): ä¸‹è½½æ–‡ä»¶çš„è·¯å¾„ã€‚

    ç¤ºä¾‹:
        ```python
        file_path = attempt_download_asset("yolo11n.pt", repo="ultralytics/assets", release="latest")
        ```
    """
    from ultralytics.utils import SETTINGS  # ä¸ºé¿å…å¾ªç¯å¯¼å…¥ï¼Œä½œç”¨åŸŸé™å®š

    if 'v12' in str(file):
        repo = "sunsmarterjie/yolov12"
        release = "turbo"

    # YOLOv3/5u æ›´æ–°
    file = str(file)
    file = checks.check_yolov5u_filename(file)
    file = Path(file.strip().replace("'", ""))
    if file.exists():
        return str(file)
    elif (SETTINGS["weights_dir"] / file).exists():
        return str(SETTINGS["weights_dir"] / file)
    else:
        # URL æŒ‡å®š
        name = Path(parse.unquote(str(file))).name  # è§£ç  '%2F' ä¸º '/' ç­‰
        download_url = f"https://github.com/{repo}/releases/download"
        if str(file).startswith(("http:/", "https:/")):  # ä¸‹è½½
            url = str(file).replace(":/", "://")  # Pathlib ä¼šå°† :// è½¬æ¢ä¸º :/
            file = url2file(name)  # è§£æèº«ä»½éªŒè¯ https://url.com/file.txt?auth...
            if Path(file).is_file():
                LOGGER.info(f"åœ¨ {file} æœ¬åœ°æ‰¾åˆ° {clean_url(url)}")  # æ–‡ä»¶å·²å­˜åœ¨
            else:
                safe_download(url=url, file=file, min_bytes=1e5, **kwargs)

        elif repo == GITHUB_ASSETS_REPO and name in GITHUB_ASSETS_NAMES:
            safe_download(url=f"{download_url}/{release}/{name}", file=file, min_bytes=1e5, **kwargs)

        else:
            tag, assets = get_github_assets(repo, release)
            if not assets:
                tag, assets = get_github_assets(repo)  # æœ€æ–°å‘å¸ƒ
            if name in assets:
                safe_download(url=f"{download_url}/{tag}/{name}", file=file, min_bytes=1e5, **kwargs)

        return str(file)


def download(url, dir=Path.cwd(), unzip=True, delete=False, curl=False, threads=1, retry=3, exist_ok=False):
    """
    ä»æŒ‡å®šçš„ URL ä¸‹è½½æ–‡ä»¶åˆ°ç»™å®šçš„ç›®å½•ã€‚å¦‚æœæŒ‡å®šäº†å¤šä¸ªçº¿ç¨‹ï¼Œè¿˜æ”¯æŒå¹¶å‘ä¸‹è½½ã€‚

    å‚æ•°:
        url (str | list): è¦ä¸‹è½½çš„æ–‡ä»¶çš„ URL æˆ– URL åˆ—è¡¨ã€‚
        dir (Path, å¯é€‰): æ–‡ä»¶ä¿å­˜çš„ç›®å½•ã€‚é»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•ã€‚
        unzip (bool, å¯é€‰): ä¸‹è½½åæ˜¯å¦è§£å‹æ–‡ä»¶ã€‚é»˜è®¤ä¸º Trueã€‚
        delete (bool, å¯é€‰): è§£å‹åæ˜¯å¦åˆ é™¤å‹ç¼©æ–‡ä»¶ã€‚é»˜è®¤ä¸º Falseã€‚
        curl (bool, å¯é€‰): æ˜¯å¦ä½¿ç”¨ curl ä¸‹è½½ã€‚é»˜è®¤ä¸º Falseã€‚
        threads (int, å¯é€‰): ç”¨äºå¹¶å‘ä¸‹è½½çš„çº¿ç¨‹æ•°ã€‚é»˜è®¤ä¸º 1ã€‚
        retry (int, å¯é€‰): ä¸‹è½½å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°ã€‚é»˜è®¤ä¸º 3ã€‚
        exist_ok (bool, å¯é€‰): è§£å‹æ—¶æ˜¯å¦è¦†ç›–å·²æœ‰å†…å®¹ã€‚é»˜è®¤ä¸º Falseã€‚

    ç¤ºä¾‹:
        ```python
        download("https://ultralytics.com/assets/example.zip", dir="path/to/dir", unzip=True)
        ```
    """
    dir = Path(dir)
    dir.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•
    if threads > 1:
        with ThreadPool(threads) as pool:
            pool.map(
                lambda x: safe_download(
                    url=x[0],
                    dir=x[1],
                    unzip=unzip,
                    delete=delete,
                    curl=curl,
                    retry=retry,
                    exist_ok=exist_ok,
                    progress=threads <= 1,
                ),
                zip(url, repeat(dir)),
            )
            pool.close()
            pool.join()
    else:
        for u in [url] if isinstance(url, (str, Path)) else url:
            safe_download(url=u, dir=dir, unzip=unzip, delete=delete, curl=curl, retry=retry, exist_ok=exist_ok)
