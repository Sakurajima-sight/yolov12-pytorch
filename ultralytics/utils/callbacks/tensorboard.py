# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from ultralytics.utils import LOGGER, SETTINGS, TESTS_RUNNING, colorstr

try:
    # è­¦å‘Šï¼šç”±äºprotobuf bug https://github.com/ultralytics/ultralytics/pull/4674ï¼Œè¯·ä¸è¦ç§»åŠ¨SummaryWriterçš„å¯¼å…¥
    from torch.utils.tensorboard import SummaryWriter

    assert not TESTS_RUNNING  # ä¸è®°å½•pytestæ—¥å¿—
    assert SETTINGS["tensorboard"] is True  # ç¡®è®¤é›†æˆå·²å¯ç”¨
    WRITER = None  # TensorBoard SummaryWriter å®ä¾‹
    PREFIX = colorstr("TensorBoard: ")

    # ä»¥ä¸‹å¯¼å…¥ä»…åœ¨å¯ç”¨TensorBoardæ—¶éœ€è¦
    import warnings
    from copy import deepcopy

    from ultralytics.utils.torch_utils import de_parallel, torch

except (ImportError, AssertionError, TypeError, AttributeError):
    # å¤„ç†Windowsä¸­çš„'TypeError'ï¼Œå³â€œæè¿°ç¬¦ä¸èƒ½ç›´æ¥åˆ›å»ºâ€çš„protobufé”™è¯¯
    # å¤„ç†'AttributeError: module 'tensorflow' has no attribute 'io'ï¼Œå¦‚æœæœªå®‰è£…'tensorflow'
    SummaryWriter = None


def _log_scalars(scalars, step=0):
    """å°†æ ‡é‡å€¼è®°å½•åˆ°TensorBoardä¸­ã€‚"""
    if WRITER:
        for k, v in scalars.items():
            WRITER.add_scalar(k, v, step)


def _log_tensorboard_graph(trainer):
    """å°†æ¨¡å‹å›¾è®°å½•åˆ°TensorBoardä¸­ã€‚"""
    # è¾“å…¥å›¾åƒ
    imgsz = trainer.args.imgsz
    imgsz = (imgsz, imgsz) if isinstance(imgsz, int) else imgsz
    p = next(trainer.model.parameters())  # è·å–è®¾å¤‡å’Œç±»å‹
    im = torch.zeros((1, 3, *imgsz), device=p.device, dtype=p.dtype)  # è¾“å…¥å›¾åƒï¼ˆå¿…é¡»æ˜¯é›¶è€Œä¸æ˜¯ç©ºï¼‰

    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=UserWarning)  # å¿½ç•¥jit traceè­¦å‘Š
        warnings.simplefilter("ignore", category=torch.jit.TracerWarning)  # å¿½ç•¥jit traceè­¦å‘Š

        # å°è¯•ç®€å•æ–¹æ³•ï¼ˆYOLOï¼‰
        try:
            trainer.model.eval()  # åˆ‡æ¢åˆ°.eval()æ¨¡å¼ä»¥é¿å…BatchNormç»Ÿè®¡é‡å˜åŒ–
            WRITER.add_graph(torch.jit.trace(de_parallel(trainer.model), im, strict=False), [])
            LOGGER.info(f"{PREFIX}æ¨¡å‹å›¾å½¢å¯è§†åŒ–å·²æ·»åŠ  âœ…")
            return

        except Exception:
            # å›é€€åˆ°TorchScriptå¯¼å‡ºæ­¥éª¤ï¼ˆRTDETRï¼‰
            try:
                model = deepcopy(de_parallel(trainer.model))
                model.eval()
                model = model.fuse(verbose=False)
                for m in model.modules():
                    if hasattr(m, "export"):  # æ£€æµ‹ï¼ŒRTDETRDecoderï¼ˆSegmentå’ŒPoseä½¿ç”¨DetectåŸºç±»ï¼‰
                        m.export = True
                        m.format = "torchscript"
                model(im)  # å¹²è¿è¡Œ
                WRITER.add_graph(torch.jit.trace(model, im, strict=False), [])
                LOGGER.info(f"{PREFIX}æ¨¡å‹å›¾å½¢å¯è§†åŒ–å·²æ·»åŠ  âœ…")
            except Exception as e:
                LOGGER.warning(f"{PREFIX}è­¦å‘Š âš ï¸ TensorBoardå›¾å½¢å¯è§†åŒ–å¤±è´¥ {e}")


def on_pretrain_routine_start(trainer):
    """åœ¨é¢„è®­ç»ƒä¾‹ç¨‹å¼€å§‹æ—¶åˆå§‹åŒ–TensorBoardæ—¥å¿—è®°å½•å™¨ã€‚"""
    if SummaryWriter:
        try:
            global WRITER
            WRITER = SummaryWriter(str(trainer.save_dir))
            LOGGER.info(f"{PREFIX}å¼€å§‹ä½¿ç”¨ 'tensorboard --logdir {trainer.save_dir}'ï¼Œå¯ä»¥åœ¨ http://localhost:6006/ æŸ¥çœ‹")
        except Exception as e:
            LOGGER.warning(f"{PREFIX}è­¦å‘Š âš ï¸ TensorBoardæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œæœªè®°å½•æ­¤æ¬¡è¿è¡Œã€‚{e}")


def on_train_start(trainer):
    """è®°å½•TensorBoardæ¨¡å‹å›¾ã€‚"""
    if WRITER:
        _log_tensorboard_graph(trainer)


def on_train_epoch_end(trainer):
    """åœ¨æ¯ä¸ªè®­ç»ƒå‘¨æœŸç»“æŸæ—¶è®°å½•æ ‡é‡ç»Ÿè®¡æ•°æ®ã€‚"""
    _log_scalars(trainer.label_loss_items(trainer.tloss, prefix="train"), trainer.epoch + 1)
    _log_scalars(trainer.lr, trainer.epoch + 1)


def on_fit_epoch_end(trainer):
    """åœ¨è®­ç»ƒå‘¨æœŸç»“æŸæ—¶è®°å½•å‘¨æœŸæŒ‡æ ‡ã€‚"""
    _log_scalars(trainer.metrics, trainer.epoch + 1)


callbacks = (
    {
        "on_pretrain_routine_start": on_pretrain_routine_start,
        "on_train_start": on_train_start,
        "on_fit_epoch_end": on_fit_epoch_end,
        "on_train_epoch_end": on_train_epoch_end,
    }
    if SummaryWriter
    else {}
)
