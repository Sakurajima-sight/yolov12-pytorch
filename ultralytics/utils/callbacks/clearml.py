# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from ultralytics.utils import LOGGER, SETTINGS, TESTS_RUNNING

try:
    assert not TESTS_RUNNING  # ä¸è®°å½•pytestæ—¥å¿—
    assert SETTINGS["clearml"] is True  # éªŒè¯æ˜¯å¦å¯ç”¨äº†é›†æˆ
    import clearml
    from clearml import Task

    assert hasattr(clearml, "__version__")  # éªŒè¯åŒ…ä¸æ˜¯ç›®å½•

except (ImportError, AssertionError):
    clearml = None


def _log_debug_samples(files, title="Debug Samples") -> None:
    """
    å°†æ–‡ä»¶ï¼ˆå›¾åƒï¼‰ä½œä¸ºè°ƒè¯•æ ·æœ¬è®°å½•åˆ°ClearMLä»»åŠ¡ä¸­ã€‚

    å‚æ•°ï¼š
        files (list): ä¸€ä¸ªåŒ…å«PosixPathæ ¼å¼æ–‡ä»¶è·¯å¾„çš„åˆ—è¡¨ã€‚
        title (str): ä¸€ä¸ªæ ‡é¢˜ï¼Œç”¨æ¥å°†å…·æœ‰ç›¸åŒå€¼çš„å›¾åƒåˆ†ç»„ã€‚
    """
    import re

    if task := Task.current_task():
        for f in files:
            if f.exists():
                it = re.search(r"_batch(\d+)", f.name)
                iteration = int(it.groups()[0]) if it else 0
                task.get_logger().report_image(
                    title=title, series=f.name.replace(it.group(), ""), local_path=str(f), iteration=iteration
                )


def _log_plot(title, plot_path) -> None:
    """
    å°†å›¾åƒä½œä¸ºå›¾è¡¨è®°å½•åˆ°ClearMLçš„å›¾è¡¨éƒ¨åˆ†ã€‚

    å‚æ•°ï¼š
        title (str): å›¾è¡¨çš„æ ‡é¢˜ã€‚
        plot_path (str): ä¿å­˜çš„å›¾åƒæ–‡ä»¶è·¯å¾„ã€‚
    """
    import matplotlib.image as mpimg
    import matplotlib.pyplot as plt

    img = mpimg.imread(plot_path)
    fig = plt.figure()
    ax = fig.add_axes([0, 0, 1, 1], frameon=False, aspect="auto", xticks=[], yticks=[])  # ä¸æ˜¾ç¤ºåæ ‡è½´
    ax.imshow(img)

    Task.current_task().get_logger().report_matplotlib_figure(
        title=title, series="", figure=fig, report_interactive=False
    )


def on_pretrain_routine_start(trainer):
    """åœ¨é¢„è®­ç»ƒè¿‡ç¨‹å¼€å§‹æ—¶è¿è¡Œï¼›åˆå§‹åŒ–å¹¶è¿æ¥/è®°å½•ä»»åŠ¡åˆ°ClearMLã€‚"""
    try:
        if task := Task.current_task():
            # è­¦å‘Šï¼šç¡®ä¿ç¦ç”¨äº†è‡ªåŠ¨çš„pytorchå’Œmatplotlibç»‘å®šï¼
            # æˆ‘ä»¬ä¼šåœ¨é›†æˆä¸­æ‰‹åŠ¨è®°å½•è¿™äº›å›¾è¡¨å’Œæ¨¡å‹æ–‡ä»¶
            from clearml.binding.frameworks.pytorch_bind import PatchPyTorchModelIO
            from clearml.binding.matplotlib_bind import PatchedMatplotlib

            PatchPyTorchModelIO.update_current_task(None)
            PatchedMatplotlib.update_current_task(None)
        else:
            task = Task.init(
                project_name=trainer.args.project or "Ultralytics",
                task_name=trainer.args.name,
                tags=["Ultralytics"],
                output_uri=True,
                reuse_last_task_id=False,
                auto_connect_frameworks={"pytorch": False, "matplotlib": False},
            )
            LOGGER.warning(
                "ClearMLåˆå§‹åŒ–äº†ä¸€ä¸ªæ–°ä»»åŠ¡ã€‚å¦‚æœæ‚¨æƒ³è¿œç¨‹è¿è¡Œï¼Œè¯·åœ¨åˆå§‹åŒ–YOLOä¹‹å‰æ·»åŠ clearml-initå¹¶è¿æ¥æ‚¨çš„å‚æ•°ã€‚"
            )
        task.connect(vars(trainer.args), name="General")
    except Exception as e:
        LOGGER.warning(f"è­¦å‘Š âš ï¸ ClearMLå·²å®‰è£…ï¼Œä½†æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œæœªè®°å½•æ­¤è¿è¡Œã€‚{e}")


def on_train_epoch_end(trainer):
    """åœ¨YOLOè®­ç»ƒçš„æ¯ä¸ªepochç»“æŸæ—¶è®°å½•è°ƒè¯•æ ·æœ¬å¹¶æŠ¥å‘Šå½“å‰è®­ç»ƒè¿›åº¦ã€‚"""
    if task := Task.current_task():
        # è®°å½•è°ƒè¯•æ ·æœ¬
        if trainer.epoch == 1:
            _log_debug_samples(sorted(trainer.save_dir.glob("train_batch*.jpg")), "Mosaic")
        # æŠ¥å‘Šå½“å‰è®­ç»ƒè¿›åº¦
        for k, v in trainer.label_loss_items(trainer.tloss, prefix="train").items():
            task.get_logger().report_scalar("train", k, v, iteration=trainer.epoch)
        for k, v in trainer.lr.items():
            task.get_logger().report_scalar("lr", k, v, iteration=trainer.epoch)


def on_fit_epoch_end(trainer):
    """åœ¨æ¯ä¸ªepochç»“æŸæ—¶æŠ¥å‘Šæ¨¡å‹ä¿¡æ¯åˆ°æ—¥å¿—ä¸­ã€‚"""
    if task := Task.current_task():
        # ä½ åº”è¯¥å¯ä»¥è®¿é—®åˆ°éªŒè¯é›†çš„bboxæ•°æ®ï¼Œå­˜å‚¨åœ¨jdictä¸­
        task.get_logger().report_scalar(
            title="Epoch Time", series="Epoch Time", value=trainer.epoch_time, iteration=trainer.epoch
        )
        for k, v in trainer.metrics.items():
            task.get_logger().report_scalar("val", k, v, iteration=trainer.epoch)
        if trainer.epoch == 0:
            from ultralytics.utils.torch_utils import model_info_for_loggers

            for k, v in model_info_for_loggers(trainer).items():
                task.get_logger().report_single_value(k, v)


def on_val_end(validator):
    """è®°å½•éªŒè¯ç»“æœï¼ŒåŒ…æ‹¬æ ‡ç­¾å’Œé¢„æµ‹ç»“æœã€‚"""
    if Task.current_task():
        # è®°å½•val_labelså’Œval_pred
        _log_debug_samples(sorted(validator.save_dir.glob("val*.jpg")), "Validation")


def on_train_end(trainer):
    """åœ¨è®­ç»ƒå®Œæˆæ—¶è®°å½•æœ€ç»ˆæ¨¡å‹åŠå…¶åç§°ã€‚"""
    if task := Task.current_task():
        # è®°å½•æœ€ç»ˆç»“æœï¼ŒCMçŸ©é˜µ + PRæ›²çº¿
        files = [
            "results.png",
            "confusion_matrix.png",
            "confusion_matrix_normalized.png",
            *(f"{x}_curve.png" for x in ("F1", "PR", "P", "R")),
        ]
        files = [(trainer.save_dir / f) for f in files if (trainer.save_dir / f).exists()]  # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
        for f in files:
            _log_plot(title=f.stem, plot_path=f)
        # æŠ¥å‘Šæœ€ç»ˆçš„æŒ‡æ ‡
        for k, v in trainer.validator.metrics.results_dict.items():
            task.get_logger().report_single_value(k, v)
        # è®°å½•æœ€ç»ˆæ¨¡å‹
        task.update_output_model(model_path=str(trainer.best), model_name=trainer.args.name, auto_delete_file=False)


callbacks = (
    {
        "on_pretrain_routine_start": on_pretrain_routine_start,
        "on_train_epoch_end": on_train_epoch_end,
        "on_fit_epoch_end": on_fit_epoch_end,
        "on_val_end": on_val_end,
        "on_train_end": on_train_end,
    }
    if clearml
    else {}
)
