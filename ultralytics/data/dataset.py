# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import json
from collections import defaultdict
from itertools import repeat
from multiprocessing.pool import ThreadPool
from pathlib import Path

import cv2
import numpy as np
import torch
from PIL import Image
from torch.utils.data import ConcatDataset

from ultralytics.utils import LOCAL_RANK, NUM_THREADS, TQDM, colorstr
from ultralytics.utils.ops import resample_segments
from ultralytics.utils.torch_utils import TORCHVISION_0_18

from .augment import (
    Compose,
    Format,
    Instances,
    LetterBox,
    RandomLoadText,
    classify_augmentations,
    classify_transforms,
    v8_transforms,
)
from .base import BaseDataset
from .utils import (
    HELP_URL,
    LOGGER,
    get_hash,
    img2label_paths,
    load_dataset_cache_file,
    save_dataset_cache_file,
    verify_image,
    verify_image_label,
)

# Ultralytics æ•°æ®é›† *.cache ç‰ˆæœ¬ï¼Œ>= 1.0.0 ç”¨äº YOLOv8
DATASET_CACHE_VERSION = "1.0.3"


class YOLODataset(BaseDataset):
    """
    ç”¨äºåŠ è½½ YOLO æ ¼å¼çš„ç›®æ ‡æ£€æµ‹å’Œ/æˆ–åˆ†å‰²æ ‡ç­¾çš„æ•°æ®é›†ç±»ã€‚

    å‚æ•°ï¼š
        data (dict, å¯é€‰)ï¼šæ•°æ®é›†çš„ YAML å­—å…¸ã€‚é»˜è®¤ä¸º Noneã€‚
        task (str)ï¼šæ˜¾å¼å‚æ•°ï¼Œç”¨äºæŒ‡å®šå½“å‰ä»»åŠ¡ï¼Œé»˜è®¤ä¸º 'detect'ã€‚

    è¿”å›ï¼š
        (torch.utils.data.Dataset)ï¼šä¸€ä¸ª PyTorch æ•°æ®é›†å¯¹è±¡ï¼Œå¯ç”¨äºè®­ç»ƒç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚
    """

    def __init__(self, *args, data=None, task="detect", **kwargs):
        """åˆå§‹åŒ– YOLODatasetï¼Œæ”¯æŒå¯é€‰çš„åˆ†å‰²å’Œå…³é”®ç‚¹é…ç½®ã€‚"""
        self.use_segments = task == "segment"
        self.use_keypoints = task == "pose"
        self.use_obb = task == "obb"
        self.data = data
        assert not (self.use_segments and self.use_keypoints), "ä¸èƒ½åŒæ—¶ä½¿ç”¨åˆ†å‰²å’Œå…³é”®ç‚¹ã€‚"
        super().__init__(*args, **kwargs)

    def cache_labels(self, path=Path("./labels.cache")):
        """
        ç¼“å­˜æ•°æ®é›†æ ‡ç­¾ï¼Œæ£€æŸ¥å›¾åƒå¹¶è¯»å–å½¢çŠ¶ã€‚

        å‚æ•°ï¼š
            path (Path)ï¼šä¿å­˜ç¼“å­˜æ–‡ä»¶çš„è·¯å¾„ã€‚é»˜è®¤å€¼æ˜¯ Path("./labels.cache")ã€‚

        è¿”å›ï¼š
            (dict)ï¼šæ ‡ç­¾ã€‚
        """
        x = {"labels": []}
        nm, nf, ne, nc, msgs = 0, 0, 0, 0, []  # ç¼ºå¤±çš„ï¼Œæ‰¾åˆ°çš„ï¼Œç©ºçš„ï¼ŒæŸåçš„ï¼Œæ¶ˆæ¯
        desc = f"{self.prefix}æ­£åœ¨æ‰«æ {path.parent / path.stem}..."
        total = len(self.im_files)
        nkpt, ndim = self.data.get("kpt_shape", (0, 0))
        if self.use_keypoints and (nkpt <= 0 or ndim not in {2, 3}):
            raise ValueError(
                "'kpt_shape' åœ¨ data.yaml ä¸­ç¼ºå¤±æˆ–ä¸æ­£ç¡®ã€‚åº”ä¸ºä¸€ä¸ªåŒ…å« [å…³é”®ç‚¹æ•°é‡, ç»´åº¦æ•°é‡ (2 è¡¨ç¤º x,y æˆ– 3 è¡¨ç¤º x,y,å¯è§æ€§)] çš„åˆ—è¡¨ï¼Œä¾‹å¦‚ 'kpt_shape: [17, 3]'"
            )
        with ThreadPool(NUM_THREADS) as pool:
            results = pool.imap(
                func=verify_image_label,
                iterable=zip(
                    self.im_files,
                    self.label_files,
                    repeat(self.prefix),
                    repeat(self.use_keypoints),
                    repeat(len(self.data["names"])),
                    repeat(nkpt),
                    repeat(ndim),
                ),
            )
            pbar = TQDM(results, desc=desc, total=total)
            for im_file, lb, shape, segments, keypoint, nm_f, nf_f, ne_f, nc_f, msg in pbar:
                nm += nm_f
                nf += nf_f
                ne += ne_f
                nc += nc_f
                if im_file:
                    x["labels"].append(
                        {
                            "im_file": im_file,
                            "shape": shape,
                            "cls": lb[:, 0:1],  # n, 1
                            "bboxes": lb[:, 1:],  # n, 4
                            "segments": segments,
                            "keypoints": keypoint,
                            "normalized": True,
                            "bbox_format": "xywh",
                        }
                    )
                if msg:
                    msgs.append(msg)
                pbar.desc = f"{desc} {nf} å¼ å›¾ç‰‡ï¼Œ{nm + ne} ä¸ªèƒŒæ™¯ï¼Œ{nc} ä¸ªæŸå"
            pbar.close()

        if msgs:
            LOGGER.info("\n".join(msgs))
        if nf == 0:
            LOGGER.warning(f"{self.prefix}è­¦å‘Š âš ï¸ åœ¨ {path} ä¸­æœªæ‰¾åˆ°æ ‡ç­¾ã€‚ {HELP_URL}")
        x["hash"] = get_hash(self.label_files + self.im_files)
        x["results"] = nf, nm, ne, nc, len(self.im_files)
        x["msgs"] = msgs  # è­¦å‘Šä¿¡æ¯
        save_dataset_cache_file(self.prefix, path, x, DATASET_CACHE_VERSION)
        return x

    def get_labels(self):
        """è¿”å› YOLO è®­ç»ƒçš„æ ‡ç­¾å­—å…¸ã€‚"""
        self.label_files = img2label_paths(self.im_files)
        cache_path = Path(self.label_files[0]).parent.with_suffix(".cache")
        try:
            cache, exists = load_dataset_cache_file(cache_path), True  # å°è¯•åŠ è½½ *.cache æ–‡ä»¶
            assert cache["version"] == DATASET_CACHE_VERSION  # ç¡®ä¿ç‰ˆæœ¬ä¸€è‡´
            assert cache["hash"] == get_hash(self.label_files + self.im_files)  # ç¡®ä¿å“ˆå¸Œä¸€è‡´
        except (FileNotFoundError, AssertionError, AttributeError):
            cache, exists = self.cache_labels(cache_path), False  # æ‰§è¡Œç¼“å­˜æ“ä½œ

        # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
        nf, nm, ne, nc, n = cache.pop("results")  # æ‰¾åˆ°çš„ï¼Œç¼ºå¤±çš„ï¼Œç©ºçš„ï¼ŒæŸåçš„ï¼Œæ€»æ•°
        if exists and LOCAL_RANK in {-1, 0}:
            d = f"æ­£åœ¨æ‰«æ {cache_path}... {nf} å¼ å›¾ç‰‡ï¼Œ{nm + ne} ä¸ªèƒŒæ™¯ï¼Œ{nc} ä¸ªæŸå"
            TQDM(None, desc=self.prefix + d, total=n, initial=n)  # æ˜¾ç¤ºç»“æœ
            if cache["msgs"]:
                LOGGER.info("\n".join(cache["msgs"]))  # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯

        # è¯»å–ç¼“å­˜
        [cache.pop(k) for k in ("hash", "version", "msgs")]  # ç§»é™¤ç¼“å­˜ä¸­çš„é¡¹ç›®
        labels = cache["labels"]
        if not labels:
            LOGGER.warning(f"è­¦å‘Š âš ï¸ åœ¨ {cache_path} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ï¼Œè®­ç»ƒå¯èƒ½æ— æ³•æ­£å¸¸è¿›è¡Œã€‚ {HELP_URL}")
        self.im_files = [lb["im_file"] for lb in labels]  # æ›´æ–° im_files

        # æ£€æŸ¥æ•°æ®é›†æ˜¯å…¨æ˜¯æ¡†è¿˜æ˜¯å…¨æ˜¯åˆ†å‰²
        lengths = ((len(lb["cls"]), len(lb["bboxes"]), len(lb["segments"])) for lb in labels)
        len_cls, len_boxes, len_segments = (sum(x) for x in zip(*lengths))
        if len_segments and len_boxes != len_segments:
            LOGGER.warning(
                f"è­¦å‘Š âš ï¸ æ¡†å’Œåˆ†å‰²æ•°é‡åº”è¯¥ç›¸ç­‰ï¼Œä½† len(segments) = {len_segments}, len(boxes) = {len_boxes} ä¸ç›¸ç­‰ã€‚ä¸ºäº†è§£å†³æ­¤é—®é¢˜ï¼Œå°†åªä½¿ç”¨æ¡†ï¼Œå¹¶åˆ é™¤æ‰€æœ‰åˆ†å‰²ã€‚"
                "ä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œè¯·æä¾›æ£€æµ‹æˆ–åˆ†å‰²æ•°æ®é›†ï¼Œè€Œä¸æ˜¯æ£€æµ‹-åˆ†å‰²æ··åˆæ•°æ®é›†ã€‚"
            )
            for lb in labels:
                lb["segments"] = []
        if len_cls == 0:
            LOGGER.warning(f"è­¦å‘Š âš ï¸ åœ¨ {cache_path} ä¸­æœªæ‰¾åˆ°æ ‡ç­¾ï¼Œè®­ç»ƒå¯èƒ½æ— æ³•æ­£å¸¸è¿›è¡Œã€‚ {HELP_URL}")
        return labels

    def build_transforms(self, hyp=None):
        """æ„å»ºå¹¶é™„åŠ å˜æ¢åˆ°åˆ—è¡¨ä¸­ã€‚"""
        if self.augment:
            hyp.mosaic = hyp.mosaic if self.augment and not self.rect else 0.0
            hyp.mixup = hyp.mixup if self.augment and not self.rect else 0.0
            transforms = v8_transforms(self, self.imgsz, hyp)
        else:
            transforms = Compose([LetterBox(new_shape=(self.imgsz, self.imgsz), scaleup=False)])
        transforms.append(
            Format(
                bbox_format="xywh",
                normalize=True,
                return_mask=self.use_segments,
                return_keypoint=self.use_keypoints,
                return_obb=self.use_obb,
                batch_idx=True,
                mask_ratio=hyp.mask_ratio,
                mask_overlap=hyp.overlap_mask,
                bgr=hyp.bgr if self.augment else 0.0,  # ä»…å½±å“è®­ç»ƒ
            )
        )
        return transforms

    def close_mosaic(self, hyp):
        """å°† mosaicã€copy_paste å’Œ mixup é€‰é¡¹è®¾ç½®ä¸º 0.0ï¼Œå¹¶æ„å»ºå˜æ¢ã€‚"""
        hyp.mosaic = 0.0  # è®¾ç½® mosaic æ¯”ä¾‹ä¸º 0.0
        hyp.copy_paste = 0.0  # ä¿æŒä¸ä»¥å‰ v8 close-mosaic ç›¸åŒçš„è¡Œä¸º
        hyp.mixup = 0.0  # ä¿æŒä¸ä»¥å‰ v8 close-mosaic ç›¸åŒçš„è¡Œä¸º
        self.transforms = self.build_transforms(hyp)

    def update_labels_info(self, label):
        """
        åœ¨æ­¤å¤„è‡ªå®šä¹‰æ‚¨çš„æ ‡ç­¾æ ¼å¼ã€‚

        æ³¨æ„ï¼š
            cls ä¸å†åŒ…å« bboxesï¼Œç°åœ¨åˆ†ç±»å’Œè¯­ä¹‰åˆ†å‰²éœ€è¦ç‹¬ç«‹çš„ cls æ ‡ç­¾
            è¿˜å¯ä»¥é€šè¿‡æ·»åŠ æˆ–åˆ é™¤å­—å…¸é”®æ¥æ”¯æŒåˆ†ç±»å’Œè¯­ä¹‰åˆ†å‰²ã€‚
        """
        bboxes = label.pop("bboxes")
        segments = label.pop("segments", [])
        keypoints = label.pop("keypoints", None)
        bbox_format = label.pop("bbox_format")
        normalized = label.pop("normalized")

        # æ³¨æ„ï¼šä¸è¦é‡æ–°é‡‡æ ·æœ‰å®šå‘æ¡†çš„
        segment_resamples = 100 if self.use_obb else 1000
        if len(segments) > 0:
            # ç¡®ä¿å¦‚æœåŸå§‹é•¿åº¦å¤§äº segment_resamples æ—¶ï¼Œåˆ†å‰²æ­£ç¡®æ’å€¼
            max_len = max(len(s) for s in segments)
            segment_resamples = (max_len + 1) if segment_resamples < max_len else segment_resamples
            # list[np.array(segment_resamples, 2)] * num_samples
            segments = np.stack(resample_segments(segments, n=segment_resamples), axis=0)
        else:
            segments = np.zeros((0, segment_resamples, 2), dtype=np.float32)
        label["instances"] = Instances(bboxes, segments, keypoints, bbox_format=bbox_format, normalized=normalized)
        return label

    @staticmethod
    def collate_fn(batch):
        """å°†æ•°æ®æ ·æœ¬åˆå¹¶ä¸ºæ‰¹æ¬¡ã€‚"""
        new_batch = {}
        keys = batch[0].keys()
        values = list(zip(*[list(b.values()) for b in batch]))
        for i, k in enumerate(keys):
            value = values[i]
            if k == "img":
                value = torch.stack(value, 0)
            if k in {"masks", "keypoints", "bboxes", "cls", "segments", "obb"}:
                value = torch.cat(value, 0)
            new_batch[k] = value
        new_batch["batch_idx"] = list(new_batch["batch_idx"])
        for i in range(len(new_batch["batch_idx"])):
            new_batch["batch_idx"][i] += i  # ä¸º build_targets() æ·»åŠ ç›®æ ‡å›¾åƒç´¢å¼•
        new_batch["batch_idx"] = torch.cat(new_batch["batch_idx"], 0)
        return new_batch


class YOLOMultiModalDataset(YOLODataset):
    """
    ç”¨äºåŠ è½½YOLOæ ¼å¼çš„ç›®æ ‡æ£€æµ‹å’Œ/æˆ–åˆ†å‰²æ ‡ç­¾çš„æ•°æ®é›†ç±»ã€‚

    å‚æ•°ï¼š
        data (dict, å¯é€‰): ä¸€ä¸ªæ•°æ®é›†çš„YAMLå­—å…¸ã€‚é»˜è®¤ä¸ºNoneã€‚
        task (str): ä¸€ä¸ªæ˜ç¡®çš„å‚æ•°æ¥æŒ‡å®šå½“å‰ä»»åŠ¡ï¼Œé»˜è®¤ä¸º'detect'ã€‚

    è¿”å›ï¼š
        (torch.utils.data.Dataset): ä¸€ä¸ªPyTorchæ•°æ®é›†å¯¹è±¡ï¼Œå¯ç”¨äºè®­ç»ƒç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚
    """

    def __init__(self, *args, data=None, task="detect", **kwargs):
        """åˆå§‹åŒ–ä¸€ä¸ªç”¨äºç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„æ•°æ®é›†å¯¹è±¡ï¼Œå¯ä»¥é€‰æ‹©æ€§åœ°æŒ‡å®šå…¶ä»–å‚æ•°ã€‚"""
        super().__init__(*args, data=data, task=task, **kwargs)

    def update_labels_info(self, label):
        """ä¸ºå¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒæ·»åŠ æ–‡æœ¬ä¿¡æ¯ã€‚"""
        labels = super().update_labels_info(label)
        # æ³¨æ„ï¼šæŸäº›ç±»åˆ«ä¸å…¶åŒä¹‰è¯é€šè¿‡â€œ/â€è¿›è¡Œè¿æ¥ã€‚
        labels["texts"] = [v.split("/") for _, v in self.data["names"].items()]
        return labels

    def build_transforms(self, hyp=None):
        """å¢å¼ºæ•°æ®è½¬æ¢ï¼Œæ”¯æŒå¤šæ¨¡æ€è®­ç»ƒæ—¶çš„æ–‡æœ¬æ•°æ®å¢å¼ºã€‚"""
        transforms = super().build_transforms(hyp)
        if self.augment:
            # æ³¨æ„ï¼šç›®å‰ç¡¬ç¼–ç äº†è¿™äº›å‚æ•°ã€‚
            transforms.insert(-1, RandomLoadText(max_samples=min(self.data["nc"], 80), padding=True))
        return transforms


class GroundingDataset(YOLODataset):
    """å¤„ç†ç›®æ ‡æ£€æµ‹ä»»åŠ¡ï¼Œé€šè¿‡ä»æŒ‡å®šçš„ JSON æ–‡ä»¶åŠ è½½æ³¨é‡Šï¼Œæ”¯æŒ YOLO æ ¼å¼ã€‚"""

    def __init__(self, *args, task="detect", json_file, **kwargs):
        """åˆå§‹åŒ– GroundingDataset è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œä»æŒ‡å®šçš„ JSON æ–‡ä»¶åŠ è½½æ³¨é‡Šã€‚"""
        assert task == "detect", "`GroundingDataset` ç›®å‰åªæ”¯æŒ `detect` ä»»åŠ¡ï¼"
        self.json_file = json_file
        super().__init__(*args, task=task, data={}, **kwargs)

    def get_img_files(self, img_path):
        """å›¾åƒæ–‡ä»¶å°†åœ¨ `get_labels` å‡½æ•°ä¸­è¯»å–ï¼Œè¿™é‡Œè¿”å›ç©ºåˆ—è¡¨ã€‚"""
        return []

    def get_labels(self):
        """ä» JSON æ–‡ä»¶åŠ è½½æ³¨é‡Šï¼Œè¿‡æ»¤å¹¶å½’ä¸€åŒ–æ¯ä¸ªå›¾åƒçš„è¾¹ç•Œæ¡†ã€‚"""
        labels = []
        LOGGER.info("æ­£åœ¨åŠ è½½æ³¨é‡Šæ–‡ä»¶...")
        with open(self.json_file) as f:
            annotations = json.load(f)
        images = {f"{x['id']:d}": x for x in annotations["images"]}
        img_to_anns = defaultdict(list)
        for ann in annotations["annotations"]:
            img_to_anns[ann["image_id"]].append(ann)
        for img_id, anns in TQDM(img_to_anns.items(), desc=f"æ­£åœ¨è¯»å–æ³¨é‡Š {self.json_file}"):
            img = images[f"{img_id:d}"]
            h, w, f = img["height"], img["width"], img["file_name"]
            im_file = Path(self.img_path) / f
            if not im_file.exists():
                continue
            self.im_files.append(str(im_file))
            bboxes = []
            cat2id = {}
            texts = []
            for ann in anns:
                if ann["iscrowd"]:
                    continue
                box = np.array(ann["bbox"], dtype=np.float32)
                box[:2] += box[2:] / 2
                box[[0, 2]] /= float(w)
                box[[1, 3]] /= float(h)
                if box[2] <= 0 or box[3] <= 0:
                    continue

                caption = img["caption"]
                cat_name = " ".join([caption[t[0] : t[1]] for t in ann["tokens_positive"]])
                if cat_name not in cat2id:
                    cat2id[cat_name] = len(cat2id)
                    texts.append([cat_name])
                cls = cat2id[cat_name]  # ç±»åˆ«
                box = [cls] + box.tolist()
                if box not in bboxes:
                    bboxes.append(box)
            lb = np.array(bboxes, dtype=np.float32) if len(bboxes) else np.zeros((0, 5), dtype=np.float32)
            labels.append(
                {
                    "im_file": im_file,
                    "shape": (h, w),
                    "cls": lb[:, 0:1],  # n, 1
                    "bboxes": lb[:, 1:],  # n, 4
                    "normalized": True,
                    "bbox_format": "xywh",
                    "texts": texts,
                }
            )
        return labels

    def build_transforms(self, hyp=None):
        """é…ç½®è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼ºï¼ŒåŒ…æ‹¬å¯é€‰çš„æ–‡æœ¬åŠ è½½ï¼›`hyp` è°ƒæ•´å¢å¼ºçš„å¼ºåº¦ã€‚"""
        transforms = super().build_transforms(hyp)
        if self.augment:
            # æ³¨æ„ï¼šå½“å‰ç¡¬ç¼–ç äº†å‚æ•°ã€‚
            transforms.insert(-1, RandomLoadText(max_samples=80, padding=True))
        return transforms


class YOLOConcatDataset(ConcatDataset):
    """
    ä½œä¸ºå¤šä¸ªæ•°æ®é›†æ‹¼æ¥çš„æ•°æ®é›†ç±»ã€‚

    è¿™ä¸ªç±»ç”¨äºç»„è£…ä¸åŒçš„ç°æœ‰æ•°æ®é›†ã€‚
    """

    @staticmethod
    def collate_fn(batch):
        """å°†æ•°æ®æ ·æœ¬æ•´ç†æˆæ‰¹æ¬¡ã€‚"""
        return YOLODataset.collate_fn(batch)


# TODO: æ”¯æŒè¯­ä¹‰åˆ†å‰²
class SemanticDataset(BaseDataset):
    """
    è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ã€‚

    è¿™ä¸ªç±»è´Ÿè´£å¤„ç†ç”¨äºè¯­ä¹‰åˆ†å‰²ä»»åŠ¡çš„æ•°æ®é›†ã€‚å®ƒç»§æ‰¿äº†BaseDatasetç±»çš„åŠŸèƒ½ã€‚

    æ³¨æ„ï¼š
        ç›®å‰è¿™ä¸ªç±»æ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œéœ€è¦å¡«å……æ–¹æ³•å’Œå±æ€§ä»¥æ”¯æŒè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ–ä¸€ä¸ªSemanticDatasetå¯¹è±¡ã€‚"""
        super().__init__()


class ClassificationDataset:
    """
    æ‰©å±•äº†torchvisionçš„ImageFolderï¼Œä»¥æ”¯æŒYOLOåˆ†ç±»ä»»åŠ¡ï¼Œæä¾›å›¾åƒå¢å¼ºã€ç¼“å­˜å’ŒéªŒè¯ç­‰åŠŸèƒ½ã€‚
    è¯¥ç±»æ—¨åœ¨é«˜æ•ˆå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°è¿›è¡Œå›¾åƒå˜æ¢å’Œç¼“å­˜æœºåˆ¶ï¼Œä»¥åŠ é€Ÿè®­ç»ƒã€‚

    æ­¤ç±»æ”¯æŒä½¿ç”¨torchvisionå’ŒAlbumentationsåº“è¿›è¡Œå¢å¼ºï¼Œå¹¶æ”¯æŒå°†å›¾åƒç¼“å­˜åˆ°RAMæˆ–ç£ç›˜ä¸Šï¼Œä»¥å‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­çš„IOå¼€é”€ã€‚
    æ­¤å¤–ï¼Œå®ƒè¿˜å®ç°äº†ä¸€ä¸ªå¼ºå¤§çš„éªŒè¯è¿‡ç¨‹ï¼Œä»¥ç¡®ä¿æ•°æ®çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§ã€‚

    å±æ€§ï¼š
        cache_ram (bool): æŒ‡ç¤ºæ˜¯å¦å¯ç”¨RAMç¼“å­˜ã€‚
        cache_disk (bool): æŒ‡ç¤ºæ˜¯å¦å¯ç”¨ç£ç›˜ç¼“å­˜ã€‚
        samples (list): ä¸€ä¸ªåŒ…å«å…ƒç»„çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç»„åŒ…å«å›¾åƒè·¯å¾„ã€å…¶ç±»åˆ«ç´¢å¼•ã€å…¶.npæ–‡ä»¶çš„è·¯å¾„
                        ï¼ˆå¦‚æœä½¿ç”¨ç£ç›˜ç¼“å­˜ï¼‰ï¼Œä»¥åŠå¯é€‰çš„å·²åŠ è½½çš„å›¾åƒæ•°ç»„ï¼ˆå¦‚æœä½¿ç”¨RAMç¼“å­˜ï¼‰ã€‚
        torch_transforms (callable): åº”ç”¨äºå›¾åƒçš„PyTorchå˜æ¢å‡½æ•°ã€‚
    """

    def __init__(self, root, args, augment=False, prefix=""):
        """
        ä½¿ç”¨æ ¹ç›®å½•ã€å›¾åƒå¤§å°ã€å¢å¼ºå’Œç¼“å­˜è®¾ç½®åˆå§‹åŒ–YOLOå¯¹è±¡ã€‚

        å‚æ•°ï¼š
            root (str): æ•°æ®é›†ç›®å½•è·¯å¾„ï¼Œå…¶ä¸­å›¾åƒä»¥ç±»åˆ«ç‰¹å®šçš„æ–‡ä»¶å¤¹ç»“æ„å­˜å‚¨ã€‚
            args (Namespace): åŒ…å«æ•°æ®é›†ç›¸å…³è®¾ç½®çš„é…ç½®ï¼Œå¦‚å›¾åƒå¤§å°ã€å¢å¼ºå‚æ•°å’Œç¼“å­˜è®¾ç½®ã€‚å®ƒåŒ…æ‹¬å±æ€§å¦‚`imgsz`ï¼ˆå›¾åƒå¤§å°ï¼‰ã€
                `fraction`ï¼ˆä½¿ç”¨çš„æ•°æ®æ¯”ä¾‹ï¼‰ã€`scale`ã€`fliplr`ã€`flipud`ã€`cache`ï¼ˆç”¨äºæ›´å¿«è®­ç»ƒçš„ç£ç›˜æˆ–RAMç¼“å­˜ï¼‰ã€`auto_augment`ã€
                `hsv_h`ã€`hsv_s`ã€`hsv_v`å’Œ`crop_fraction`ç­‰ã€‚
            augment (bool, å¯é€‰): æ˜¯å¦å¯¹æ•°æ®é›†è¿›è¡Œå¢å¼ºã€‚é»˜è®¤ä¸ºFalseã€‚
            prefix (str, å¯é€‰): æ—¥å¿—å’Œç¼“å­˜æ–‡ä»¶åçš„å‰ç¼€ï¼Œå¸®åŠ©æ•°æ®é›†çš„è¯†åˆ«å’Œè°ƒè¯•ã€‚é»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²ã€‚
        """
        import torchvision  # ç”¨äºåŠ é€Ÿ'import ultralytics'

        # å°†åŸºç±»ä½œä¸ºå±æ€§åˆ†é…ï¼Œè€Œä¸æ˜¯ç”¨ä½œåŸºç±»ï¼Œä»¥ä¾¿åœ¨å¯¼å…¥torchvisionæ—¶è¿›è¡Œä½œç”¨åŸŸæ§åˆ¶
        if TORCHVISION_0_18:  # 'allow_empty'å‚æ•°é¦–æ¬¡åœ¨torchvision 0.18ä¸­å¼•å…¥
            self.base = torchvision.datasets.ImageFolder(root=root, allow_empty=True)
        else:
            self.base = torchvision.datasets.ImageFolder(root=root)
        self.samples = self.base.samples
        self.root = self.base.root

        # åˆå§‹åŒ–å±æ€§
        if augment and args.fraction < 1.0:  # å‡å°‘è®­ç»ƒæ•°æ®æ¯”ä¾‹
            self.samples = self.samples[: round(len(self.samples) * args.fraction)]
        self.prefix = colorstr(f"{prefix}: ") if prefix else ""
        self.cache_ram = args.cache is True or str(args.cache).lower() == "ram"  # å°†å›¾åƒç¼“å­˜åˆ°RAMä¸­
        if self.cache_ram:
            LOGGER.warning(
                "WARNING âš ï¸ åˆ†ç±»è®­ç»ƒ `cache_ram` åœ¨ "
                "https://github.com/ultralytics/ultralytics/issues/9824 ä¸­æœ‰å·²çŸ¥å†…å­˜æ³„æ¼é—®é¢˜ï¼Œæ­£åœ¨å°† `cache_ram=False`ã€‚"
            )
            self.cache_ram = False
        self.cache_disk = str(args.cache).lower() == "disk"  # å°†å›¾åƒç¼“å­˜åˆ°ç¡¬ç›˜ä¸Šï¼Œä½œä¸ºæœªå‹ç¼©çš„*.npyæ–‡ä»¶
        self.samples = self.verify_images()  # è¿‡æ»¤æ‰åçš„å›¾åƒ
        self.samples = [list(x) + [Path(x[0]).with_suffix(".npy"), None] for x in self.samples]  # æ–‡ä»¶ã€ç´¢å¼•ã€npyã€å›¾åƒ
        scale = (1.0 - args.scale, 1.0)  # (0.08, 1.0)
        self.torch_transforms = (
            classify_augmentations(
                size=args.imgsz,
                scale=scale,
                hflip=args.fliplr,
                vflip=args.flipud,
                erasing=args.erasing,
                auto_augment=args.auto_augment,
                hsv_h=args.hsv_h,
                hsv_s=args.hsv_s,
                hsv_v=args.hsv_v,
            )
            if augment
            else classify_transforms(size=args.imgsz, crop_fraction=args.crop_fraction)
        )

    def __getitem__(self, i):
        """è¿”å›ä¸ç»™å®šç´¢å¼•å¯¹åº”çš„æ•°æ®å’Œç›®æ ‡å­é›†ã€‚"""
        f, j, fn, im = self.samples[i]  # æ–‡ä»¶åã€ç´¢å¼•ã€æ–‡ä»¶å.with_suffix('.npy')ã€å›¾åƒ
        if self.cache_ram:
            if im is None:  # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¸¤ä¸ªå•ç‹¬çš„ifè¯­å¥ï¼Œä¸èƒ½å°†å…¶ä¸å‰é¢çš„è¡Œåˆå¹¶
                im = self.samples[i][3] = cv2.imread(f)
        elif self.cache_disk:
            if not fn.exists():  # åŠ è½½npyæ–‡ä»¶
                np.save(fn.as_posix(), cv2.imread(f), allow_pickle=False)
            im = np.load(fn)
        else:  # è¯»å–å›¾åƒ
            im = cv2.imread(f)  # BGR
        # å°†NumPyæ•°ç»„è½¬æ¢ä¸ºPILå›¾åƒ
        im = Image.fromarray(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))
        sample = self.torch_transforms(im)
        return {"img": sample, "cls": j}

    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†ä¸­çš„æ ·æœ¬æ€»æ•°ã€‚"""
        return len(self.samples)

    def verify_images(self):
        """éªŒè¯æ•°æ®é›†ä¸­çš„æ‰€æœ‰å›¾åƒã€‚"""
        desc = f"{self.prefix}æ‰«æ {self.root}..."
        path = Path(self.root).with_suffix(".cache")  # *.cacheæ–‡ä»¶è·¯å¾„

        try:
            cache = load_dataset_cache_file(path)  # å°è¯•åŠ è½½*.cacheæ–‡ä»¶
            assert cache["version"] == DATASET_CACHE_VERSION  # ä¸å½“å‰ç‰ˆæœ¬åŒ¹é…
            assert cache["hash"] == get_hash([x[0] for x in self.samples])  # å“ˆå¸Œå€¼ç›¸åŒ
            nf, nc, n, samples = cache.pop("results")  # æ‰¾åˆ°ã€ç¼ºå¤±ã€ç©ºç™½ã€æŸåã€æ€»æ•°
            if LOCAL_RANK in {-1, 0}:
                d = f"{desc} {nf} å›¾åƒ, {nc} æŸå"
                TQDM(None, desc=d, total=n, initial=n)
                if cache["msgs"]:
                    LOGGER.info("\n".join(cache["msgs"]))  # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
            return samples

        except (FileNotFoundError, AssertionError, AttributeError):
            # å¦‚æœæ— æ³•æ£€ç´¢*.cacheï¼Œåˆ™è¿è¡Œæ‰«æ
            nf, nc, msgs, samples, x = 0, 0, [], [], {}
            with ThreadPool(NUM_THREADS) as pool:
                results = pool.imap(func=verify_image, iterable=zip(self.samples, repeat(self.prefix)))
                pbar = TQDM(results, desc=desc, total=len(self.samples))
                for sample, nf_f, nc_f, msg in pbar:
                    if nf_f:
                        samples.append(sample)
                    if msg:
                        msgs.append(msg)
                    nf += nf_f
                    nc += nc_f
                    pbar.desc = f"{desc} {nf} å›¾åƒ, {nc} æŸå"
                pbar.close()
            if msgs:
                LOGGER.info("\n".join(msgs))
            x["hash"] = get_hash([x[0] for x in self.samples])
            x["results"] = nf, nc, len(samples), samples
            x["msgs"] = msgs  # è­¦å‘Šä¿¡æ¯
            save_dataset_cache_file(self.prefix, path, x, DATASET_CACHE_VERSION)
            return samples
