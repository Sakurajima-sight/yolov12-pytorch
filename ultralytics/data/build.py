# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import os
import random
from pathlib import Path

import numpy as np
import torch
from PIL import Image
from torch.utils.data import dataloader, distributed

from ultralytics.data.dataset import GroundingDataset, YOLODataset, YOLOMultiModalDataset
from ultralytics.data.loaders import (
    LOADERS,
    LoadImagesAndVideos,
    LoadPilAndNumpy,
    LoadScreenshots,
    LoadStreams,
    LoadTensor,
    SourceTypes,
    autocast_list,
)
from ultralytics.data.utils import IMG_FORMATS, PIN_MEMORY, VID_FORMATS
from ultralytics.utils import RANK, colorstr
from ultralytics.utils.checks import check_file


class InfiniteDataLoader(dataloader.DataLoader):
    """
    æ— é™æ•°æ®åŠ è½½å™¨ï¼Œé‡å¤ä½¿ç”¨å·¥ä½œçº¿ç¨‹ã€‚

    ä½¿ç”¨ä¸æ™®é€šDataLoaderç›¸åŒçš„è¯­æ³•ã€‚
    """

    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–ä¸€ä¸ªæ— é™å¾ªç¯å›æ”¶å·¥ä½œçº¿ç¨‹çš„æ•°æ®åŠ è½½å™¨ï¼Œç»§æ‰¿è‡ªDataLoaderã€‚"""
        super().__init__(*args, **kwargs)
        object.__setattr__(self, "batch_sampler", _RepeatSampler(self.batch_sampler))
        self.iterator = super().__iter__()

    def __len__(self):
        """è¿”å›æ‰¹æ¬¡é‡‡æ ·å™¨çš„é•¿åº¦ã€‚"""
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        """åˆ›å»ºä¸€ä¸ªå¯ä»¥æ— é™é‡å¤çš„é‡‡æ ·å™¨ã€‚"""
        for _ in range(len(self)):
            yield next(self.iterator)

    def __del__(self):
        """ç¡®ä¿å·¥ä½œçº¿ç¨‹è¢«ç»ˆæ­¢ã€‚"""
        if hasattr(self.iterator, "_workers"):
            for w in self.iterator._workers:  # å¼ºåˆ¶ç»ˆæ­¢
                if w.is_alive():
                    w.terminate()
            self.iterator._shutdown_workers()  # æ¸…ç†å·¥ä½œçº¿ç¨‹

    def reset(self):
        """
        é‡ç½®è¿­ä»£å™¨ã€‚

        å½“æˆ‘ä»¬åœ¨è®­ç»ƒæ—¶æƒ³è¦ä¿®æ”¹æ•°æ®é›†è®¾ç½®æ—¶ï¼Œè¿™ä¸ªæ–¹æ³•éå¸¸æœ‰ç”¨ã€‚
        """
        self.iterator = self._get_iterator()


class _RepeatSampler:
    """
    ä¸€ä¸ªæ°¸è¿œé‡å¤çš„é‡‡æ ·å™¨ã€‚

    å‚æ•°ï¼š
        sampler (Dataset.sampler): è¦é‡å¤çš„é‡‡æ ·å™¨ã€‚
    """

    def __init__(self, sampler):
        """åˆå§‹åŒ–ä¸€ä¸ªæ°¸è¿œé‡å¤ç»™å®šé‡‡æ ·å™¨çš„å¯¹è±¡ã€‚"""
        self.sampler = sampler

    def __iter__(self):
        """è¿­ä»£'sampler'å¹¶ä¸æ–­è¾“å‡ºå…¶å†…å®¹ã€‚"""
        while True:
            yield from iter(self.sampler)


def seed_worker(worker_id):  # noqa
    """è®¾ç½®dataloaderå·¥ä½œçº¿ç¨‹çš„ç§å­ https://pytorch.org/docs/stable/notes/randomness.html#dataloaderã€‚"""
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)


def build_yolo_dataset(cfg, img_path, batch, data, mode="train", rect=False, stride=32, multi_modal=False):
    """æ„å»ºYOLOæ•°æ®é›†ã€‚"""
    dataset = YOLOMultiModalDataset if multi_modal else YOLODataset
    return dataset(
        img_path=img_path,
        imgsz=cfg.imgsz,
        batch_size=batch,
        augment=mode == "train",  # æ•°æ®å¢å¼º
        hyp=cfg,  # TODO: å¯èƒ½éœ€è¦æ·»åŠ ä¸€ä¸ªä»cfgè·å–è¶…å‚æ•°çš„å‡½æ•°
        rect=cfg.rect or rect,  # æ˜¯å¦ä½¿ç”¨çŸ©å½¢æ‰¹æ¬¡
        cache=cfg.cache or None,
        single_cls=cfg.single_cls or False,
        stride=int(stride),
        pad=0.0 if mode == "train" else 0.5,
        prefix=colorstr(f"{mode}: "),
        task=cfg.task,
        classes=cfg.classes,
        data=data,
        fraction=cfg.fraction if mode == "train" else 1.0,
    )


def build_grounding(cfg, img_path, json_file, batch, mode="train", rect=False, stride=32):
    """æ„å»ºYOLOæ•°æ®é›†ã€‚"""
    return GroundingDataset(
        img_path=img_path,
        json_file=json_file,
        imgsz=cfg.imgsz,
        batch_size=batch,
        augment=mode == "train",  # æ•°æ®å¢å¼º
        hyp=cfg,  # TODO: å¯èƒ½éœ€è¦æ·»åŠ ä¸€ä¸ªä»cfgè·å–è¶…å‚æ•°çš„å‡½æ•°
        rect=cfg.rect or rect,  # çŸ©å½¢æ‰¹æ¬¡
        cache=cfg.cache or None,
        single_cls=cfg.single_cls or False,
        stride=int(stride),
        pad=0.0 if mode == "train" else 0.5,
        prefix=colorstr(f"{mode}: "),
        task=cfg.task,
        classes=cfg.classes,
        fraction=cfg.fraction if mode == "train" else 1.0,
    )


def build_dataloader(dataset, batch, workers, shuffle=True, rank=-1):
    """è¿”å›ç”¨äºè®­ç»ƒæˆ–éªŒè¯é›†çš„InfiniteDataLoaderæˆ–DataLoaderã€‚"""
    batch = min(batch, len(dataset))
    nd = torch.cuda.device_count()  # CUDAè®¾å¤‡æ•°é‡
    nw = min(os.cpu_count() // max(nd, 1), workers)  # å·¥ä½œçº¿ç¨‹æ•°é‡
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    generator = torch.Generator()
    generator.manual_seed(6148914691236517205 + RANK)
    return InfiniteDataLoader(
        dataset=dataset,
        batch_size=batch,
        shuffle=shuffle and sampler is None,
        num_workers=nw,
        sampler=sampler,
        pin_memory=PIN_MEMORY,
        collate_fn=getattr(dataset, "collate_fn", None),
        worker_init_fn=seed_worker,
        generator=generator,
    )


def check_source(source):
    """æ£€æŸ¥æºç±»å‹å¹¶è¿”å›å¯¹åº”çš„æ ‡å¿—å€¼ã€‚"""
    webcam, screenshot, from_img, in_memory, tensor = False, False, False, False, False
    if isinstance(source, (str, int, Path)):  # å¯¹äºæœ¬åœ°USBæ‘„åƒå¤´ï¼Œintç±»å‹
        source = str(source)
        is_file = Path(source).suffix[1:] in (IMG_FORMATS | VID_FORMATS)
        is_url = source.lower().startswith(("https://", "http://", "rtsp://", "rtmp://", "tcp://"))
        webcam = source.isnumeric() or source.endswith(".streams") or (is_url and not is_file)
        screenshot = source.lower() == "screen"
        if is_url and is_file:
            source = check_file(source)  # ä¸‹è½½
    elif isinstance(source, LOADERS):
        in_memory = True
    elif isinstance(source, (list, tuple)):
        source = autocast_list(source)  # å°†æ‰€æœ‰åˆ—è¡¨å…ƒç´ è½¬æ¢ä¸ºPILæˆ–npæ•°ç»„
        from_img = True
    elif isinstance(source, (Image.Image, np.ndarray)):
        from_img = True
    elif isinstance(source, torch.Tensor):
        tensor = True
    else:
        raise TypeError("ä¸æ”¯æŒçš„å›¾åƒç±»å‹ã€‚æœ‰å…³æ”¯æŒçš„ç±»å‹ï¼Œè¯·å‚è§ https://docs.ultralytics.com/modes/predict")

    return source, webcam, screenshot, from_img, in_memory, tensor


def load_inference_source(source=None, batch=1, vid_stride=1, buffer=False):
    """
    åŠ è½½ç”¨äºç›®æ ‡æ£€æµ‹çš„æ¨ç†æºï¼Œå¹¶åº”ç”¨å¿…è¦çš„è½¬æ¢ã€‚

    å‚æ•°ï¼š
        source (str, Path, Tensor, PIL.Image, np.ndarray): ç”¨äºæ¨ç†çš„è¾“å…¥æºã€‚
        batch (int, å¯é€‰): æ•°æ®åŠ è½½å™¨çš„æ‰¹æ¬¡å¤§å°ã€‚é»˜è®¤ä¸º1ã€‚
        vid_stride (int, å¯é€‰): è§†é¢‘æºçš„å¸§é—´éš”ã€‚é»˜è®¤ä¸º1ã€‚
        buffer (bool, å¯é€‰): ç¡®å®šæ˜¯å¦ç¼“å†²æµå¸§ã€‚é»˜è®¤ä¸ºFalseã€‚

    è¿”å›ï¼š
        dataset (Dataset): ä¸ºæŒ‡å®šè¾“å…¥æºåˆ›å»ºçš„æ•°æ®é›†å¯¹è±¡ã€‚
    """
    source, stream, screenshot, from_img, in_memory, tensor = check_source(source)
    source_type = source.source_type if in_memory else SourceTypes(stream, screenshot, from_img, tensor)

    # æ•°æ®åŠ è½½å™¨
    if tensor:
        dataset = LoadTensor(source)
    elif in_memory:
        dataset = source
    elif stream:
        dataset = LoadStreams(source, vid_stride=vid_stride, buffer=buffer)
    elif screenshot:
        dataset = LoadScreenshots(source)
    elif from_img:
        dataset = LoadPilAndNumpy(source)
    else:
        dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)

    # å°†æºç±»å‹é™„åŠ åˆ°æ•°æ®é›†
    setattr(dataset, "source_type", source_type)

    return dataset
