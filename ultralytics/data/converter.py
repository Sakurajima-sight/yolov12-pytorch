# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import json
import random
import shutil
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

import cv2
import numpy as np
from PIL import Image

from ultralytics.utils import DATASETS_DIR, LOGGER, NUM_THREADS, TQDM
from ultralytics.utils.downloads import download
from ultralytics.utils.files import increment_path


def coco91_to_coco80_class():
    """
    å°†91ç´¢å¼•çš„COCOç±»åˆ«IDè½¬æ¢ä¸º80ç´¢å¼•çš„COCOç±»åˆ«IDã€‚

    è¿”å›ï¼š
        (list): ä¸€ä¸ªåŒ…å«91ä¸ªç±»åˆ«IDçš„åˆ—è¡¨ï¼Œå…¶ä¸­ç´¢å¼•è¡¨ç¤º80ç´¢å¼•ç±»åˆ«IDï¼Œå€¼ä¸ºå¯¹åº”çš„91ç´¢å¼•ç±»åˆ«IDã€‚
    """
    return [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        None,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        None,
        24,
        25,
        None,
        None,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        None,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        None,
        60,
        None,
        None,
        61,
        None,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        None,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        None,
    ]


def coco80_to_coco91_class():
    r"""
    å°†80ç´¢å¼•ï¼ˆval2014ï¼‰è½¬æ¢ä¸º91ç´¢å¼•ï¼ˆè®ºæ–‡ä¸­çš„ç±»åˆ«IDï¼‰ã€‚
    è¯¦æƒ…è¯·è§ https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/ã€‚

    ç¤ºä¾‹ï¼š
        ```python
        import numpy as np

        a = np.loadtxt("data/coco.names", dtype="str", delimiter="\n")
        b = np.loadtxt("data/coco_paper.names", dtype="str", delimiter="\n")
        x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknetè½¬coco
        x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # cocoè½¬darknet
        ```
    """
    return [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        27,
        28,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        67,
        70,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
    ]


def convert_coco(
    labels_dir="../coco/annotations/",
    save_dir="coco_converted/",
    use_segments=False,
    use_keypoints=False,
    cls91to80=True,
    lvis=False,
):
    """
    å°†COCOæ•°æ®é›†çš„æ³¨é‡Šè½¬æ¢ä¸ºé€‚ç”¨äºè®­ç»ƒYOLOæ¨¡å‹çš„YOLOæ³¨é‡Šæ ¼å¼ã€‚

    å‚æ•°ï¼š
        labels_dir (str, å¯é€‰): åŒ…å«COCOæ•°æ®é›†æ³¨é‡Šæ–‡ä»¶çš„ç›®å½•è·¯å¾„ã€‚
        save_dir (str, å¯é€‰): ç”¨äºä¿å­˜ç»“æœçš„ç›®å½•è·¯å¾„ã€‚
        use_segments (bool, å¯é€‰): æ˜¯å¦åœ¨è¾“å‡ºä¸­åŒ…å«åˆ†å‰²æ©ç ã€‚
        use_keypoints (bool, å¯é€‰): æ˜¯å¦åœ¨è¾“å‡ºä¸­åŒ…å«å…³é”®ç‚¹æ³¨é‡Šã€‚
        cls91to80 (bool, å¯é€‰): æ˜¯å¦å°†91ä¸ªCOCOç±»åˆ«IDè½¬æ¢ä¸ºå¯¹åº”çš„80ä¸ªCOCOç±»åˆ«IDã€‚
        lvis (bool, å¯é€‰): æ˜¯å¦ä»¥lvisæ•°æ®é›†çš„æ–¹å¼è½¬æ¢æ•°æ®ã€‚

    ç¤ºä¾‹ï¼š
        ```python
        from ultralytics.data.converter import convert_coco

        convert_coco("../datasets/coco/annotations/", use_segments=True, use_keypoints=False, cls91to80=False)
        convert_coco(
            "../datasets/lvis/annotations/", use_segments=True, use_keypoints=False, cls91to80=False, lvis=True
        )
        ```

    è¾“å‡ºï¼š
        åœ¨æŒ‡å®šçš„è¾“å‡ºç›®å½•ä¸­ç”Ÿæˆè¾“å‡ºæ–‡ä»¶ã€‚
    """
    # åˆ›å»ºæ•°æ®é›†ç›®å½•
    save_dir = increment_path(save_dir)  # å¦‚æœä¿å­˜ç›®å½•å·²å­˜åœ¨ï¼Œåˆ™é€’å¢ç›®å½•åç§°
    for p in save_dir / "labels", save_dir / "images":
        p.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®å½•

    # è½¬æ¢ç±»åˆ«
    coco80 = coco91_to_coco80_class()

    # å¯¼å…¥json
    for json_file in sorted(Path(labels_dir).resolve().glob("*.json")):
        lname = "" if lvis else json_file.stem.replace("instances_", "")
        fn = Path(save_dir) / "labels" / lname  # æ–‡ä»¶å¤¹åç§°
        fn.mkdir(parents=True, exist_ok=True)
        if lvis:
            # NOTE: æå‰ä¸ºtrainå’Œvalåˆ›å»ºæ–‡ä»¶å¤¹ï¼Œ
            # å› ä¸ºLVISçš„valé›†åŒ…å«COCO 2017è®­ç»ƒé›†ä¸­çš„å›¾åƒï¼Œä»¥åŠCOCO 2017éªŒè¯é›†ä¸­çš„å›¾åƒã€‚
            (fn / "train2017").mkdir(parents=True, exist_ok=True)
            (fn / "val2017").mkdir(parents=True, exist_ok=True)
        with open(json_file, encoding="utf-8") as f:
            data = json.load(f)

        # åˆ›å»ºå›¾åƒå­—å…¸
        images = {f"{x['id']:d}": x for x in data["images"]}
        # åˆ›å»ºå›¾åƒ-æ³¨é‡Šå­—å…¸
        imgToAnns = defaultdict(list)
        for ann in data["annotations"]:
            imgToAnns[ann["image_id"]].append(ann)

        image_txt = []
        # å†™å…¥æ ‡ç­¾æ–‡ä»¶
        for img_id, anns in TQDM(imgToAnns.items(), desc=f"Annotations {json_file}"):
            img = images[f"{img_id:d}"]
            h, w = img["height"], img["width"]
            f = str(Path(img["coco_url"]).relative_to("http://images.cocodataset.org")) if lvis else img["file_name"]
            if lvis:
                image_txt.append(str(Path("./images") / f))

            bboxes = []
            segments = []
            keypoints = []
            for ann in anns:
                if ann.get("iscrowd", False):
                    continue
                # COCOæ¡†çš„æ ¼å¼æ˜¯ [å·¦ä¸Šè§’x, å·¦ä¸Šè§’y, å®½åº¦, é«˜åº¦]
                box = np.array(ann["bbox"], dtype=np.float64)
                box[:2] += box[2:] / 2  # å°†å·¦ä¸Šè§’åæ ‡è½¬æ¢ä¸ºä¸­å¿ƒåæ ‡
                box[[0, 2]] /= w  # xåæ ‡å½’ä¸€åŒ–
                box[[1, 3]] /= h  # yåæ ‡å½’ä¸€åŒ–
                if box[2] <= 0 or box[3] <= 0:  # å¦‚æœå®½åº¦æˆ–é«˜åº¦<=0
                    continue

                cls = coco80[ann["category_id"] - 1] if cls91to80 else ann["category_id"] - 1  # ç±»åˆ«
                box = [cls] + box.tolist()
                if box not in bboxes:
                    bboxes.append(box)
                    if use_segments and ann.get("segmentation") is not None:
                        if len(ann["segmentation"]) == 0:
                            segments.append([])
                            continue
                        elif len(ann["segmentation"]) > 1:
                            s = merge_multi_segment(ann["segmentation"])
                            s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()
                        else:
                            s = [j for i in ann["segmentation"] for j in i]  # æ‰€æœ‰åˆ†å‰²åŒºåŸŸåˆå¹¶
                            s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()
                        s = [cls] + s
                        segments.append(s)
                    if use_keypoints and ann.get("keypoints") is not None:
                        keypoints.append(
                            box + (np.array(ann["keypoints"]).reshape(-1, 3) / np.array([w, h, 1])).reshape(-1).tolist()
                        )

            # å†™å…¥æ–‡ä»¶
            with open((fn / f).with_suffix(".txt"), "a") as file:
                for i in range(len(bboxes)):
                    if use_keypoints:
                        line = (*(keypoints[i]),)  # ç±»åˆ«ï¼Œæ¡†ï¼Œå…³é”®ç‚¹
                    else:
                        line = (
                            *(segments[i] if use_segments and len(segments[i]) > 0 else bboxes[i]),  # ç±»åˆ«ï¼Œæ¡†æˆ–åˆ†å‰²åŒºåŸŸ
                        )
                    file.write(("%g " * len(line)).rstrip() % line + "\n")

        if lvis:
            with open((Path(save_dir) / json_file.name.replace("lvis_v1_", "").replace(".json", ".txt")), "a") as f:
                f.writelines(f"{line}\n" for line in image_txt)

    LOGGER.info(f"{'LVIS' if lvis else 'COCO'} æ•°æ®æˆåŠŸè½¬æ¢ã€‚\nç»“æœå·²ä¿å­˜è‡³ {save_dir.resolve()}")


def convert_segment_masks_to_yolo_seg(masks_dir, output_dir, classes):
    """
    å°†åˆ†å‰²æ©è†œå›¾åƒæ•°æ®é›†è½¬æ¢ä¸º YOLO åˆ†å‰²æ ¼å¼ã€‚

    è¯¥å‡½æ•°å°†åŒ…å«äºŒè¿›åˆ¶æ ¼å¼æ©è†œå›¾åƒçš„ç›®å½•ä¸­çš„å›¾åƒè½¬æ¢ä¸º YOLO åˆ†å‰²æ ¼å¼ã€‚
    è½¬æ¢åçš„æ©è†œå°†ä¿å­˜åœ¨æŒ‡å®šçš„è¾“å‡ºç›®å½•ä¸­ã€‚

    å‚æ•°:
        masks_dir (str): å­˜å‚¨æ‰€æœ‰æ©è†œå›¾åƒï¼ˆpng, jpgï¼‰çš„ç›®å½•è·¯å¾„ã€‚
        output_dir (str): å­˜å‚¨è½¬æ¢åçš„ YOLO åˆ†å‰²æ©è†œçš„ç›®å½•è·¯å¾„ã€‚
        classes (int): æ•°æ®é›†ä¸­çš„æ€»ç±»åˆ«æ•°ï¼Œä¾‹å¦‚ COCO æ•°æ®é›†æœ‰ 80 ä¸ªç±»åˆ«ã€‚

    ç¤ºä¾‹:
        ```python
        from ultralytics.data.converter import convert_segment_masks_to_yolo_seg

        # è¿™é‡Œçš„ classes æ˜¯æ•°æ®é›†ä¸­çš„æ€»ç±»åˆ«æ•°ï¼Œå¯¹äº COCO æ•°æ®é›†ï¼Œç±»æ•°ä¸º 80
        convert_segment_masks_to_yolo_seg("path/to/masks_directory", "path/to/output/directory", classes=80)
        ```

    è¯´æ˜:
        æ©è†œå›¾åƒçš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

            - masks
                â”œâ”€ mask_image_01.png æˆ– mask_image_01.jpg
                â”œâ”€ mask_image_02.png æˆ– mask_image_02.jpg
                â”œâ”€ mask_image_03.png æˆ– mask_image_03.jpg
                â””â”€ mask_image_04.png æˆ– mask_image_04.jpg

        æ‰§è¡Œåï¼Œæ ‡ç­¾å°†è¢«ç»„ç»‡æˆä»¥ä¸‹ç»“æ„ï¼š

            - output_dir
                â”œâ”€ mask_yolo_01.txt
                â”œâ”€ mask_yolo_02.txt
                â”œâ”€ mask_yolo_03.txt
                â””â”€ mask_yolo_04.txt
    """
    pixel_to_class_mapping = {i + 1: i for i in range(classes)}
    for mask_path in Path(masks_dir).iterdir():
        if mask_path.suffix in {".png", ".jpg"}:
            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)  # ä»¥ç°åº¦æ¨¡å¼è¯»å–æ©è†œå›¾åƒ
            img_height, img_width = mask.shape  # è·å–å›¾åƒå°ºå¯¸
            LOGGER.info(f"æ­£åœ¨å¤„ç† {mask_path} imgsz = {img_height} x {img_width}")

            unique_values = np.unique(mask)  # è·å–ä»£è¡¨ä¸åŒç±»åˆ«çš„å”¯ä¸€åƒç´ å€¼
            yolo_format_data = []

            for value in unique_values:
                if value == 0:
                    continue  # è·³è¿‡èƒŒæ™¯
                class_index = pixel_to_class_mapping.get(value, -1)
                if class_index == -1:
                    LOGGER.warning(f"æ–‡ä»¶ {mask_path} ä¸­åƒç´ å€¼ {value} çš„ç±»åˆ«æœªçŸ¥ï¼Œè·³è¿‡è¯¥å€¼ã€‚")
                    continue

                # ä¸ºå½“å‰ç±»åˆ«åˆ›å»ºäºŒè¿›åˆ¶æ©è†œå¹¶æ‰¾åˆ°è½®å»“
                contours, _ = cv2.findContours(
                    (mask == value).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
                )  # æŸ¥æ‰¾è½®å»“

                for contour in contours:
                    if len(contour) >= 3:  # YOLO è¦æ±‚è‡³å°‘æœ‰ 3 ä¸ªç‚¹æ‰èƒ½ä½œä¸ºæœ‰æ•ˆçš„åˆ†å‰²
                        contour = contour.squeeze()  # å»é™¤å•ä¸€ç»´åº¦çš„æ¡ç›®
                        yolo_format = [class_index]
                        for point in contour:
                            # æ ‡å‡†åŒ–åæ ‡
                            yolo_format.append(round(point[0] / img_width, 6))  # ä¿ç•™ 6 ä½å°æ•°
                            yolo_format.append(round(point[1] / img_height, 6))
                        yolo_format_data.append(yolo_format)
            # å°† Ultralytics YOLO æ ¼å¼çš„æ•°æ®ä¿å­˜åˆ°æ–‡ä»¶
            output_path = Path(output_dir) / f"{mask_path.stem}.txt"
            with open(output_path, "w") as file:
                for item in yolo_format_data:
                    line = " ".join(map(str, item))
                    file.write(line + "\n")
            LOGGER.info(f"å·²å¤„ç†å¹¶å­˜å‚¨åœ¨ {output_path} imgsz = {img_height} x {img_width}")


def convert_dota_to_yolo_obb(dota_root_path: str):
    """
    å°† DOTA æ•°æ®é›†æ³¨é‡Šè½¬æ¢ä¸º YOLO OBBï¼ˆå®šå‘è¾¹ç•Œæ¡†ï¼‰æ ¼å¼ã€‚

    è¯¥å‡½æ•°å¤„ç† DOTA æ•°æ®é›†çš„ 'train' å’Œ 'val' æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒã€‚å¯¹äºæ¯ä¸ªå›¾åƒï¼Œå®ƒè¯»å–å…³è”çš„æ ‡ç­¾æ–‡ä»¶å¹¶å°†æ–°çš„æ ‡ç­¾ä»¥ YOLO OBB æ ¼å¼å†™å…¥æ–°çš„ç›®å½•ã€‚

    å‚æ•°:
        dota_root_path (str): DOTA æ•°æ®é›†çš„æ ¹ç›®å½•è·¯å¾„ã€‚

    ç¤ºä¾‹:
        ```python
        from ultralytics.data.converter import convert_dota_to_yolo_obb

        convert_dota_to_yolo_obb("path/to/DOTA")
        ```

    è¯´æ˜:
        å‡è®¾ DOTA æ•°æ®é›†çš„ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

            - DOTA
                â”œâ”€ images
                â”‚   â”œâ”€ train
                â”‚   â””â”€ val
                â””â”€ labels
                    â”œâ”€ train_original
                    â””â”€ val_original

        æ‰§è¡Œåï¼Œæ ‡ç­¾å°†è¢«ç»„ç»‡æˆï¼š

            - DOTA
                â””â”€ labels
                    â”œâ”€ train
                    â””â”€ val
    """
    dota_root_path = Path(dota_root_path)

    # ç±»åˆ«åç§°åˆ°ç´¢å¼•çš„æ˜ å°„
    class_mapping = {
        "plane": 0,
        "ship": 1,
        "storage-tank": 2,
        "baseball-diamond": 3,
        "tennis-court": 4,
        "basketball-court": 5,
        "ground-track-field": 6,
        "harbor": 7,
        "bridge": 8,
        "large-vehicle": 9,
        "small-vehicle": 10,
        "helicopter": 11,
        "roundabout": 12,
        "soccer-ball-field": 13,
        "swimming-pool": 14,
        "container-crane": 15,
        "airport": 16,
        "helipad": 17,
    }

    def convert_label(image_name, image_width, image_height, orig_label_dir, save_dir):
        """å°†å•ä¸ªå›¾åƒçš„ DOTA æ³¨é‡Šè½¬æ¢ä¸º YOLO OBB æ ¼å¼å¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚"""
        orig_label_path = orig_label_dir / f"{image_name}.txt"
        save_path = save_dir / f"{image_name}.txt"

        with orig_label_path.open("r") as f, save_path.open("w") as g:
            lines = f.readlines()
            for line in lines:
                parts = line.strip().split()
                if len(parts) < 9:
                    continue
                class_name = parts[8]
                class_idx = class_mapping[class_name]
                coords = [float(p) for p in parts[:8]]
                normalized_coords = [
                    coords[i] / image_width if i % 2 == 0 else coords[i] / image_height for i in range(8)
                ]
                formatted_coords = [f"{coord:.6g}" for coord in normalized_coords]
                g.write(f"{class_idx} {' '.join(formatted_coords)}\n")

    for phase in ["train", "val"]:
        image_dir = dota_root_path / "images" / phase
        orig_label_dir = dota_root_path / "labels" / f"{phase}_original"
        save_dir = dota_root_path / "labels" / phase

        save_dir.mkdir(parents=True, exist_ok=True)

        image_paths = list(image_dir.iterdir())
        for image_path in TQDM(image_paths, desc=f"æ­£åœ¨å¤„ç† {phase} å›¾åƒ"):
            if image_path.suffix != ".png":
                continue
            image_name_without_ext = image_path.stem
            img = cv2.imread(str(image_path))
            h, w = img.shape[:2]
            convert_label(image_name_without_ext, w, h, orig_label_dir, save_dir)


def min_index(arr1, arr2):
    """
    æ‰¾åˆ°ä¸¤ä¸ª 2D ç‚¹æ•°ç»„ä¹‹é—´è·ç¦»æœ€çŸ­çš„ä¸€å¯¹ç´¢å¼•ã€‚

    å‚æ•°:
        arr1 (np.ndarray): å½¢çŠ¶ä¸º (N, 2) çš„ NumPy æ•°ç»„ï¼Œè¡¨ç¤º N ä¸ª 2D ç‚¹ã€‚
        arr2 (np.ndarray): å½¢çŠ¶ä¸º (M, 2) çš„ NumPy æ•°ç»„ï¼Œè¡¨ç¤º M ä¸ª 2D ç‚¹ã€‚

    è¿”å›:
        (tuple): åŒ…å« arr1 å’Œ arr2 ä¸­è·ç¦»æœ€çŸ­çš„ç‚¹çš„ç´¢å¼•çš„å…ƒç»„ã€‚
    """
    dis = ((arr1[:, None, :] - arr2[None, :, :]) ** 2).sum(-1)
    return np.unravel_index(np.argmin(dis, axis=None), dis.shape)


def merge_multi_segment(segments):
    """
    å°†å¤šä¸ªåˆ†æ®µåˆå¹¶ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œé€šè¿‡è¿æ¥æ¯ä¸ªåˆ†æ®µä¹‹é—´æœ€å°è·ç¦»çš„åæ ‡æ¥å®ç°åˆå¹¶ã€‚
    æ­¤å‡½æ•°é€šè¿‡ä½¿ç”¨ä¸€æ¡ç»†çº¿è¿æ¥è¿™äº›åæ ‡ï¼Œåˆå¹¶æ‰€æœ‰åˆ†æ®µä¸ºä¸€ä¸ªã€‚

    å‚æ•°ï¼š
        segments (List[List]): æ¥è‡ªCOCO JSONæ–‡ä»¶çš„åŸå§‹åˆ†æ®µã€‚
                               æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåæ ‡åˆ—è¡¨ï¼Œä¾‹å¦‚[segmentation1, segmentation2,...]ã€‚

    è¿”å›ï¼š
        s (List[np.ndarray]): ä¸€ä¸ªè¡¨ç¤ºå·²è¿æ¥åˆ†æ®µçš„NumPyæ•°ç»„åˆ—è¡¨ã€‚
    """
    s = []
    segments = [np.array(i).reshape(-1, 2) for i in segments]
    idx_list = [[] for _ in range(len(segments))]

    # è®°å½•æ¯ä¸ªåˆ†æ®µä¹‹é—´æœ€å°è·ç¦»çš„ç´¢å¼•
    for i in range(1, len(segments)):
        idx1, idx2 = min_index(segments[i - 1], segments[i])
        idx_list[i - 1].append(idx1)
        idx_list[i].append(idx2)

    # ä½¿ç”¨ä¸¤è½®è¿æ¥æ‰€æœ‰åˆ†æ®µ
    for k in range(2):
        # æ­£å‘è¿æ¥
        if k == 0:
            for i, idx in enumerate(idx_list):
                # ä¸­é—´çš„åˆ†æ®µæœ‰ä¸¤ä¸ªç´¢å¼•ï¼Œå¦‚æœä¸­é—´çš„åˆ†æ®µç´¢å¼•é¡ºåºæ˜¯åçš„ï¼Œåˆ™å°†å…¶åè½¬
                if len(idx) == 2 and idx[0] > idx[1]:
                    idx = idx[::-1]
                    segments[i] = segments[i][::-1, :]

                segments[i] = np.roll(segments[i], -idx[0], axis=0)
                segments[i] = np.concatenate([segments[i], segments[i][:1]])
                # å¤„ç†ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªåˆ†æ®µ
                if i in {0, len(idx_list) - 1}:
                    s.append(segments[i])
                else:
                    idx = [0, idx[1] - idx[0]]
                    s.append(segments[i][idx[0] : idx[1] + 1])

        else:
            for i in range(len(idx_list) - 1, -1, -1):
                if i not in {0, len(idx_list) - 1}:
                    idx = idx_list[i]
                    nidx = abs(idx[1] - idx[0])
                    s.append(segments[i][nidx:])
    return s


def yolo_bbox2segment(im_dir, save_dir=None, sam_model="sam_b.pt", device=None):
    """
    å°†ç°æœ‰çš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼ˆè¾¹ç•Œæ¡†ï¼‰è½¬æ¢ä¸ºåˆ†å‰²æ•°æ®é›†æˆ–æœ‰å‘è¾¹ç•Œæ¡†ï¼ˆOBBï¼‰
    ä»¥YOLOæ ¼å¼ç”Ÿæˆåˆ†å‰²æ•°æ®ï¼Œå¿…è¦æ—¶ä½¿ç”¨SAMè‡ªåŠ¨æ ‡æ³¨å™¨ç”Ÿæˆåˆ†å‰²æ•°æ®ã€‚

    å‚æ•°ï¼š
        im_dir (str | Path): è¦è½¬æ¢çš„å›¾åƒç›®å½•è·¯å¾„ã€‚
        save_dir (str | Path): è¦ä¿å­˜ç”Ÿæˆçš„æ ‡ç­¾çš„è·¯å¾„ã€‚å¦‚æœsave_dirä¸ºNoneï¼Œæ ‡ç­¾å°†ä¿å­˜åˆ°
            ä¸im_diråŒçº§ç›®å½•ä¸­çš„â€œlabels-segmentâ€æ–‡ä»¶å¤¹ã€‚é»˜è®¤å€¼ï¼šNoneã€‚
        sam_model (str): ç”¨äºä¸­é—´åˆ†å‰²æ•°æ®çš„åˆ†å‰²æ¨¡å‹ï¼›å¯é€‰ã€‚
        device (int | str): è¿è¡ŒSAMæ¨¡å‹çš„å…·ä½“è®¾å¤‡ã€‚é»˜è®¤å€¼ï¼šNoneã€‚

    æ³¨æ„ï¼š
        å‡è®¾è¾“å…¥ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

            - im_dir
                â”œâ”€ 001.jpg
                â”œâ”€ ...
                â””â”€ NNN.jpg
            - labels
                â”œâ”€ 001.txt
                â”œâ”€ ...
                â””â”€ NNN.txt
    """
    from ultralytics import SAM
    from ultralytics.data import YOLODataset
    from ultralytics.utils import LOGGER
    from ultralytics.utils.ops import xywh2xyxy

    # æ³¨æ„ï¼šæ·»åŠ å ä½ç¬¦æ¥é€šè¿‡ç±»ç´¢å¼•æ£€æŸ¥
    dataset = YOLODataset(im_dir, data=dict(names=list(range(1000))))
    if len(dataset.labels[0]["segments"]) > 0:  # å¦‚æœæ˜¯åˆ†å‰²æ•°æ®
        LOGGER.info("æ£€æµ‹åˆ°åˆ†å‰²æ ‡ç­¾ï¼Œæ— éœ€ç”Ÿæˆæ–°æ ‡ç­¾ï¼")
        return

    LOGGER.info("æ£€æµ‹åˆ°æ£€æµ‹æ ‡ç­¾ï¼Œæ­£åœ¨ä½¿ç”¨SAMæ¨¡å‹ç”Ÿæˆåˆ†å‰²æ ‡ç­¾ï¼")
    sam_model = SAM(sam_model)
    for label in TQDM(dataset.labels, total=len(dataset.labels), desc="ç”Ÿæˆåˆ†å‰²æ ‡ç­¾"):
        h, w = label["shape"]
        boxes = label["bboxes"]
        if len(boxes) == 0:  # è·³è¿‡æ²¡æœ‰æ ‡ç­¾çš„å›¾ç‰‡
            continue
        boxes[:, [0, 2]] *= w
        boxes[:, [1, 3]] *= h
        im = cv2.imread(label["im_file"])
        sam_results = sam_model(im, bboxes=xywh2xyxy(boxes), verbose=False, save=False, device=device)
        label["segments"] = sam_results[0].masks.xyn

    save_dir = Path(save_dir) if save_dir else Path(im_dir).parent / "labels-segment"
    save_dir.mkdir(parents=True, exist_ok=True)
    for label in dataset.labels:
        texts = []
        lb_name = Path(label["im_file"]).with_suffix(".txt").name
        txt_file = save_dir / lb_name
        cls = label["cls"]
        for i, s in enumerate(label["segments"]):
            if len(s) == 0:
                continue
            line = (int(cls[i]), *s.reshape(-1))
            texts.append(("%g " * len(line)).rstrip() % line)
        with open(txt_file, "a") as f:
            f.writelines(text + "\n" for text in texts)
    LOGGER.info(f"ç”Ÿæˆçš„åˆ†å‰²æ ‡ç­¾å·²ä¿å­˜åˆ° {save_dir}")


def create_synthetic_coco_dataset():
    """
    åˆ›å»ºä¸€ä¸ªåˆæˆçš„COCOæ•°æ®é›†ï¼ŒåŸºäºæ ‡ç­¾åˆ—è¡¨ä¸­çš„æ–‡ä»¶åç”Ÿæˆéšæœºå›¾åƒã€‚

    æ­¤å‡½æ•°ä¸‹è½½COCOæ ‡ç­¾ï¼Œè¯»å–æ ‡ç­¾åˆ—è¡¨æ–‡ä»¶ä¸­çš„å›¾åƒæ–‡ä»¶åï¼Œ
    ä¸ºtrain2017å’Œval2017å­é›†åˆ›å»ºåˆæˆå›¾åƒï¼Œå¹¶å°†å®ƒä»¬ç»„ç»‡åˆ°COCOæ•°æ®é›†ç»“æ„ä¸­ã€‚å®ƒä½¿ç”¨å¤šçº¿ç¨‹é«˜æ•ˆç”Ÿæˆå›¾åƒã€‚

    ç¤ºä¾‹ï¼š
        >>> from ultralytics.data.converter import create_synthetic_coco_dataset
        >>> create_synthetic_coco_dataset()

    æ³¨æ„ï¼š
        - éœ€è¦äº’è”ç½‘è¿æ¥ä¸‹è½½æ ‡ç­¾æ–‡ä»¶ã€‚
        - ç”ŸæˆéšæœºRGBå›¾åƒï¼Œå°ºå¯¸ä»480x480åˆ°640x640åƒç´ ä¸ç­‰ã€‚
        - åˆ é™¤ç°æœ‰çš„test2017ç›®å½•ï¼Œå› ä¸ºä¸éœ€è¦å®ƒã€‚
        - ä»train2017.txtå’Œval2017.txtæ–‡ä»¶ä¸­è¯»å–å›¾åƒæ–‡ä»¶åã€‚
    """

    def create_synthetic_image(image_file):
        """ç”Ÿæˆç”¨äºæ•°æ®é›†å¢å¼ºæˆ–æµ‹è¯•ç›®çš„çš„åˆæˆå›¾åƒï¼Œå›¾åƒçš„å¤§å°å’Œé¢œè‰²æ˜¯éšæœºçš„ã€‚"""
        if not image_file.exists():
            size = (random.randint(480, 640), random.randint(480, 640))
            Image.new(
                "RGB",
                size=size,
                color=(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)),
            ).save(image_file)

    # ä¸‹è½½æ ‡ç­¾
    dir = DATASETS_DIR / "coco"
    url = "https://github.com/ultralytics/assets/releases/download/v0.0.0/"
    label_zip = "coco2017labels-segments.zip"
    download([url + label_zip], dir=dir.parent)

    # åˆ›å»ºåˆæˆå›¾åƒ
    shutil.rmtree(dir / "labels" / "test2017", ignore_errors=True)  # åˆ é™¤ä¸éœ€è¦çš„test2017ç›®å½•
    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:
        for subset in ["train2017", "val2017"]:
            subset_dir = dir / "images" / subset
            subset_dir.mkdir(parents=True, exist_ok=True)

            # ä»æ ‡ç­¾åˆ—è¡¨æ–‡ä»¶ä¸­è¯»å–å›¾åƒæ–‡ä»¶å
            label_list_file = dir / f"{subset}.txt"
            if label_list_file.exists():
                with open(label_list_file) as f:
                    image_files = [dir / line.strip() for line in f]

                # æäº¤æ‰€æœ‰ä»»åŠ¡
                futures = [executor.submit(create_synthetic_image, image_file) for image_file in image_files]
                for _ in TQDM(as_completed(futures), total=len(futures), desc=f"ä¸º{subset}ç”Ÿæˆå›¾åƒ"):
                    pass  # å®é™…å·¥ä½œåœ¨åå°å®Œæˆ
            else:
                print(f"è­¦å‘Šï¼šæ ‡ç­¾æ–‡ä»¶ {label_list_file} ä¸å­˜åœ¨ï¼Œè·³è¿‡{subset}çš„å›¾åƒåˆ›å»ºã€‚")

    print("åˆæˆCOCOæ•°æ®é›†åˆ›å»ºæˆåŠŸã€‚")
