# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import math
import random
from copy import deepcopy
from typing import Tuple, Union

import cv2
import numpy as np
import torch
from PIL import Image

from ultralytics.data.utils import polygons2masks, polygons2masks_overlap
from ultralytics.utils import LOGGER, colorstr
from ultralytics.utils.checks import check_version
from ultralytics.utils.instance import Instances
from ultralytics.utils.metrics import bbox_ioa
from ultralytics.utils.ops import segment2box, xyxyxyxy2xywhr
from ultralytics.utils.torch_utils import TORCHVISION_0_10, TORCHVISION_0_11, TORCHVISION_0_13

DEFAULT_MEAN = (0.0, 0.0, 0.0)
DEFAULT_STD = (1.0, 1.0, 1.0)
DEFAULT_CROP_FRACTION = 1.0


class BaseTransform:
    """
    Ultralyticsåº“ä¸­å›¾åƒå˜æ¢çš„åŸºç±»ã€‚

    è¯¥ç±»ä½œä¸ºå®ç°å„ç§å›¾åƒå¤„ç†æ“ä½œçš„åŸºç¡€ï¼Œæ—¨åœ¨å…¼å®¹åˆ†ç±»ä»»åŠ¡å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ã€‚

    æ–¹æ³•ï¼š
        apply_image: å¯¹æ ‡ç­¾åº”ç”¨å›¾åƒå˜æ¢ã€‚
        apply_instances: å¯¹æ ‡ç­¾ä¸­çš„ç‰©ä½“å®ä¾‹åº”ç”¨å˜æ¢ã€‚
        apply_semantic: å¯¹å›¾åƒåº”ç”¨è¯­ä¹‰åˆ†å‰²ã€‚
        __call__: å¯¹å›¾åƒã€å®ä¾‹å’Œè¯­ä¹‰æ©ç åº”ç”¨æ‰€æœ‰æ ‡ç­¾å˜æ¢ã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = BaseTransform()
        >>> labels = {"image": np.array(...), "instances": [...], "semantic": np.array(...)}
        >>> transformed_labels = transform(labels)
    """

    def __init__(self) -> None:
        """
        åˆå§‹åŒ–BaseTransformå¯¹è±¡ã€‚

        è¯¥æ„é€ å‡½æ•°è®¾ç½®åŸºç¡€å˜æ¢å¯¹è±¡ï¼Œå¯ä»¥æ‰©å±•ç”¨äºç‰¹å®šçš„å›¾åƒå¤„ç†ä»»åŠ¡ã€‚è®¾è®¡æ—¶å…¼å®¹åˆ†ç±»å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseTransform()
        """
        pass

    def apply_image(self, labels):
        """
        å¯¹æ ‡ç­¾åº”ç”¨å›¾åƒå˜æ¢ã€‚

        è¯¥æ–¹æ³•é¢„è®¡ç”±å­ç±»é‡å†™ï¼Œä»¥å®ç°ç‰¹å®šçš„å›¾åƒå˜æ¢é€»è¾‘ã€‚åœ¨åŸºç±»ä¸­ï¼Œè¿”å›çš„æ ‡ç­¾ä¸è¾“å…¥æ ‡ç­¾ç›¸åŒã€‚

        å‚æ•°ï¼š
            labels (Any): è¦è¿›è¡Œå˜æ¢çš„è¾“å…¥æ ‡ç­¾ã€‚å…·ä½“çš„ç±»å‹å’Œç»“æ„å¯èƒ½ä¼šæ ¹æ®å®ç°çš„ä¸åŒè€Œæœ‰æ‰€å˜åŒ–ã€‚

        è¿”å›ï¼š
            (Any): å˜æ¢åçš„æ ‡ç­¾ã€‚åœ¨åŸºç±»å®ç°ä¸­ï¼Œè¿™ä¸è¾“å…¥æ ‡ç­¾ç›¸åŒã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseTransform()
            >>> original_labels = [1, 2, 3]
            >>> transformed_labels = transform.apply_image(original_labels)
            >>> print(transformed_labels)
            [1, 2, 3]
        """
        pass

    def apply_instances(self, labels):
        """
        å¯¹æ ‡ç­¾ä¸­çš„ç‰©ä½“å®ä¾‹åº”ç”¨å˜æ¢ã€‚

        è¯¥æ–¹æ³•è´Ÿè´£å¯¹ç»™å®šæ ‡ç­¾ä¸­çš„ç‰©ä½“å®ä¾‹åº”ç”¨å„ç§å˜æ¢ã€‚è®¾è®¡æ—¶é¢„è®¡ç”±å­ç±»é‡å†™ï¼Œä»¥å®ç°ç‰¹å®šçš„å®ä¾‹å˜æ¢é€»è¾‘ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«æ ‡ç­¾ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬ç‰©ä½“å®ä¾‹ã€‚

        è¿”å›ï¼š
            (Dict): ç»è¿‡å˜æ¢åçš„æ ‡ç­¾å­—å…¸ï¼ŒåŒ…å«ä¿®æ”¹åçš„ç‰©ä½“å®ä¾‹ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseTransform()
            >>> labels = {"instances": Instances(xyxy=torch.rand(5, 4), cls=torch.randint(0, 80, (5,)))}
            >>> transformed_labels = transform.apply_instances(labels)
        """
        pass

    def apply_semantic(self, labels):
        """
        å¯¹å›¾åƒåº”ç”¨è¯­ä¹‰åˆ†å‰²å˜æ¢ã€‚

        è¯¥æ–¹æ³•é¢„è®¡ç”±å­ç±»é‡å†™ï¼Œä»¥å®ç°ç‰¹å®šçš„è¯­ä¹‰åˆ†å‰²å˜æ¢ã€‚åœ¨åŸºç±»ä¸­ï¼Œä¸æ‰§è¡Œä»»ä½•æ“ä½œã€‚

        å‚æ•°ï¼š
            labels (Any): è¦è¿›è¡Œå˜æ¢çš„è¾“å…¥æ ‡ç­¾æˆ–è¯­ä¹‰åˆ†å‰²æ©ç ã€‚

        è¿”å›ï¼š
            (Any): å˜æ¢åçš„è¯­ä¹‰åˆ†å‰²æ©ç æˆ–æ ‡ç­¾ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseTransform()
            >>> semantic_mask = np.zeros((100, 100), dtype=np.uint8)
            >>> transformed_mask = transform.apply_semantic(semantic_mask)
        """
        pass

    def __call__(self, labels):
        """
        å¯¹å›¾åƒã€å®ä¾‹å’Œè¯­ä¹‰æ©ç åº”ç”¨æ‰€æœ‰æ ‡ç­¾å˜æ¢ã€‚

        è¯¥æ–¹æ³•åè°ƒäº†å¯¹è¾“å…¥æ ‡ç­¾åº”ç”¨BaseTransformç±»ä¸­å®šä¹‰çš„å„ç§å˜æ¢ï¼ŒæŒ‰é¡ºåºè°ƒç”¨apply_imageå’Œapply_instancesæ–¹æ³•æ¥å¤„ç†å›¾åƒå’Œç‰©ä½“å®ä¾‹ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ•°æ®å’Œæ³¨é‡Šçš„å­—å…¸ã€‚é¢„æœŸçš„é”®åŒ…æ‹¬'img'ï¼ˆå›¾åƒæ•°æ®ï¼‰å’Œ'instances'ï¼ˆç‰©ä½“å®ä¾‹ï¼‰ã€‚

        è¿”å›ï¼š
            (Dict): ç»è¿‡å˜æ¢åçš„è¾“å…¥æ ‡ç­¾å­—å…¸ï¼ŒåŒ…å«å˜æ¢åçš„å›¾åƒå’Œå®ä¾‹ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseTransform()
            >>> labels = {"img": np.random.rand(640, 640, 3), "instances": []}
            >>> transformed_labels = transform(labels)
        """
        self.apply_image(labels)
        self.apply_instances(labels)
        self.apply_semantic(labels)


class Compose:
    """
    ç”¨äºç»„åˆå¤šä¸ªå›¾åƒå˜æ¢çš„ç±»ã€‚

    å±æ€§ï¼š
        transforms (List[Callable]): è¦ä¾æ¬¡åº”ç”¨çš„å˜æ¢å‡½æ•°åˆ—è¡¨ã€‚

    æ–¹æ³•ï¼š
        __call__: å¯¹è¾“å…¥æ•°æ®åº”ç”¨ä¸€ç³»åˆ—å˜æ¢ã€‚
        append: å°†ä¸€ä¸ªæ–°çš„å˜æ¢è¿½åŠ åˆ°ç°æœ‰çš„å˜æ¢åˆ—è¡¨ä¸­ã€‚
        insert: åœ¨æŒ‡å®šçš„ç´¢å¼•ä½ç½®æ’å…¥ä¸€ä¸ªæ–°çš„å˜æ¢ã€‚
        __getitem__: ä½¿ç”¨ç´¢å¼•æ£€ç´¢ä¸€ä¸ªç‰¹å®šçš„å˜æ¢æˆ–ä¸€ç»„å˜æ¢ã€‚
        __setitem__: ä½¿ç”¨ç´¢å¼•è®¾ç½®ä¸€ä¸ªç‰¹å®šçš„å˜æ¢æˆ–ä¸€ç»„å˜æ¢ã€‚
        tolist: å°†å˜æ¢åˆ—è¡¨è½¬æ¢ä¸ºæ ‡å‡†çš„Pythonåˆ—è¡¨ã€‚

    ç¤ºä¾‹ï¼š
        >>> transforms = [RandomFlip(), RandomPerspective(30)]
        >>> compose = Compose(transforms)
        >>> transformed_data = compose(data)
        >>> compose.append(CenterCrop((224, 224)))
        >>> compose.insert(0, RandomFlip())
    """

    def __init__(self, transforms):
        """
        ä½¿ç”¨å˜æ¢åˆ—è¡¨åˆå§‹åŒ–Composeå¯¹è±¡ã€‚

        å‚æ•°ï¼š
            transforms (List[Callable]): è¦ä¾æ¬¡åº”ç”¨çš„å¯è°ƒç”¨å˜æ¢å¯¹è±¡åˆ—è¡¨ã€‚

        ç¤ºä¾‹ï¼š
            >>> from ultralytics.data.augment import Compose, RandomHSV, RandomFlip
            >>> transforms = [RandomHSV(), RandomFlip()]
            >>> compose = Compose(transforms)
        """
        self.transforms = transforms if isinstance(transforms, list) else [transforms]

    def __call__(self, data):
        """
        å¯¹è¾“å…¥æ•°æ®åº”ç”¨ä¸€ç³»åˆ—å˜æ¢ã€‚è¯¥æ–¹æ³•ä¾æ¬¡å¯¹Composeå¯¹è±¡çš„å˜æ¢åˆ—è¡¨ä¸­çš„æ¯ä¸ªå˜æ¢åº”ç”¨åˆ°è¾“å…¥æ•°æ®ä¸Šã€‚

        å‚æ•°ï¼š
            data (Any): è¦å˜æ¢çš„è¾“å…¥æ•°æ®ã€‚æ•°æ®ç±»å‹å¯ä»¥æ ¹æ®å˜æ¢åˆ—è¡¨ä¸­çš„å˜æ¢è€Œä¸åŒã€‚

        è¿”å›ï¼š
            (Any): åº”ç”¨æ‰€æœ‰å˜æ¢åçš„æ•°æ®ã€‚

        ç¤ºä¾‹ï¼š
            >>> transforms = [Transform1(), Transform2(), Transform3()]
            >>> compose = Compose(transforms)
            >>> transformed_data = compose(input_data)
        """
        for t in self.transforms:
            data = t(data)
        return data

    def append(self, transform):
        """
        å°†ä¸€ä¸ªæ–°çš„å˜æ¢è¿½åŠ åˆ°ç°æœ‰çš„å˜æ¢åˆ—è¡¨ä¸­ã€‚

        å‚æ•°ï¼š
            transform (BaseTransform): è¦æ·»åŠ åˆ°ç»„åˆä¸­çš„å˜æ¢ã€‚

        ç¤ºä¾‹ï¼š
            >>> compose = Compose([RandomFlip(), RandomPerspective()])
            >>> compose.append(RandomHSV())
        """
        self.transforms.append(transform)

    def insert(self, index, transform):
        """
        åœ¨ç°æœ‰çš„å˜æ¢åˆ—è¡¨ä¸­ï¼Œåœ¨æŒ‡å®šç´¢å¼•ä½ç½®æ’å…¥ä¸€ä¸ªæ–°çš„å˜æ¢ã€‚

        å‚æ•°ï¼š
            index (int): è¦æ’å…¥æ–°å˜æ¢çš„ç´¢å¼•ä½ç½®ã€‚
            transform (BaseTransform): è¦æ’å…¥çš„å˜æ¢å¯¹è±¡ã€‚

        ç¤ºä¾‹ï¼š
            >>> compose = Compose([Transform1(), Transform2()])
            >>> compose.insert(1, Transform3())
            >>> len(compose.transforms)
            3
        """
        self.transforms.insert(index, transform)

    def __getitem__(self, index: Union[list, int]) -> "Compose":
        """
        ä½¿ç”¨ç´¢å¼•æ£€ç´¢ä¸€ä¸ªç‰¹å®šçš„å˜æ¢æˆ–ä¸€ç»„å˜æ¢ã€‚

        å‚æ•°ï¼š
            index (int | List[int]): è¦æ£€ç´¢çš„å˜æ¢ç´¢å¼•æˆ–ç´¢å¼•åˆ—è¡¨ã€‚

        è¿”å›ï¼š
            (Compose): ä¸€ä¸ªæ–°çš„Composeå¯¹è±¡ï¼ŒåŒ…å«æ‰€é€‰çš„å˜æ¢ã€‚

        å¼‚å¸¸ï¼š
            AssertionError: å¦‚æœç´¢å¼•ç±»å‹ä¸æ˜¯intæˆ–listã€‚

        ç¤ºä¾‹ï¼š
            >>> transforms = [RandomFlip(), RandomPerspective(10), RandomHSV(0.5, 0.5, 0.5)]
            >>> compose = Compose(transforms)
            >>> single_transform = compose[1]  # è¿”å›ä¸€ä¸ªåªåŒ…å«RandomPerspectiveçš„Composeå¯¹è±¡
            >>> multiple_transforms = compose[0:2]  # è¿”å›ä¸€ä¸ªåŒ…å«RandomFlipå’ŒRandomPerspectiveçš„Composeå¯¹è±¡
        """
        assert isinstance(index, (int, list)), f"ç´¢å¼•åº”ä¸ºlistæˆ–intç±»å‹ï¼Œä½†è·å¾—äº†{type(index)}"
        index = [index] if isinstance(index, int) else index
        return Compose([self.transforms[i] for i in index])

    def __setitem__(self, index: Union[list, int], value: Union[list, int]) -> None:
        """
        ä½¿ç”¨ç´¢å¼•è®¾ç½®ä¸€ä¸ªæˆ–å¤šä¸ªå˜æ¢ã€‚

        å‚æ•°ï¼š
            index (int | List[int]): è¦è®¾ç½®å˜æ¢çš„ç´¢å¼•æˆ–ç´¢å¼•åˆ—è¡¨ã€‚
            value (Any | List[Any]): è¦è®¾ç½®çš„å˜æ¢æˆ–å˜æ¢åˆ—è¡¨ã€‚

        å¼‚å¸¸ï¼š
            AssertionError: å¦‚æœç´¢å¼•ç±»å‹æ— æ•ˆï¼Œæˆ–è€…å€¼ç±»å‹ä¸ç´¢å¼•ç±»å‹ä¸åŒ¹é…ï¼Œæˆ–è€…ç´¢å¼•è¶…å‡ºèŒƒå›´ã€‚

        ç¤ºä¾‹ï¼š
            >>> compose = Compose([Transform1(), Transform2(), Transform3()])
            >>> compose[1] = NewTransform()  # æ›¿æ¢ç¬¬äºŒä¸ªå˜æ¢
            >>> compose[0:2] = [NewTransform1(), NewTransform2()]  # æ›¿æ¢å‰ä¸¤ä¸ªå˜æ¢
        """
        assert isinstance(index, (int, list)), f"ç´¢å¼•åº”ä¸ºlistæˆ–intç±»å‹ï¼Œä½†è·å¾—äº†{type(index)}"
        if isinstance(index, list):
            assert isinstance(value, list), (
                f"ç´¢å¼•åº”ä¸å€¼ç±»å‹ç›¸åŒï¼Œä½†è·å¾—äº†{type(index)}å’Œ{type(value)}"
            )
        if isinstance(index, int):
            index, value = [index], [value]
        for i, v in zip(index, value):
            assert i < len(self.transforms), f"åˆ—è¡¨ç´¢å¼•{i}è¶…å‡ºäº†èŒƒå›´ {len(self.transforms)}ã€‚"
            self.transforms[i] = v

    def tolist(self):
        """
        å°†å˜æ¢åˆ—è¡¨è½¬æ¢ä¸ºæ ‡å‡†çš„Pythonåˆ—è¡¨ã€‚

        è¿”å›ï¼š
            (List): åŒ…å«Composeå®ä¾‹ä¸­æ‰€æœ‰å˜æ¢å¯¹è±¡çš„åˆ—è¡¨ã€‚

        ç¤ºä¾‹ï¼š
            >>> transforms = [RandomFlip(), RandomPerspective(10), CenterCrop()]
            >>> compose = Compose(transforms)
            >>> transform_list = compose.tolist()
            >>> print(len(transform_list))
            3
        """
        return self.transforms

    def __repr__(self):
        """
        è¿”å›Composeå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºã€‚

        è¿”å›ï¼š
            (str): Composeå¯¹è±¡çš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼ŒåŒ…æ‹¬å˜æ¢åˆ—è¡¨ã€‚

        ç¤ºä¾‹ï¼š
            >>> transforms = [RandomFlip(), RandomPerspective(degrees=10, translate=0.1, scale=0.1)]
            >>> compose = Compose(transforms)
            >>> print(compose)
            Compose([
                RandomFlip(),
                RandomPerspective(degrees=10, translate=0.1, scale=0.1)
            ])
        """
        return f"{self.__class__.__name__}({', '.join([f'{t}' for t in self.transforms])})"


class BaseMixTransform:
    """
    æ··åˆå˜æ¢çš„åŸºç±»ï¼Œå¦‚MixUpå’ŒMosaicã€‚

    è¯¥ç±»ä¸ºåœ¨æ•°æ®é›†ä¸Šå®ç°æ··åˆå˜æ¢æä¾›äº†åŸºç¡€ã€‚å®ƒå¤„ç†åŸºäºæ¦‚ç‡çš„å˜æ¢åº”ç”¨ï¼Œå¹¶ç®¡ç†å¤šä¸ªå›¾åƒå’Œæ ‡ç­¾çš„æ··åˆã€‚

    å±æ€§ï¼š
        dataset (Any): åŒ…å«å›¾åƒå’Œæ ‡ç­¾çš„æ•°æ®é›†å¯¹è±¡ã€‚
        pre_transform (Callable | None): å¯é€‰çš„åœ¨æ··åˆä¹‹å‰åº”ç”¨çš„å˜æ¢ã€‚
        p (float): åº”ç”¨æ··åˆå˜æ¢çš„æ¦‚ç‡ã€‚

    æ–¹æ³•ï¼š
        __call__: å¯¹è¾“å…¥æ ‡ç­¾åº”ç”¨æ··åˆå˜æ¢ã€‚
        _mix_transform: æŠ½è±¡æ–¹æ³•ï¼Œç”±å­ç±»å®ç°å…·ä½“çš„æ··åˆæ“ä½œã€‚
        get_indexes: æŠ½è±¡æ–¹æ³•ï¼Œç”¨äºè·å–éœ€è¦æ··åˆçš„å›¾åƒç´¢å¼•ã€‚
        _update_label_text: æ›´æ–°æ··åˆå›¾åƒçš„æ ‡ç­¾æ–‡æœ¬ã€‚

    ç¤ºä¾‹ï¼š
        >>> class CustomMixTransform(BaseMixTransform):
        ...     def _mix_transform(self, labels):
        ...         # åœ¨è¿™é‡Œå®ç°è‡ªå®šä¹‰çš„æ··åˆé€»è¾‘
        ...         return labels
        ...
        ...     def get_indexes(self):
        ...         return [random.randint(0, len(self.dataset) - 1) for _ in range(3)]
        >>> dataset = YourDataset()
        >>> transform = CustomMixTransform(dataset, p=0.5)
        >>> mixed_labels = transform(original_labels)
    """

    def __init__(self, dataset, pre_transform=None, p=0.0) -> None:
        """
        ä¸ºæ··åˆå˜æ¢ï¼ˆå¦‚MixUpå’ŒMosaicï¼‰åˆå§‹åŒ–BaseMixTransformå¯¹è±¡ã€‚

        è¯¥ç±»ä½œä¸ºåœ¨å›¾åƒå¤„ç†ç®¡é“ä¸­å®ç°æ··åˆå˜æ¢çš„åŸºç¡€ã€‚

        å‚æ•°ï¼š
            dataset (Any): åŒ…å«å›¾åƒå’Œæ ‡ç­¾çš„æ•°æ®é›†å¯¹è±¡ï¼Œç”¨äºæ··åˆã€‚
            pre_transform (Callable | None): å¯é€‰çš„åœ¨æ··åˆä¹‹å‰åº”ç”¨çš„å˜æ¢ã€‚
            p (float): åº”ç”¨æ··åˆå˜æ¢çš„æ¦‚ç‡ï¼Œåº”è¯¥åœ¨[0.0, 1.0]èŒƒå›´å†…ã€‚

        ç¤ºä¾‹ï¼š
            >>> dataset = YOLODataset("path/to/data")
            >>> pre_transform = Compose([RandomFlip(), RandomPerspective()])
            >>> mix_transform = BaseMixTransform(dataset, pre_transform, p=0.5)
        """
        self.dataset = dataset
        self.pre_transform = pre_transform
        self.p = p

    def __call__(self, labels):
        """
        å¯¹æ ‡ç­¾æ•°æ®åº”ç”¨é¢„å¤„ç†å˜æ¢å’ŒMixUp/Mosaicå˜æ¢ã€‚

        è¯¥æ–¹æ³•æ ¹æ®æ¦‚ç‡å› å­å†³å®šæ˜¯å¦åº”ç”¨æ··åˆå˜æ¢ã€‚å¦‚æœåº”ç”¨ï¼Œå®ƒä¼šé€‰æ‹©é¢å¤–çš„å›¾åƒï¼Œåº”ç”¨é¢„å˜æ¢ï¼ˆå¦‚æœæŒ‡å®šäº†ï¼‰ï¼Œç„¶åæ‰§è¡Œæ··åˆå˜æ¢ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ ‡ç­¾æ•°æ®çš„å­—å…¸ã€‚

        è¿”å›ï¼š
            (Dict): ç»è¿‡å˜æ¢çš„æ ‡ç­¾å­—å…¸ï¼Œå¯èƒ½åŒ…å«æ¥è‡ªå…¶ä»–å›¾åƒçš„æ··åˆæ•°æ®ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseMixTransform(dataset, pre_transform=None, p=0.5)
            >>> result = transform({"image": img, "bboxes": boxes, "cls": classes})
        """
        if random.uniform(0, 1) > self.p:
            return labels

        # è·å–ä¸€ä¸ªæˆ–ä¸‰ä¸ªå…¶ä»–å›¾åƒçš„ç´¢å¼•
        indexes = self.get_indexes()
        if isinstance(indexes, int):
            indexes = [indexes]

        # è·å–å°†ç”¨äºMosaicæˆ–MixUpçš„å›¾åƒä¿¡æ¯
        mix_labels = [self.dataset.get_image_and_label(i) for i in indexes]

        if self.pre_transform is not None:
            for i, data in enumerate(mix_labels):
                mix_labels[i] = self.pre_transform(data)
        labels["mix_labels"] = mix_labels

        # æ›´æ–°ç±»å’Œæ–‡æœ¬
        labels = self._update_label_text(labels)
        # Mosaicæˆ–MixUp
        labels = self._mix_transform(labels)
        labels.pop("mix_labels", None)
        return labels

    def _mix_transform(self, labels):
        """
        å¯¹æ ‡ç­¾å­—å…¸åº”ç”¨MixUpæˆ–Mosaicå¢å¼ºã€‚

        è¯¥æ–¹æ³•åº”è¯¥ç”±å­ç±»å®ç°ï¼Œç”¨äºæ‰§è¡Œå…·ä½“çš„æ··åˆå˜æ¢ï¼Œå¦‚MixUpæˆ–Mosaicã€‚å®ƒä¼šå°±åœ°ä¿®æ”¹è¾“å…¥çš„æ ‡ç­¾å­—å…¸ï¼Œæ·»åŠ å¢å¼ºåçš„æ•°æ®ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒå’Œæ ‡ç­¾æ•°æ®çš„å­—å…¸ï¼Œé¢„è®¡ä¼šæœ‰ä¸€ä¸ª'mix_labels'é”®ï¼ŒåŒ…å«ç”¨äºæ··åˆçš„é¢å¤–å›¾åƒå’Œæ ‡ç­¾æ•°æ®ã€‚

        è¿”å›ï¼š
            (Dict): ç»è¿‡æ··åˆå˜æ¢å¢å¼ºåçš„æ ‡ç­¾å­—å…¸ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseMixTransform(dataset)
            >>> labels = {"image": img, "bboxes": boxes, "mix_labels": [{"image": img2, "bboxes": boxes2}]}
            >>> augmented_labels = transform._mix_transform(labels)
        """
        raise NotImplementedError

    def get_indexes(self):
        """
        è·å–ç”¨äºé©¬èµ›å…‹å¢å¼ºçš„æ‰“ä¹±åçš„ç´¢å¼•åˆ—è¡¨ã€‚

        è¿”å›ï¼š
            (List[int]): ä»æ•°æ®é›†ä¸­éšæœºæ‰“ä¹±çš„ç´¢å¼•åˆ—è¡¨ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = BaseMixTransform(dataset)
            >>> indexes = transform.get_indexes()
            >>> print(indexes)  # [3, 18, 7, 2]
        """
        raise NotImplementedError

    @staticmethod
    def _update_label_text(labels):
        """
        æ›´æ–°å›¾åƒå¢å¼ºä¸­çš„æ··åˆæ ‡ç­¾æ–‡æœ¬å’Œç±»IDã€‚

        è¯¥æ–¹æ³•å¤„ç†è¾“å…¥æ ‡ç­¾å­—å…¸çš„'texts'å’Œ'cls'å­—æ®µï¼Œä»¥åŠä»»ä½•æ··åˆæ ‡ç­¾ï¼Œåˆ›å»ºç»Ÿä¸€çš„æ–‡æœ¬æ ‡ç­¾é›†å¹¶ç›¸åº”æ›´æ–°ç±»IDã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«æ ‡ç­¾ä¿¡æ¯çš„å­—å…¸ï¼ŒåŒ…æ‹¬'texts'å’Œ'cls'å­—æ®µï¼Œå¯èƒ½è¿˜ä¼šæœ‰ä¸€ä¸ª'mix_labels'å­—æ®µï¼ŒåŒ…å«é¢å¤–çš„æ ‡ç­¾å­—å…¸ã€‚

        è¿”å›ï¼š
            (Dict): æ›´æ–°åçš„æ ‡ç­¾å­—å…¸ï¼ŒåŒ…å«ç»Ÿä¸€çš„æ–‡æœ¬æ ‡ç­¾å’Œæ›´æ–°åçš„ç±»IDã€‚

        ç¤ºä¾‹ï¼š
            >>> labels = {
            ...     "texts": [["cat"], ["dog"]],
            ...     "cls": torch.tensor([[0], [1]]),
            ...     "mix_labels": [{"texts": [["bird"], ["fish"]], "cls": torch.tensor([[0], [1]])}],
            ... }
            >>> updated_labels = self._update_label_text(labels)
            >>> print(updated_labels["texts"])
            [['cat'], ['dog'], ['bird'], ['fish']]
            >>> print(updated_labels["cls"])
            tensor([[0],
                    [1]])
            >>> print(updated_labels["mix_labels"][0]["cls"])
            tensor([[2],
                    [3]])
        """
        if "texts" not in labels:
            return labels

        mix_texts = sum([labels["texts"]] + [x["texts"] for x in labels["mix_labels"]], [])
        mix_texts = list({tuple(x) for x in mix_texts})
        text2id = {text: i for i, text in enumerate(mix_texts)}

        for label in [labels] + labels["mix_labels"]:
            for i, cls in enumerate(label["cls"].squeeze(-1).tolist()):
                text = label["texts"][int(cls)]
                label["cls"][i] = text2id[tuple(text)]
            label["texts"] = mix_texts
        return labels


class Mosaic(BaseMixTransform):
    """
    å›¾åƒæ•°æ®é›†çš„é©¬èµ›å…‹å¢å¼ºï¼ˆMosaicï¼‰

    è¯¥ç±»é€šè¿‡å°†å¤šå¼ ï¼ˆ4æˆ–9å¼ ï¼‰å›¾åƒåˆæˆåˆ°ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­æ¥æ‰§è¡Œé©¬èµ›å…‹å¢å¼ºã€‚
    è¯¥å¢å¼ºä¼šä»¥ç»™å®šçš„æ¦‚ç‡åº”ç”¨åˆ°æ•°æ®é›†ä¸Šã€‚

    å±æ€§ï¼š
        dataset: åº”ç”¨é©¬èµ›å…‹å¢å¼ºçš„æ•°æ®é›†ã€‚
        imgsz (int): å•å¼ å›¾åƒç»è¿‡é©¬èµ›å…‹å¤„ç†åçš„å›¾åƒå¤§å°ï¼ˆé«˜åº¦å’Œå®½åº¦ï¼‰ã€‚
        p (float): åº”ç”¨é©¬èµ›å…‹å¢å¼ºçš„æ¦‚ç‡ï¼Œå¿…é¡»åœ¨0åˆ°1ä¹‹é—´ã€‚
        n (int): ç½‘æ ¼å¤§å°ï¼Œ4è¡¨ç¤º2x2ç½‘æ ¼ï¼Œ9è¡¨ç¤º3x3ç½‘æ ¼ã€‚
        border (Tuple[int, int]): è¾¹æ¡†å¤§å°ï¼ˆå®½åº¦å’Œé«˜åº¦ï¼‰ã€‚

    æ–¹æ³•ï¼š
        get_indexes: è¿”å›ä»æ•°æ®é›†ä¸­éšæœºé€‰æ‹©çš„ç´¢å¼•åˆ—è¡¨ã€‚
        _mix_transform: å¯¹è¾“å…¥å›¾åƒå’Œæ ‡ç­¾åº”ç”¨æ··åˆå˜æ¢ã€‚
        _mosaic3: åˆ›å»º1x3çš„å›¾åƒé©¬èµ›å…‹ã€‚
        _mosaic4: åˆ›å»º2x2çš„å›¾åƒé©¬èµ›å…‹ã€‚
        _mosaic9: åˆ›å»º3x3çš„å›¾åƒé©¬èµ›å…‹ã€‚
        _update_labels: æ›´æ–°å¸¦æœ‰å¡«å……çš„æ ‡ç­¾ã€‚
        _cat_labels: åˆå¹¶æ ‡ç­¾å¹¶è£å‰ªé©¬èµ›å…‹è¾¹ç•Œå®ä¾‹ã€‚

    ç¤ºä¾‹ï¼š
        >>> from ultralytics.data.augment import Mosaic
        >>> dataset = YourDataset(...)  # ä½ çš„å›¾åƒæ•°æ®é›†
        >>> mosaic_aug = Mosaic(dataset, imgsz=640, p=0.5, n=4)
        >>> augmented_labels = mosaic_aug(original_labels)
    """

    def __init__(self, dataset, imgsz=640, p=1.0, n=4):
        """
        åˆå§‹åŒ–é©¬èµ›å…‹å¢å¼ºå¯¹è±¡ã€‚

        è¯¥ç±»é€šè¿‡å°†å¤šå¼ ï¼ˆ4æˆ–9å¼ ï¼‰å›¾åƒåˆæˆåˆ°ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­æ¥æ‰§è¡Œé©¬èµ›å…‹å¢å¼ºã€‚
        è¯¥å¢å¼ºä¼šä»¥ç»™å®šçš„æ¦‚ç‡åº”ç”¨åˆ°æ•°æ®é›†ä¸Šã€‚

        å‚æ•°ï¼š
            dataset (Any): åº”ç”¨é©¬èµ›å…‹å¢å¼ºçš„æ•°æ®é›†ã€‚
            imgsz (int): å•å¼ å›¾åƒç»è¿‡é©¬èµ›å…‹å¤„ç†åçš„å›¾åƒå¤§å°ï¼ˆé«˜åº¦å’Œå®½åº¦ï¼‰ã€‚
            p (float): åº”ç”¨é©¬èµ›å…‹å¢å¼ºçš„æ¦‚ç‡ï¼Œå¿…é¡»åœ¨0åˆ°1ä¹‹é—´ã€‚
            n (int): ç½‘æ ¼å¤§å°ï¼Œ4è¡¨ç¤º2x2ç½‘æ ¼ï¼Œ9è¡¨ç¤º3x3ç½‘æ ¼ã€‚

        ç¤ºä¾‹ï¼š
            >>> from ultralytics.data.augment import Mosaic
            >>> dataset = YourDataset(...)
            >>> mosaic_aug = Mosaic(dataset, imgsz=640, p=0.5, n=4)
        """
        assert 0 <= p <= 1.0, f"æ¦‚ç‡åº”åœ¨[0, 1]èŒƒå›´å†…ï¼Œä½†å¾—åˆ°{p}."
        assert n in {4, 9}, "ç½‘æ ¼å¿…é¡»æ˜¯4æˆ–9."
        super().__init__(dataset=dataset, p=p)
        self.imgsz = imgsz
        self.border = (-imgsz // 2, -imgsz // 2)  # å®½åº¦ï¼Œé«˜åº¦
        self.n = n

    def get_indexes(self, buffer=True):
        """
        è¿”å›ç”¨äºé©¬èµ›å…‹å¢å¼ºçš„éšæœºç´¢å¼•åˆ—è¡¨ã€‚

        è¯¥æ–¹æ³•æ ¹æ®'buffer'å‚æ•°ä»ç¼“å†²åŒºæˆ–æ•´ä¸ªæ•°æ®é›†ä¸­éšæœºé€‰æ‹©å›¾åƒç´¢å¼•ã€‚
        å®ƒç”¨äºé€‰æ‹©å›¾åƒä»¥åˆ›å»ºé©¬èµ›å…‹å¢å¼ºã€‚

        å‚æ•°ï¼š
            buffer (bool): å¦‚æœä¸ºTrueï¼Œä»æ•°æ®é›†ç¼“å†²åŒºä¸­é€‰æ‹©å›¾åƒã€‚å¦‚æœä¸ºFalseï¼Œåˆ™ä»æ•´ä¸ªæ•°æ®é›†ä¸­é€‰æ‹©ã€‚

        è¿”å›ï¼š
            (List[int]): éšæœºå›¾åƒç´¢å¼•çš„åˆ—è¡¨ï¼Œåˆ—è¡¨é•¿åº¦ä¸ºn-1ï¼Œnæ˜¯ç”¨äºé©¬èµ›å…‹çš„å›¾åƒæ•°é‡ï¼ˆå¦‚æœnä¸º4ï¼Œåˆ™ä¸º3ï¼Œå¦‚æœnä¸º9ï¼Œåˆ™ä¸º8ï¼‰ã€‚

        ç¤ºä¾‹ï¼š
            >>> mosaic = Mosaic(dataset, imgsz=640, p=1.0, n=4)
            >>> indexes = mosaic.get_indexes()
            >>> print(len(indexes))  # è¾“å‡º: 3
        """
        if buffer:  # ä»ç¼“å†²åŒºé€‰æ‹©å›¾åƒ
            return random.choices(list(self.dataset.buffer), k=self.n - 1)
        else:  # ä»æ•´ä¸ªæ•°æ®é›†ä¸­é€‰æ‹©å›¾åƒ
            return [random.randint(0, len(self.dataset) - 1) for _ in range(self.n - 1)]

    def _mix_transform(self, labels):
        """
        å¯¹è¾“å…¥å›¾åƒå’Œæ ‡ç­¾åº”ç”¨é©¬èµ›å…‹å¢å¼ºã€‚

        è¯¥æ–¹æ³•å°†å¤šå¼ å›¾åƒï¼ˆ3å¼ ã€4å¼ æˆ–9å¼ ï¼‰åˆæˆåˆ°ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­ï¼ŒåŸºäº'n'å±æ€§ã€‚
        å®ƒç¡®ä¿æ²¡æœ‰çŸ©å½¢æ³¨é‡Šï¼Œå¹¶ä¸”æœ‰å…¶ä»–å›¾åƒå¯ç”¨äºé©¬èµ›å…‹å¢å¼ºã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ•°æ®å’Œæ³¨é‡Šçš„å­—å…¸ï¼Œé¢„è®¡æœ‰ä»¥ä¸‹é”®ï¼š
                - 'rect_shape': åº”ä¸ºNoneï¼Œå› ä¸ºçŸ©å½¢å’Œé©¬èµ›å…‹æ˜¯äº’æ–¥çš„ã€‚
                - 'mix_labels': ä¸€ä¸ªåŒ…å«æ•°æ®çš„å­—å…¸åˆ—è¡¨ï¼Œç”¨äºå…¶ä»–å›¾åƒè¿›è¡Œé©¬èµ›å…‹ã€‚

        è¿”å›ï¼š
            (Dict): ä¸€ä¸ªåŒ…å«é©¬èµ›å…‹å¢å¼ºå›¾åƒå’Œæ›´æ–°åçš„æ³¨é‡Šçš„å­—å…¸ã€‚

        å¼‚å¸¸ï¼š
            AssertionError: å¦‚æœ'rect_shape'ä¸ä¸ºNoneï¼Œæˆ–'mix_labels'ä¸ºç©ºã€‚

        ç¤ºä¾‹ï¼š
            >>> mosaic = Mosaic(dataset, imgsz=640, p=1.0, n=4)
            >>> augmented_data = mosaic._mix_transform(labels)
        """
        assert labels.get("rect_shape", None) is None, "çŸ©å½¢å’Œé©¬èµ›å…‹æ˜¯äº’æ–¥çš„."
        assert len(labels.get("mix_labels", [])), "æ²¡æœ‰å…¶ä»–å›¾åƒå¯ç”¨äºé©¬èµ›å…‹å¢å¼º."
        return (
            self._mosaic3(labels) if self.n == 3 else self._mosaic4(labels) if self.n == 4 else self._mosaic9(labels)
        )  # æ­¤ä»£ç å·²ä¸ºmosaic3æ–¹æ³•è¿›è¡Œäº†ä¿®æ”¹ã€‚

    def _mosaic3(self, labels):
        """
        åˆ›å»ºä¸€ä¸ª1x3çš„å›¾åƒé©¬èµ›å…‹ï¼Œå°†ä¸‰å¼ å›¾åƒç»„åˆåœ¨ä¸€èµ·ã€‚

        è¯¥æ–¹æ³•å°†ä¸‰å¼ å›¾åƒæ°´å¹³æ’åˆ—ï¼Œä¸»å›¾åƒæ”¾åœ¨ä¸­é—´ï¼Œå¦å¤–ä¸¤å¼ å›¾åƒåˆ†åˆ«æ”¾åœ¨ä¸¤ä¾§ã€‚
        å®ƒæ˜¯ç”¨äºç›®æ ‡æ£€æµ‹çš„é©¬èµ›å…‹å¢å¼ºæŠ€æœ¯çš„ä¸€éƒ¨åˆ†ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«ä¸»å›¾åƒï¼ˆä¸­å¿ƒå›¾åƒï¼‰å›¾åƒå’Œæ ‡ç­¾ä¿¡æ¯çš„å­—å…¸ã€‚
                å¿…é¡»åŒ…æ‹¬'img'é”®ï¼ˆå›¾åƒæ•°ç»„ï¼‰ï¼Œå¹¶ä¸”'mix_labels'é”®åŒ…å«ä¸¤ä¸ªå­—å…¸ï¼Œ
                å…¶ä¸­åŒ…å«ä¾§è¾¹å›¾åƒçš„ç›¸å…³ä¿¡æ¯ã€‚

        è¿”å›ï¼š
            (Dict): ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«é©¬èµ›å…‹å›¾åƒå’Œæ›´æ–°åçš„æ ‡ç­¾ã€‚é”®åŒ…æ‹¬ï¼š
                - 'img' (np.ndarray): é©¬èµ›å…‹å›¾åƒæ•°ç»„ï¼Œå½¢çŠ¶ä¸º(H, W, C)ã€‚
                - å…¶ä»–è¾“å…¥æ ‡ç­¾çš„é”®ï¼Œæ›´æ–°ä¸ºåæ˜ æ–°å›¾åƒå°ºå¯¸çš„å€¼ã€‚

        ç¤ºä¾‹ï¼š
            >>> mosaic = Mosaic(dataset, imgsz=640, p=1.0, n=3)
            >>> labels = {
            ...     "img": np.random.rand(480, 640, 3),
            ...     "mix_labels": [{"img": np.random.rand(480, 640, 3)} for _ in range(2)],
            ... }
            >>> result = mosaic._mosaic3(labels)
            >>> print(result["img"].shape)
            (640, 640, 3)
        """
        mosaic_labels = []
        s = self.imgsz
        for i in range(3):
            labels_patch = labels if i == 0 else labels["mix_labels"][i - 1]
            # åŠ è½½å›¾åƒ
            img = labels_patch["img"]
            h, w = labels_patch.pop("resized_shape")

            # æ”¾ç½®å›¾åƒåˆ°img3
            if i == 0:  # ä¸­å¿ƒ
                img3 = np.full((s * 3, s * 3, img.shape[2]), 114, dtype=np.uint8)  # ä»¥3å—å›¾åƒä¸ºåŸºç¡€çš„å›¾åƒ
                h0, w0 = h, w
                c = s, s, s + w, s + h  # xmin, ymin, xmax, ymaxï¼ˆåŸºç¡€ï¼‰åæ ‡
            elif i == 1:  # å³ä¾§
                c = s + w0, s, s + w0 + w, s + h
            elif i == 2:  # å·¦ä¾§
                c = s - w, s + h0 - h, s, s + h0

            padw, padh = c[:2]
            x1, y1, x2, y2 = (max(x, 0) for x in c)  # åˆ†é…åæ ‡

            img3[y1:y2, x1:x2] = img[y1 - padh :, x1 - padw :]  # img3[ymin:ymax, xmin:xmax]
            # hp, wp = h, w  # ä¸ºä¸‹æ¬¡è¿­ä»£å‡†å¤‡å‰ä¸€ä¸ªé«˜åº¦å’Œå®½åº¦

            # æ›´æ–°æ ‡ç­¾ï¼Œå‡è®¾é©¬èµ›å…‹å¤§å°ä¸ºimgsz*2
            labels_patch = self._update_labels(labels_patch, padw + self.border[0], padh + self.border[1])
            mosaic_labels.append(labels_patch)
        final_labels = self._cat_labels(mosaic_labels)

        final_labels["img"] = img3[-self.border[0] : self.border[0], -self.border[1] : self.border[1]]
        return final_labels

    def _mosaic4(self, labels):
        """
        åˆ›å»ºä¸€ä¸ª2x2çš„å›¾åƒé©¬èµ›å…‹ï¼Œç”±å››å¼ å›¾åƒåˆæˆã€‚

        è¯¥æ–¹æ³•å°†å››å¼ å›¾åƒåˆæˆåˆ°ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­ï¼Œé€šè¿‡å°†å®ƒä»¬æ’åˆ—åœ¨2x2çš„ç½‘æ ¼ä¸­ã€‚
        å®ƒè¿˜æ›´æ–°æ¯ä¸ªå›¾åƒåœ¨é©¬èµ›å…‹ä¸­çš„æ ‡ç­¾ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«åŸºæœ¬å›¾åƒï¼ˆç´¢å¼•ä¸º0ï¼‰å’Œä¸‰å¼ é™„åŠ å›¾åƒï¼ˆç´¢å¼•ä¸º1-3ï¼‰çš„å›¾åƒæ•°æ®å’Œæ ‡ç­¾ï¼Œ
                è¿™äº›å›¾åƒçš„ä¿¡æ¯åœ¨'mix_labels'é”®ä¸­ã€‚

        è¿”å›ï¼š
            (Dict): ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«é©¬èµ›å…‹å›¾åƒå’Œæ›´æ–°åçš„æ ‡ç­¾ã€‚'img'é”®åŒ…å«é©¬èµ›å…‹å›¾åƒï¼Œ
                å…¶ä»–é”®åŒ…å«æ‰€æœ‰å››å¼ å›¾åƒçš„åˆå¹¶å’Œè°ƒæ•´åçš„æ ‡ç­¾ã€‚

        ç¤ºä¾‹ï¼š
            >>> mosaic = Mosaic(dataset, imgsz=640, p=1.0, n=4)
            >>> labels = {
            ...     "img": np.random.rand(480, 640, 3),
            ...     "mix_labels": [{"img": np.random.rand(480, 640, 3)} for _ in range(3)],
            ... }
            >>> result = mosaic._mosaic4(labels)
            >>> assert result["img"].shape == (1280, 1280, 3)
        """
        mosaic_labels = []
        s = self.imgsz
        yc, xc = (int(random.uniform(-x, 2 * s + x)) for x in self.border)  # é©¬èµ›å…‹ä¸­å¿ƒxï¼Œy
        for i in range(4):
            labels_patch = labels if i == 0 else labels["mix_labels"][i - 1]
            # åŠ è½½å›¾åƒ
            img = labels_patch["img"]
            h, w = labels_patch.pop("resized_shape")

            # æ”¾ç½®å›¾åƒåˆ°img4
            if i == 0:  # å·¦ä¸Š
                img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # ä»¥4å—å›¾åƒä¸ºåŸºç¡€çš„å›¾åƒ
                x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymaxï¼ˆå¤§å›¾åƒï¼‰
                x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymaxï¼ˆå°å›¾åƒï¼‰
            elif i == 1:  # å³ä¸Š
                x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
                x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
            elif i == 2:  # å·¦ä¸‹
                x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
                x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
            elif i == 3:  # å³ä¸‹
                x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
                x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)

            img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
            padw = x1a - x1b
            padh = y1a - y1b

            labels_patch = self._update_labels(labels_patch, padw, padh)
            mosaic_labels.append(labels_patch)
        final_labels = self._cat_labels(mosaic_labels)
        final_labels["img"] = img4
        return final_labels


class MixUp(BaseMixTransform):
    """
    å¯¹å›¾åƒæ•°æ®é›†åº”ç”¨MixUpå¢å¼ºã€‚

    è¯¥ç±»å®ç°äº†è®ºæ–‡â€œmixup: Beyond Empirical Risk Minimizationâ€ï¼ˆhttps://arxiv.org/abs/1710.09412ï¼‰ä¸­æè¿°çš„MixUpå¢å¼ºæŠ€æœ¯ã€‚
    MixUpé€šè¿‡ä½¿ç”¨ä¸€ä¸ªéšæœºæƒé‡å°†ä¸¤å¼ å›¾åƒåŠå…¶æ ‡ç­¾ç»“åˆåœ¨ä¸€èµ·ã€‚

    å±æ€§ï¼š
        dataset (Any): åº”ç”¨MixUpå¢å¼ºçš„æ•°æ®é›†ã€‚
        pre_transform (Callable | None): å¯é€‰çš„åœ¨MixUpä¹‹å‰åº”ç”¨çš„å˜æ¢ã€‚
        p (float): åº”ç”¨MixUpå¢å¼ºçš„æ¦‚ç‡ã€‚

    æ–¹æ³•ï¼š
        get_indexes: è¿”å›æ•°æ®é›†ä¸­çš„éšæœºç´¢å¼•ã€‚
        _mix_transform: å¯¹è¾“å…¥æ ‡ç­¾åº”ç”¨MixUpå¢å¼ºã€‚

    ç¤ºä¾‹ï¼š
        >>> from ultralytics.data.augment import MixUp
        >>> dataset = YourDataset(...)  # ä½ çš„å›¾åƒæ•°æ®é›†
        >>> mixup = MixUp(dataset, p=0.5)
        >>> augmented_labels = mixup(original_labels)
    """

    def __init__(self, dataset, pre_transform=None, p=0.0) -> None:
        """
        åˆå§‹åŒ–MixUpå¢å¼ºå¯¹è±¡ã€‚

        MixUpæ˜¯ä¸€ç§å›¾åƒå¢å¼ºæŠ€æœ¯ï¼Œé€šè¿‡å¯¹ä¸¤å¼ å›¾åƒçš„åƒç´ å€¼å’Œæ ‡ç­¾è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå°†ä¸¤å¼ å›¾åƒåˆæˆä¸€å¼ ã€‚
        æœ¬å®ç°ä¸“ä¸ºUltralytics YOLOæ¡†æ¶è®¾è®¡ã€‚

        å‚æ•°ï¼š
            dataset (Any): åº”ç”¨MixUpå¢å¼ºçš„æ•°æ®é›†ã€‚
            pre_transform (Callable | None): å¯é€‰çš„åœ¨MixUpä¹‹å‰åº”ç”¨çš„å˜æ¢ã€‚
            p (float): åº”ç”¨MixUpå¢å¼ºçš„æ¦‚ç‡ï¼Œå¿…é¡»åœ¨[0, 1]èŒƒå›´å†…ã€‚

        ç¤ºä¾‹ï¼š
            >>> from ultralytics.data.dataset import YOLODataset
            >>> dataset = YOLODataset("path/to/data.yaml")
            >>> mixup = MixUp(dataset, pre_transform=None, p=0.5)
        """
        super().__init__(dataset=dataset, pre_transform=pre_transform, p=p)

    def get_indexes(self):
        """
        ä»æ•°æ®é›†ä¸­è·å–ä¸€ä¸ªéšæœºç´¢å¼•ã€‚

        è¯¥æ–¹æ³•è¿”å›æ•°æ®é›†ä¸­çš„å•ä¸ªéšæœºç´¢å¼•ï¼Œç”¨äºé€‰æ‹©è¿›è¡ŒMixUpå¢å¼ºçš„å›¾åƒã€‚

        è¿”å›ï¼š
            (int): æ•°æ®é›†é•¿åº¦èŒƒå›´å†…çš„ä¸€ä¸ªéšæœºæ•´æ•°ç´¢å¼•ã€‚

        ç¤ºä¾‹ï¼š
            >>> mixup = MixUp(dataset)
            >>> index = mixup.get_indexes()
            >>> print(index)
            42
        """
        return random.randint(0, len(self.dataset) - 1)

    def _mix_transform(self, labels):
        """
        å¯¹è¾“å…¥æ ‡ç­¾åº”ç”¨MixUpå¢å¼ºã€‚

        è¯¥æ–¹æ³•å®ç°äº†è®ºæ–‡â€œmixup: Beyond Empirical Risk Minimizationâ€ï¼ˆhttps://arxiv.org/abs/1710.09412ï¼‰ä¸­æè¿°çš„MixUpå¢å¼ºæŠ€æœ¯ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«åŸå§‹å›¾åƒå’Œæ ‡ç­¾ä¿¡æ¯çš„å­—å…¸ã€‚

        è¿”å›ï¼š
            (Dict): åŒ…å«æ··åˆå›¾åƒå’Œåˆå¹¶æ ‡ç­¾ä¿¡æ¯çš„å­—å…¸ã€‚

        ç¤ºä¾‹ï¼š
            >>> mixer = MixUp(dataset)
            >>> mixed_labels = mixer._mix_transform(labels)
        """
        r = np.random.beta(32.0, 32.0)  # mixupæ¯”ä¾‹ï¼Œalpha=beta=32.0
        labels2 = labels["mix_labels"][0]
        labels["img"] = (labels["img"] * r + labels2["img"] * (1 - r)).astype(np.uint8)
        labels["instances"] = Instances.concatenate([labels["instances"], labels2["instances"]], axis=0)
        labels["cls"] = np.concatenate([labels["cls"], labels2["cls"]], 0)
        return labels


class RandomPerspective:
    """
    å®ç°å›¾åƒåŠå…¶å¯¹åº”æ³¨é‡Šçš„éšæœºé€è§†å’Œä»¿å°„å˜æ¢ã€‚

    è¯¥ç±»å¯¹å›¾åƒåŠå…¶å¯¹åº”çš„è¾¹ç•Œæ¡†ã€åˆ†å‰²ã€å…³é”®ç‚¹åº”ç”¨éšæœºæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€å‰ªåˆ‡å’Œé€è§†å˜æ¢ã€‚
    å®ƒå¯ä»¥ä½œä¸ºç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²ä»»åŠ¡çš„æ•°æ®å¢å¼ºç®¡é“çš„ä¸€éƒ¨åˆ†ä½¿ç”¨ã€‚

    å±æ€§ï¼š
        degrees (float): éšæœºæ—‹è½¬çš„æœ€å¤§ç»å¯¹è§’åº¦èŒƒå›´ã€‚
        translate (float): æœ€å¤§å¹³ç§»é‡ï¼Œå å›¾åƒå¤§å°çš„æ¯”ä¾‹ã€‚
        scale (float): ç¼©æ”¾å› å­èŒƒå›´ï¼Œä¾‹å¦‚ï¼Œscale=0.1è¡¨ç¤º0.9åˆ°1.1ä¹‹é—´ã€‚
        shear (float): æœ€å¤§å‰ªåˆ‡è§’åº¦ï¼ˆåº¦ï¼‰ã€‚
        perspective (float): é€è§†ç•¸å˜å› å­ã€‚
        border (Tuple[int, int]): é©¬èµ›å…‹è¾¹æ¡†å¤§å°ï¼ˆxï¼Œyï¼‰ã€‚
        pre_transform (Callable | None): å¯é€‰çš„åœ¨éšæœºé€è§†å˜æ¢ä¹‹å‰åº”ç”¨çš„å˜æ¢ã€‚

    æ–¹æ³•ï¼š
        affine_transform: å¯¹è¾“å…¥å›¾åƒåº”ç”¨ä»¿å°„å˜æ¢ã€‚
        apply_bboxes: ä½¿ç”¨ä»¿å°„çŸ©é˜µå˜æ¢è¾¹ç•Œæ¡†ã€‚
        apply_segments: å˜æ¢åˆ†å‰²å¹¶ç”Ÿæˆæ–°çš„è¾¹ç•Œæ¡†ã€‚
        apply_keypoints: ä½¿ç”¨ä»¿å°„çŸ©é˜µå˜æ¢å…³é”®ç‚¹ã€‚
        __call__: å¯¹å›¾åƒå’Œæ³¨é‡Šåº”ç”¨éšæœºé€è§†å˜æ¢ã€‚
        box_candidates: æ ¹æ®å¤§å°å’Œé•¿å®½æ¯”è¿‡æ»¤å˜æ¢åçš„è¾¹ç•Œæ¡†ã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = RandomPerspective(degrees=10, translate=0.1, scale=0.1, shear=10)
        >>> image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        >>> labels = {"img": image, "cls": np.array([0, 1]), "instances": Instances(...)}
        >>> result = transform(labels)
        >>> transformed_image = result["img"]
        >>> transformed_instances = result["instances"]
    """

    def __init__(
        self, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, border=(0, 0), pre_transform=None
    ):
        """
        åˆå§‹åŒ–RandomPerspectiveå¯¹è±¡ï¼Œå¹¶è®¾ç½®å˜æ¢å‚æ•°ã€‚

        è¯¥ç±»å®ç°å›¾åƒåŠå…¶å¯¹åº”çš„è¾¹ç•Œæ¡†ã€åˆ†å‰²å’Œå…³é”®ç‚¹çš„éšæœºé€è§†å’Œä»¿å°„å˜æ¢ã€‚
        å˜æ¢åŒ…æ‹¬æ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾å’Œå‰ªåˆ‡ã€‚

        å‚æ•°ï¼š
            degrees (float): éšæœºæ—‹è½¬çš„è§’åº¦èŒƒå›´ã€‚
            translate (float): éšæœºå¹³ç§»çš„å®½åº¦å’Œé«˜åº¦çš„æ¯”ä¾‹ã€‚
            scale (float): ç¼©æ”¾å› å­çš„åŒºé—´ï¼Œä¾‹å¦‚ï¼Œscale=0.5è¡¨ç¤ºç¼©æ”¾å› å­åœ¨50%åˆ°150%ä¹‹é—´ã€‚
            shear (float): å‰ªåˆ‡å¼ºåº¦ï¼ˆè§’åº¦ï¼‰ã€‚
            perspective (float): é€è§†ç•¸å˜å› å­ã€‚
            border (Tuple[int, int]): æŒ‡å®šé©¬èµ›å…‹è¾¹æ¡†ï¼ˆé¡¶éƒ¨/åº•éƒ¨ï¼Œå·¦/å³ï¼‰çš„å…ƒç»„ã€‚
            pre_transform (Callable | None): åœ¨åº”ç”¨éšæœºå˜æ¢ä¹‹å‰å¯¹å›¾åƒåº”ç”¨çš„å‡½æ•°æˆ–å˜æ¢ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = RandomPerspective(degrees=10.0, translate=0.1, scale=0.5, shear=5.0)
            >>> result = transform(labels)  # å¯¹æ ‡ç­¾åº”ç”¨éšæœºé€è§†å˜æ¢
        """
        self.degrees = degrees
        self.translate = translate
        self.scale = scale
        self.shear = shear
        self.perspective = perspective
        self.border = border  # é©¬èµ›å…‹è¾¹æ¡†
        self.pre_transform = pre_transform

    def affine_transform(self, img, border):
        """
        å¯¹å›¾åƒåº”ç”¨ä¸€ç³»åˆ—ä»¥å›¾åƒä¸­å¿ƒä¸ºä¸­å¿ƒçš„ä»¿å°„å˜æ¢ã€‚

        è¯¥å‡½æ•°å¯¹è¾“å…¥å›¾åƒæ‰§è¡Œä¸€ç³»åˆ—å‡ ä½•å˜æ¢ï¼ŒåŒ…æ‹¬å¹³ç§»ã€é€è§†å˜åŒ–ã€æ—‹è½¬ã€ç¼©æ”¾å’Œå‰ªåˆ‡ã€‚
        å˜æ¢æŒ‰ç‰¹å®šé¡ºåºåº”ç”¨ï¼Œä»¥ä¿æŒä¸€è‡´æ€§ã€‚

        å‚æ•°ï¼š
            img (np.ndarray): éœ€è¦å˜æ¢çš„è¾“å…¥å›¾åƒã€‚
            border (Tuple[int, int]): å˜æ¢åå›¾åƒçš„è¾¹æ¡†å°ºå¯¸ã€‚

        è¿”å›ï¼š
            (Tuple[np.ndarray, np.ndarray, float]): è¿”å›ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ï¼š
                - np.ndarray: å˜æ¢åçš„å›¾åƒã€‚
                - np.ndarray: 3x3çš„å˜æ¢çŸ©é˜µã€‚
                - float: å˜æ¢è¿‡ç¨‹ä¸­åº”ç”¨çš„ç¼©æ”¾å› å­ã€‚

        ç¤ºä¾‹ï¼š
            >>> import numpy as np
            >>> img = np.random.rand(100, 100, 3)
            >>> border = (10, 10)
            >>> transformed_img, matrix, scale = affine_transform(img, border)
        """
        # ä¸­å¿ƒ
        C = np.eye(3, dtype=np.float32)

        C[0, 2] = -img.shape[1] / 2  # xå¹³ç§»ï¼ˆåƒç´ ï¼‰
        C[1, 2] = -img.shape[0] / 2  # yå¹³ç§»ï¼ˆåƒç´ ï¼‰

        # é€è§†
        P = np.eye(3, dtype=np.float32)
        P[2, 0] = random.uniform(-self.perspective, self.perspective)  # xé€è§†ï¼ˆå›´ç»•yè½´ï¼‰
        P[2, 1] = random.uniform(-self.perspective, self.perspective)  # yé€è§†ï¼ˆå›´ç»•xè½´ï¼‰

        # æ—‹è½¬å’Œç¼©æ”¾
        R = np.eye(3, dtype=np.float32)
        a = random.uniform(-self.degrees, self.degrees)
        s = random.uniform(1 - self.scale, 1 + self.scale)
        R[:2] = cv2.getRotationMatrix2D(angle=a, center=(0, 0), scale=s)

        # å‰ªåˆ‡
        S = np.eye(3, dtype=np.float32)
        S[0, 1] = math.tan(random.uniform(-self.shear, self.shear) * math.pi / 180)  # xå‰ªåˆ‡ï¼ˆåº¦ï¼‰
        S[1, 0] = math.tan(random.uniform(-self.shear, self.shear) * math.pi / 180)  # yå‰ªåˆ‡ï¼ˆåº¦ï¼‰

        # å¹³ç§»
        T = np.eye(3, dtype=np.float32)
        T[0, 2] = random.uniform(0.5 - self.translate, 0.5 + self.translate) * self.size[0]  # xå¹³ç§»ï¼ˆåƒç´ ï¼‰
        T[1, 2] = random.uniform(0.5 - self.translate, 0.5 + self.translate) * self.size[1]  # yå¹³ç§»ï¼ˆåƒç´ ï¼‰

        # åˆå¹¶çš„æ—‹è½¬çŸ©é˜µ
        M = T @ S @ R @ P @ C  # æ“ä½œé¡ºåºï¼ˆä»å³åˆ°å·¦ï¼‰å¾ˆé‡è¦
        # ä»¿å°„å›¾åƒ
        if (border[0] != 0) or (border[1] != 0) or (M != np.eye(3)).any():  # å›¾åƒå‘ç”Ÿäº†å˜åŒ–
            if self.perspective:
                img = cv2.warpPerspective(img, M, dsize=self.size, borderValue=(114, 114, 114))
            else:  # ä»¿å°„
                img = cv2.warpAffine(img, M[:2], dsize=self.size, borderValue=(114, 114, 114))
        return img, M, s

    def apply_bboxes(self, bboxes, M):
        """
        å¯¹è¾¹ç•Œæ¡†åº”ç”¨ä»¿å°„å˜æ¢ã€‚

        è¯¥å‡½æ•°ä½¿ç”¨æä¾›çš„å˜æ¢çŸ©é˜µå¯¹ä¸€ç»„è¾¹ç•Œæ¡†åº”ç”¨ä»¿å°„å˜æ¢ã€‚

        å‚æ•°ï¼š
            bboxes (torch.Tensor): ä»¥xyxyæ ¼å¼è¡¨ç¤ºçš„è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º(N, 4)ï¼Œå…¶ä¸­Næ˜¯è¾¹ç•Œæ¡†çš„æ•°é‡ã€‚
            M (torch.Tensor): å½¢çŠ¶ä¸º(3, 3)çš„ä»¿å°„å˜æ¢çŸ©é˜µã€‚

        è¿”å›ï¼š
            (torch.Tensor): ä»¥xyxyæ ¼å¼è¡¨ç¤ºçš„å˜æ¢åçš„è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º(N, 4)ã€‚

        ç¤ºä¾‹ï¼š
            >>> bboxes = torch.tensor([[10, 10, 20, 20], [30, 30, 40, 40]])
            >>> M = torch.eye(3)
            >>> transformed_bboxes = apply_bboxes(bboxes, M)
        """
        n = len(bboxes)
        if n == 0:
            return bboxes

        xy = np.ones((n * 4, 3), dtype=bboxes.dtype)
        xy[:, :2] = bboxes[:, [0, 1, 2, 3, 0, 3, 2, 1]].reshape(n * 4, 2)  # x1y1, x2y2, x1y2, x2y1
        xy = xy @ M.T  # å˜æ¢
        xy = (xy[:, :2] / xy[:, 2:3] if self.perspective else xy[:, :2]).reshape(n, 8)  # é€è§†é‡ç¼©æ”¾æˆ–ä»¿å°„

        # åˆ›å»ºæ–°çš„æ¡†
        x = xy[:, [0, 2, 4, 6]]
        y = xy[:, [1, 3, 5, 7]]
        return np.concatenate((x.min(1), y.min(1), x.max(1), y.max(1)), dtype=bboxes.dtype).reshape(4, n).T

    def apply_segments(self, segments, M):
        """
        å¯¹åˆ†å‰²åº”ç”¨ä»¿å°„å˜æ¢å¹¶ç”Ÿæˆæ–°çš„è¾¹ç•Œæ¡†ã€‚

        è¯¥å‡½æ•°å¯¹è¾“å…¥çš„åˆ†å‰²åº”ç”¨ä»¿å°„å˜æ¢ï¼Œå¹¶æ ¹æ®å˜æ¢åçš„åˆ†å‰²ç”Ÿæˆæ–°çš„è¾¹ç•Œæ¡†ã€‚
        å®ƒå°†å˜æ¢åçš„åˆ†å‰²è£å‰ªåˆ°æ–°çš„è¾¹ç•Œæ¡†å†…ã€‚

        å‚æ•°ï¼š
            segments (np.ndarray): è¾“å…¥çš„åˆ†å‰²ï¼Œå½¢çŠ¶ä¸º(N, M, 2)ï¼Œå…¶ä¸­Næ˜¯åˆ†å‰²çš„æ•°é‡ï¼ŒMæ˜¯æ¯ä¸ªåˆ†å‰²ä¸­çš„ç‚¹çš„æ•°é‡ã€‚
            M (np.ndarray): å½¢çŠ¶ä¸º(3, 3)çš„ä»¿å°„å˜æ¢çŸ©é˜µã€‚

        è¿”å›ï¼š
            (Tuple[np.ndarray, np.ndarray]): è¿”å›ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«ï¼š
                - æ–°çš„è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º(N, 4)çš„xyxyæ ¼å¼ã€‚
                - å˜æ¢åçš„åˆ†å‰²ï¼Œå½¢çŠ¶ä¸º(N, M, 2)ã€‚

        ç¤ºä¾‹ï¼š
            >>> segments = np.random.rand(10, 500, 2)  # 10ä¸ªåˆ†å‰²ï¼Œæ¯ä¸ªæœ‰500ä¸ªç‚¹
            >>> M = np.eye(3)  # å•ä½å˜æ¢çŸ©é˜µ
            >>> new_bboxes, new_segments = apply_segments(segments, M)
        """
        n, num = segments.shape[:2]
        if n == 0:
            return [], segments

        xy = np.ones((n * num, 3), dtype=segments.dtype)
        segments = segments.reshape(-1, 2)
        xy[:, :2] = segments
        xy = xy @ M.T  # å˜æ¢
        xy = xy[:, :2] / xy[:, 2:3]
        segments = xy.reshape(n, -1, 2)
        bboxes = np.stack([segment2box(xy, self.size[0], self.size[1]) for xy in segments], 0)
        segments[..., 0] = segments[..., 0].clip(bboxes[:, 0:1], bboxes[:, 2:3])
        segments[..., 1] = segments[..., 1].clip(bboxes[:, 1:2], bboxes[:, 3:4])
        return bboxes, segments

    def apply_keypoints(self, keypoints, M):
        """
        å¯¹å…³é”®ç‚¹åº”ç”¨ä»¿å°„å˜æ¢ã€‚

        è¯¥æ–¹æ³•ä½¿ç”¨æä¾›çš„ä»¿å°„å˜æ¢çŸ©é˜µå˜æ¢è¾“å…¥å…³é”®ç‚¹ã€‚å¦‚æœéœ€è¦ï¼Œå®ƒè¿˜ä¼šå¤„ç†é€è§†é‡ç¼©æ”¾ï¼Œ
        å¹¶æ›´æ–°é‚£äº›å˜æ¢åè¶…å‡ºå›¾åƒè¾¹ç•Œçš„å…³é”®ç‚¹çš„å¯è§æ€§ã€‚

        å‚æ•°ï¼š
            keypoints (np.ndarray): å…³é”®ç‚¹æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(N, 17, 3)ï¼Œå…¶ä¸­Næ˜¯å®ä¾‹çš„æ•°é‡ï¼Œ17æ˜¯æ¯ä¸ªå®ä¾‹çš„å…³é”®ç‚¹æ•°é‡ï¼Œ
                3è¡¨ç¤º(x, y, å¯è§æ€§)ã€‚
            M (np.ndarray): 3x3ä»¿å°„å˜æ¢çŸ©é˜µã€‚

        è¿”å›ï¼š
            (np.ndarray): å˜æ¢åçš„å…³é”®ç‚¹æ•°ç»„ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ(N, 17, 3)ã€‚

        ç¤ºä¾‹ï¼š
            >>> random_perspective = RandomPerspective()
            >>> keypoints = np.random.rand(5, 17, 3)  # 5ä¸ªå®ä¾‹ï¼Œæ¯ä¸ªå®ä¾‹æœ‰17ä¸ªå…³é”®ç‚¹
            >>> M = np.eye(3)  # å•ä½å˜æ¢çŸ©é˜µ
            >>> transformed_keypoints = random_perspective.apply_keypoints(keypoints, M)
        """
        n, nkpt = keypoints.shape[:2]
        if n == 0:
            return keypoints
        xy = np.ones((n * nkpt, 3), dtype=keypoints.dtype)
        visible = keypoints[..., 2].reshape(n * nkpt, 1)
        xy[:, :2] = keypoints[..., :2].reshape(n * nkpt, 2)
        xy = xy @ M.T  # å˜æ¢
        xy = xy[:, :2] / xy[:, 2:3]  # é€è§†é‡ç¼©æ”¾æˆ–ä»¿å°„
        out_mask = (xy[:, 0] < 0) | (xy[:, 1] < 0) | (xy[:, 0] > self.size[0]) | (xy[:, 1] > self.size[1])
        visible[out_mask] = 0
        return np.concatenate([xy, visible], axis=-1).reshape(n, nkpt, 3)

    def __call__(self, labels):
        """
        å¯¹å›¾åƒåŠå…¶å¯¹åº”çš„æ ‡ç­¾åº”ç”¨éšæœºé€è§†å’Œä»¿å°„å˜æ¢ã€‚

        è¯¥æ–¹æ³•å¯¹è¾“å…¥å›¾åƒæ‰§è¡Œä¸€ç³»åˆ—å˜æ¢ï¼ŒåŒ…æ‹¬æ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€å‰ªåˆ‡å’Œé€è§†ç•¸å˜ï¼Œ
        å¹¶ç›¸åº”åœ°è°ƒæ•´å¯¹åº”çš„è¾¹ç•Œæ¡†ã€åˆ†å‰²å’Œå…³é”®ç‚¹ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ•°æ®å’Œæ³¨é‡Šçš„å­—å…¸ã€‚
                å¿…é¡»åŒ…æ‹¬ï¼š
                    'img' (ndarray): è¾“å…¥å›¾åƒã€‚
                    'cls' (ndarray): ç±»åˆ«æ ‡ç­¾ã€‚
                    'instances' (Instances): åŒ…å«è¾¹ç•Œæ¡†ã€åˆ†å‰²å’Œå…³é”®ç‚¹çš„å®ä¾‹ã€‚
                å¯é€‰åœ°åŒ…æ‹¬ï¼š
                    'mosaic_border' (Tuple[int, int]): é©¬èµ›å…‹å¢å¼ºçš„è¾¹æ¡†å¤§å°ã€‚

        è¿”å›ï¼š
            (Dict): å˜æ¢åçš„æ ‡ç­¾å­—å…¸ï¼ŒåŒ…å«ï¼š
                - 'img' (np.ndarray): å˜æ¢åçš„å›¾åƒã€‚
                - 'cls' (np.ndarray): æ›´æ–°åçš„ç±»åˆ«æ ‡ç­¾ã€‚
                - 'instances' (Instances): æ›´æ–°åçš„ç›®æ ‡å®ä¾‹ã€‚
                - 'resized_shape' (Tuple[int, int]): å˜æ¢åçš„æ–°å›¾åƒå¤§å°ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = RandomPerspective()
            >>> image = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            >>> labels = {
            ...     "img": image,
            ...     "cls": np.array([0, 1, 2]),
            ...     "instances": Instances(bboxes=np.array([[10, 10, 50, 50], [100, 100, 150, 150]])),
            ... }
            >>> result = transform(labels)
            >>> assert result["img"].shape[:2] == result["resized_shape"]
        """
        if self.pre_transform and "mosaic_border" not in labels:
            labels = self.pre_transform(labels)
        labels.pop("ratio_pad", None)  # ä¸éœ€è¦æ¯”ä¾‹å¡«å……

        img = labels["img"]
        cls = labels["cls"]
        instances = labels.pop("instances")
        # ç¡®ä¿åæ ‡æ ¼å¼æ­£ç¡®
        instances.convert_bbox(format="xyxy")
        instances.denormalize(*img.shape[:2][::-1])

        border = labels.pop("mosaic_border", self.border)
        self.size = img.shape[1] + border[1] * 2, img.shape[0] + border[0] * 2  # w, h
        # Mæ˜¯ä»¿å°„çŸ©é˜µ
        # ç”¨äºå‡½æ•°:`box_candidates`çš„ç¼©æ”¾
        img, M, scale = self.affine_transform(img, border)

        bboxes = self.apply_bboxes(instances.bboxes, M)

        segments = instances.segments
        keypoints = instances.keypoints
        # å¦‚æœæœ‰åˆ†å‰²ï¼Œæ›´æ–°è¾¹ç•Œæ¡†
        if len(segments):
            bboxes, segments = self.apply_segments(segments, M)

        if keypoints is not None:
            keypoints = self.apply_keypoints(keypoints, M)
        new_instances = Instances(bboxes, segments, keypoints, bbox_format="xyxy", normalized=False)
        # è£å‰ª
        new_instances.clip(*self.size)

        # è¿‡æ»¤å®ä¾‹
        instances.scale(scale_w=scale, scale_h=scale, bbox_only=True)
        # ä½¿è¾¹ç•Œæ¡†ä¸æ–°è¾¹ç•Œæ¡†å…·æœ‰ç›¸åŒçš„ç¼©æ”¾
        i = self.box_candidates(
            box1=instances.bboxes.T, box2=new_instances.bboxes.T, area_thr=0.01 if len(segments) else 0.10
        )
        labels["instances"] = new_instances[i]
        labels["cls"] = cls[i]
        labels["img"] = img
        labels["resized_shape"] = img.shape[:2]
        return labels

    @staticmethod
    def box_candidates(box1, box2, wh_thr=2, ar_thr=100, area_thr=0.1, eps=1e-16):
        """
        æ ¹æ®å¤§å°å’Œé•¿å®½æ¯”æ ‡å‡†è®¡ç®—å€™é€‰æ¡†ï¼Œç”¨äºè¿›ä¸€æ­¥å¤„ç†ã€‚

        è¯¥æ–¹æ³•æ¯”è¾ƒå˜æ¢å‰åçš„è¾¹ç•Œæ¡†ï¼Œä»¥ç¡®å®šå®ƒä»¬æ˜¯å¦ç¬¦åˆæŒ‡å®šçš„å®½åº¦ã€é«˜åº¦ã€é•¿å®½æ¯”å’Œé¢ç§¯æ ‡å‡†ã€‚
        å®ƒç”¨äºè¿‡æ»¤é‚£äº›ç»è¿‡å˜æ¢åè¢«è¿‡åº¦æ‰­æ›²æˆ–ç¼©å°çš„è¾¹ç•Œæ¡†ã€‚

        å‚æ•°ï¼š
            box1 (numpy.ndarray): å˜æ¢å‰çš„è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º(4, N)ï¼Œå…¶ä¸­Næ˜¯è¾¹ç•Œæ¡†çš„æ•°é‡ã€‚æ ¼å¼ä¸º[x1, y1, x2, y2]ï¼ˆç»å¯¹åæ ‡ï¼‰ã€‚
            box2 (numpy.ndarray): å˜æ¢åçš„è¾¹ç•Œæ¡†ï¼Œå½¢çŠ¶ä¸º(4, N)ï¼Œæ ¼å¼ä¸º[x1, y1, x2, y2]ï¼ˆç»å¯¹åæ ‡ï¼‰ã€‚
            wh_thr (float): å®½åº¦å’Œé«˜åº¦é˜ˆå€¼ï¼ˆåƒç´ ï¼‰ã€‚ä»»ä½•å°ºå¯¸å°äºè¯¥å€¼çš„æ¡†å°†è¢«æ‹’ç»ã€‚
            ar_thr (float): é•¿å®½æ¯”é˜ˆå€¼ã€‚ä»»ä½•é•¿å®½æ¯”å¤§äºè¯¥å€¼çš„æ¡†å°†è¢«æ‹’ç»ã€‚
            area_thr (float): é¢ç§¯æ¯”é˜ˆå€¼ã€‚æ–°æ—§æ¡†çš„é¢ç§¯æ¯”ï¼ˆæ–°æ¡†é¢ç§¯/æ—§æ¡†é¢ç§¯ï¼‰å°äºè¯¥å€¼çš„æ¡†å°†è¢«æ‹’ç»ã€‚
            eps (float): é˜²æ­¢é™¤é›¶é”™è¯¯çš„å°å¸¸æ•°ã€‚

        è¿”å›ï¼š
            (numpy.ndarray): å½¢çŠ¶ä¸º(n)çš„å¸ƒå°”æ•°ç»„ï¼ŒæŒ‡ç¤ºå“ªäº›æ¡†æ˜¯å€™é€‰æ¡†ã€‚
                Trueå€¼å¯¹åº”äºç¬¦åˆæ‰€æœ‰æ ‡å‡†çš„æ¡†ã€‚

        ç¤ºä¾‹ï¼š
            >>> random_perspective = RandomPerspective()
            >>> box1 = np.array([[0, 0, 100, 100], [0, 0, 50, 50]]).T
            >>> box2 = np.array([[10, 10, 90, 90], [5, 5, 45, 45]]).T
            >>> candidates = random_perspective.box_candidates(box1, box2)
            >>> print(candidates)
            [True True]
        """
        w1, h1 = box1[2] - box1[0], box1[3] - box1[1]
        w2, h2 = box2[2] - box2[0], box2[3] - box2[1]
        ar = np.maximum(w2 / (h2 + eps), h2 / (w2 + eps))  # é•¿å®½æ¯”
        return (w2 > wh_thr) & (h2 > wh_thr) & (w2 * h2 / (w1 * h1 + eps) > area_thr) & (ar < ar_thr)  # å€™é€‰æ¡†


class RandomHSV:
    """
    éšæœºè°ƒæ•´å›¾åƒçš„è‰²è°ƒï¼ˆHueï¼‰ã€é¥±å’Œåº¦ï¼ˆSaturationï¼‰å’Œæ˜åº¦ï¼ˆValueï¼‰é€šé“ã€‚

    è¯¥ç±»å¯¹å›¾åƒåº”ç”¨éšæœºçš„HSVå¢å¼ºï¼Œå˜åŒ–èŒƒå›´ç”±hgainã€sgainå’Œvgainè®¾å®šçš„é¢„å®šä¹‰é™åˆ¶æ§åˆ¶ã€‚

    å±æ€§ï¼š
        hgain (float): è‰²è°ƒçš„æœ€å¤§å˜åŒ–èŒƒå›´ï¼Œé€šå¸¸åœ¨[0, 1]ä¹‹é—´ã€‚
        sgain (float): é¥±å’Œåº¦çš„æœ€å¤§å˜åŒ–èŒƒå›´ï¼Œé€šå¸¸åœ¨[0, 1]ä¹‹é—´ã€‚
        vgain (float): æ˜åº¦çš„æœ€å¤§å˜åŒ–èŒƒå›´ï¼Œé€šå¸¸åœ¨[0, 1]ä¹‹é—´ã€‚

    æ–¹æ³•ï¼š
        __call__: å¯¹å›¾åƒåº”ç”¨éšæœºHSVå¢å¼ºã€‚

    ç¤ºä¾‹ï¼š
        >>> import numpy as np
        >>> from ultralytics.data.augment import RandomHSV
        >>> augmenter = RandomHSV(hgain=0.5, sgain=0.5, vgain=0.5)
        >>> image = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
        >>> labels = {"img": image}
        >>> augmenter(labels)
        >>> augmented_image = augmented_labels["img"]
    """

    def __init__(self, hgain=0.5, sgain=0.5, vgain=0.5) -> None:
        """
        åˆå§‹åŒ–RandomHSVå¯¹è±¡ï¼Œç”¨äºéšæœºHSVï¼ˆè‰²è°ƒã€é¥±å’Œåº¦ã€æ˜åº¦ï¼‰å¢å¼ºã€‚

        è¯¥ç±»åœ¨æŒ‡å®šçš„é™åˆ¶èŒƒå›´å†…å¯¹å›¾åƒçš„HSVé€šé“è¿›è¡Œéšæœºè°ƒæ•´ã€‚

        å‚æ•°ï¼š
            hgain (float): è‰²è°ƒçš„æœ€å¤§å˜åŒ–èŒƒå›´ï¼Œåº”åœ¨[0, 1]ä¹‹é—´ã€‚
            sgain (float): é¥±å’Œåº¦çš„æœ€å¤§å˜åŒ–èŒƒå›´ï¼Œåº”åœ¨[0, 1]ä¹‹é—´ã€‚
            vgain (float): æ˜åº¦çš„æœ€å¤§å˜åŒ–èŒƒå›´ï¼Œåº”åœ¨[0, 1]ä¹‹é—´ã€‚

        ç¤ºä¾‹ï¼š
            >>> hsv_aug = RandomHSV(hgain=0.5, sgain=0.5, vgain=0.5)
            >>> hsv_aug(image)
        """
        self.hgain = hgain
        self.sgain = sgain
        self.vgain = vgain

    def __call__(self, labels):
        """
        åœ¨é¢„å®šä¹‰çš„é™åˆ¶èŒƒå›´å†…å¯¹å›¾åƒåº”ç”¨éšæœºHSVå¢å¼ºã€‚

        è¯¥æ–¹æ³•é€šè¿‡éšæœºè°ƒæ•´å›¾åƒçš„è‰²è°ƒã€é¥±å’Œåº¦å’Œæ˜åº¦ï¼ˆHSVï¼‰é€šé“æ¥ä¿®æ”¹è¾“å…¥å›¾åƒã€‚
        è°ƒæ•´èŒƒå›´ç”±åˆå§‹åŒ–æ—¶è®¾ç½®çš„hgainã€sgainå’Œvgainæ§åˆ¶ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ•°æ®å’Œå…ƒæ•°æ®çš„å­—å…¸ã€‚å¿…é¡»åŒ…æ‹¬ä¸€ä¸ª'img'é”®ï¼Œå€¼ä¸ºå›¾åƒçš„numpyæ•°ç»„ã€‚

        è¿”å›ï¼š
            (None): è¯¥å‡½æ•°å°±åœ°ä¿®æ”¹è¾“å…¥çš„'labels'å­—å…¸ï¼Œæ›´æ–°'img'é”®ä¸ºHSVå¢å¼ºåçš„å›¾åƒã€‚

        ç¤ºä¾‹ï¼š
            >>> hsv_augmenter = RandomHSV(hgain=0.5, sgain=0.5, vgain=0.5)
            >>> labels = {"img": np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)}
            >>> hsv_augmenter(labels)
            >>> augmented_img = labels["img"]
        """
        img = labels["img"]
        if self.hgain or self.sgain or self.vgain:
            r = np.random.uniform(-1, 1, 3) * [self.hgain, self.sgain, self.vgain] + 1  # éšæœºå¢ç›Š
            hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))
            dtype = img.dtype  # uint8

            x = np.arange(0, 256, dtype=r.dtype)
            lut_hue = ((x * r[0]) % 180).astype(dtype)
            lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)
            lut_val = np.clip(x * r[2], 0, 255).astype(dtype)

            im_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))
            cv2.cvtColor(im_hsv, cv2.COLOR_HSV2BGR, dst=img)  # ä¸éœ€è¦è¿”å›
        return labels


class RandomFlip:
    """
    å¯¹å›¾åƒåº”ç”¨éšæœºæ°´å¹³æˆ–å‚ç›´ç¿»è½¬ï¼Œå…·æœ‰ç»™å®šçš„æ¦‚ç‡ã€‚

    è¯¥ç±»æ‰§è¡Œéšæœºå›¾åƒç¿»è½¬å¹¶æ›´æ–°ç›¸åº”çš„å®ä¾‹æ³¨é‡Šï¼Œå¦‚è¾¹ç•Œæ¡†å’Œå…³é”®ç‚¹ã€‚

    å±æ€§ï¼š
        p (float): åº”ç”¨ç¿»è½¬çš„æ¦‚ç‡ï¼Œå¿…é¡»åœ¨0åˆ°1ä¹‹é—´ã€‚
        direction (str): ç¿»è½¬æ–¹å‘ï¼Œå¯ä»¥æ˜¯'horizontal'æˆ–'vertical'ã€‚
        flip_idx (array-like): ç¿»è½¬å…³é”®ç‚¹çš„ç´¢å¼•æ˜ å°„ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚

    æ–¹æ³•ï¼š
        __call__: å¯¹å›¾åƒåŠå…¶æ³¨é‡Šåº”ç”¨éšæœºç¿»è½¬å˜æ¢ã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = RandomFlip(p=0.5, direction="horizontal")
        >>> result = transform({"img": image, "instances": instances})
        >>> flipped_image = result["img"]
        >>> flipped_instances = result["instances"]
    """

    def __init__(self, p=0.5, direction="horizontal", flip_idx=None) -> None:
        """
        ä½¿ç”¨æ¦‚ç‡å’Œæ–¹å‘åˆå§‹åŒ–RandomFlipç±»ã€‚

        è¯¥ç±»å¯¹å›¾åƒåº”ç”¨éšæœºæ°´å¹³æˆ–å‚ç›´ç¿»è½¬ï¼Œå…·æœ‰ç»™å®šçš„æ¦‚ç‡ã€‚
        å®ƒè¿˜ä¼šç›¸åº”åœ°æ›´æ–°ä»»ä½•å®ä¾‹ï¼ˆå¦‚è¾¹ç•Œæ¡†ã€å…³é”®ç‚¹ç­‰ï¼‰ã€‚

        å‚æ•°ï¼š
            p (float): åº”ç”¨ç¿»è½¬çš„æ¦‚ç‡ï¼Œå¿…é¡»åœ¨0åˆ°1ä¹‹é—´ã€‚
            direction (str): ç¿»è½¬çš„æ–¹å‘ï¼Œå¿…é¡»æ˜¯'horizontal'æˆ–'vertical'ã€‚
            flip_idx (List[int] | None): ç¿»è½¬å…³é”®ç‚¹çš„ç´¢å¼•æ˜ å°„ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚

        å¼‚å¸¸ï¼š
            AssertionError: å¦‚æœæ–¹å‘ä¸æ˜¯'horizontal'æˆ–'vertical'ï¼Œæˆ–è€…pä¸åœ¨0åˆ°1ä¹‹é—´ã€‚

        ç¤ºä¾‹ï¼š
            >>> flip = RandomFlip(p=0.5, direction="horizontal")
            >>> flip_with_idx = RandomFlip(p=0.7, direction="vertical", flip_idx=[1, 0, 3, 2, 5, 4])
        """
        assert direction in {"horizontal", "vertical"}, f"æ”¯æŒæ–¹å‘ `horizontal` æˆ– `vertical`ï¼Œä½†å¾—åˆ° {direction}"
        assert 0 <= p <= 1.0, f"æ¦‚ç‡åº”åœ¨[0, 1]èŒƒå›´å†…ï¼Œä½†å¾—åˆ° {p}."

        self.p = p
        self.direction = direction
        self.flip_idx = flip_idx

    def __call__(self, labels):
        """
        å¯¹å›¾åƒåº”ç”¨éšæœºç¿»è½¬ï¼Œå¹¶ç›¸åº”æ›´æ–°å®ä¾‹ï¼ˆå¦‚è¾¹ç•Œæ¡†æˆ–å…³é”®ç‚¹ï¼‰ã€‚

        è¯¥æ–¹æ³•æ ¹æ®åˆå§‹åŒ–æ—¶çš„æ¦‚ç‡å’Œæ–¹å‘éšæœºç¿»è½¬è¾“å…¥å›¾åƒï¼Œå¹¶æ›´æ–°ç›¸åº”çš„å®ä¾‹ï¼ˆè¾¹ç•Œæ¡†ã€å…³é”®ç‚¹ï¼‰ï¼Œ
        ä»¥åŒ¹é…ç¿»è½¬åçš„å›¾åƒã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«ä»¥ä¸‹é”®çš„å­—å…¸ï¼š
                'img' (numpy.ndarray): éœ€è¦ç¿»è½¬çš„å›¾åƒã€‚
                'instances' (ultralytics.utils.instance.Instances): åŒ…å«è¾¹ç•Œæ¡†å¹¶å¯é€‰åœ°åŒ…å«å…³é”®ç‚¹çš„å®ä¾‹å¯¹è±¡ã€‚

        è¿”å›ï¼š
            (Dict): ç›¸åŒçš„å­—å…¸ï¼Œå…¶ä¸­åŒ…å«ç¿»è½¬åçš„å›¾åƒå’Œæ›´æ–°åçš„å®ä¾‹ï¼š
                'img' (numpy.ndarray): ç¿»è½¬åçš„å›¾åƒã€‚
                'instances' (ultralytics.utils.instance.Instances): æ›´æ–°åçš„å®ä¾‹ï¼ŒåŒ¹é…ç¿»è½¬åçš„å›¾åƒã€‚

        ç¤ºä¾‹ï¼š
            >>> labels = {"img": np.random.rand(640, 640, 3), "instances": Instances(...)}
            >>> random_flip = RandomFlip(p=0.5, direction="horizontal")
            >>> flipped_labels = random_flip(labels)
        """
        img = labels["img"]
        instances = labels.pop("instances")
        instances.convert_bbox(format="xywh")
        h, w = img.shape[:2]
        h = 1 if instances.normalized else h
        w = 1 if instances.normalized else w

        # ä¸Šä¸‹ç¿»è½¬
        if self.direction == "vertical" and random.random() < self.p:
            img = np.flipud(img)
            instances.flipud(h)
        if self.direction == "horizontal" and random.random() < self.p:
            img = np.fliplr(img)
            instances.fliplr(w)
            # å¯¹å…³é”®ç‚¹è¿›è¡Œç¿»è½¬
            if self.flip_idx is not None and instances.keypoints is not None:
                instances.keypoints = np.ascontiguousarray(instances.keypoints[:, self.flip_idx, :])
        labels["img"] = np.ascontiguousarray(img)
        labels["instances"] = instances
        return labels


class LetterBox:
    """
    å›¾åƒçš„ç¼©æ”¾å’Œå¡«å……ï¼Œé€‚ç”¨äºç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ä»»åŠ¡ã€‚

    è¯¥ç±»å°†å›¾åƒè°ƒæ•´ä¸ºæŒ‡å®šçš„å¤§å°ï¼Œå¹¶æ·»åŠ å¡«å……ï¼ŒåŒæ—¶ä¿æŒå›¾åƒçš„å®½é«˜æ¯”ã€‚å®ƒè¿˜ä¼šæ›´æ–°ç›¸åº”çš„æ ‡ç­¾å’Œè¾¹ç•Œæ¡†ã€‚

    å±æ€§ï¼š
        new_shape (tuple): ç›®æ ‡å¤§å°ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ç”¨äºç¼©æ”¾ã€‚
        auto (bool): æ˜¯å¦ä½¿ç”¨æœ€å°çŸ©å½¢ã€‚
        scaleFill (bool): æ˜¯å¦å°†å›¾åƒæ‹‰ä¼¸åˆ°æ–°çš„å¤§å°è€Œä¸è¿›è¡Œå¡«å……ã€‚
        scaleup (bool): æ˜¯å¦å…è®¸æ”¾å¤§ã€‚å¦‚æœä¸ºFalseï¼Œä»…è¿›è¡Œç¼©å°ã€‚
        stride (int): ç”¨äºè°ƒæ•´å¡«å……çš„æ­¥é•¿ã€‚
        center (bool): æ˜¯å¦å°†å›¾åƒå±…ä¸­ï¼Œæˆ–å¯¹é½åˆ°å·¦ä¸Šè§’ã€‚

    æ–¹æ³•ï¼š
        __call__: ç¼©æ”¾å¹¶å¡«å……å›¾åƒï¼Œæ›´æ–°æ ‡ç­¾å’Œè¾¹ç•Œæ¡†ã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = LetterBox(new_shape=(640, 640))
        >>> result = transform(labels)
        >>> resized_img = result["img"]
        >>> updated_instances = result["instances"]
    """

    def __init__(self, new_shape=(640, 640), auto=False, scaleFill=False, scaleup=True, center=True, stride=32):
        """
        åˆå§‹åŒ–LetterBoxå¯¹è±¡ï¼Œç”¨äºç¼©æ”¾å’Œå¡«å……å›¾åƒã€‚

        è¯¥ç±»æ—¨åœ¨ä¸ºç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ä»»åŠ¡ç¼©æ”¾å’Œå¡«å……å›¾åƒã€‚
        å®ƒæ”¯æŒå„ç§ç¼©æ”¾æ¨¡å¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨ç¼©æ”¾ã€å¡«å……ç¼©æ”¾å’Œä¿¡ç®±å¡«å……ï¼ˆletterboxingï¼‰ã€‚

        å‚æ•°ï¼š
            new_shape (Tuple[int, int]): ç¼©æ”¾åçš„ç›®æ ‡å¤§å°ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚
            auto (bool): å¦‚æœä¸ºTrueï¼Œä½¿ç”¨æœ€å°çŸ©å½¢è¿›è¡Œç¼©æ”¾ã€‚å¦‚æœä¸ºFalseï¼Œç›´æ¥ä½¿ç”¨new_shapeã€‚
            scaleFill (bool): å¦‚æœä¸ºTrueï¼Œå›¾åƒä¼šè¢«æ‹‰ä¼¸åˆ°new_shapeè€Œä¸è¿›è¡Œå¡«å……ã€‚
            scaleup (bool): å¦‚æœä¸ºTrueï¼Œå…è®¸æ”¾å¤§ã€‚å¦‚æœä¸ºFalseï¼Œä»…è¿›è¡Œç¼©å°ã€‚
            center (bool): å¦‚æœä¸ºTrueï¼Œå±…ä¸­æ˜¾ç¤ºå›¾åƒã€‚å¦‚æœä¸ºFalseï¼Œå°†å›¾åƒæ”¾ç½®åœ¨å·¦ä¸Šè§’ã€‚
            stride (int): æ¨¡å‹çš„æ­¥é•¿ï¼ˆä¾‹å¦‚ï¼ŒYOLOv5çš„æ­¥é•¿ä¸º32ï¼‰ã€‚

        å±æ€§ï¼š
            new_shape (Tuple[int, int]): ç¼©æ”¾åçš„ç›®æ ‡å¤§å°ã€‚
            auto (bool): ä½¿ç”¨æœ€å°çŸ©å½¢ç¼©æ”¾çš„æ ‡å¿—ã€‚
            scaleFill (bool): æ˜¯å¦æ‹‰ä¼¸å›¾åƒè€Œä¸è¿›è¡Œå¡«å……ã€‚
            scaleup (bool): æ˜¯å¦å…è®¸æ”¾å¤§ã€‚
            stride (int): ç¡®ä¿å›¾åƒå¤§å°å¯è¢«æ­¥é•¿æ•´é™¤çš„æ­¥é•¿å€¼ã€‚

        ç¤ºä¾‹ï¼š
            >>> letterbox = LetterBox(new_shape=(640, 640), auto=False, scaleFill=False, scaleup=True, stride=32)
            >>> resized_img = letterbox(original_img)
        """
        self.new_shape = new_shape
        self.auto = auto
        self.scaleFill = scaleFill
        self.scaleup = scaleup
        self.stride = stride
        self.center = center  # æ˜¯å¦å°†å›¾åƒå±…ä¸­æˆ–æ”¾ç½®åœ¨å·¦ä¸Šè§’

    def __call__(self, labels=None, image=None):
        """
        ä¸ºç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²æˆ–å§¿æ€ä¼°è®¡ä»»åŠ¡ç¼©æ”¾å’Œå¡«å……å›¾åƒã€‚

        è¯¥æ–¹æ³•å¯¹è¾“å…¥å›¾åƒåº”ç”¨ä¿¡ç®±å¡«å……ï¼Œå³åœ¨ä¿æŒå›¾åƒå®½é«˜æ¯”çš„åŒæ—¶ç¼©æ”¾å›¾åƒå¹¶æ·»åŠ å¡«å……ï¼Œ
        ä½¿å…¶ç¬¦åˆæ–°çš„å½¢çŠ¶ã€‚å®ƒè¿˜ä¼šç›¸åº”åœ°æ›´æ–°æ‰€æœ‰å…³è”çš„æ ‡ç­¾ã€‚

        å‚æ•°ï¼š
            labels (Dict | None): åŒ…å«å›¾åƒæ•°æ®å’Œå…³è”æ ‡ç­¾çš„å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ºç©ºå­—å…¸ã€‚
            image (np.ndarray | None): è¾“å…¥å›¾åƒçš„numpyæ•°ç»„ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™ä»'labels'ä¸­è·å–å›¾åƒã€‚

        è¿”å›ï¼š
            (Dict | Tuple): å¦‚æœæä¾›äº†'labels'ï¼Œåˆ™è¿”å›æ›´æ–°åçš„å­—å…¸ï¼ŒåŒ…æ‹¬ç¼©æ”¾å’Œå¡«å……åçš„å›¾åƒï¼Œ
                æ›´æ–°åçš„æ ‡ç­¾ï¼Œä»¥åŠå…¶ä»–å…ƒæ•°æ®ã€‚å¦‚æœ'labels'ä¸ºç©ºï¼Œåˆ™è¿”å›ä¸€ä¸ªåŒ…å«ç¼©æ”¾å’Œå¡«å……åå›¾åƒçš„å…ƒç»„ï¼Œ
                ä»¥åŠæ¯”ä¾‹å’Œå¡«å……å¤§å°çš„å…ƒç»„ï¼ˆratioï¼Œ(left_pad, top_pad)ï¼‰ã€‚

        ç¤ºä¾‹ï¼š
            >>> letterbox = LetterBox(new_shape=(640, 640))
            >>> result = letterbox(labels={"img": np.zeros((480, 640, 3)), "instances": Instances(...)})
            >>> resized_img = result["img"]
            >>> updated_instances = result["instances"]
        """
        if labels is None:
            labels = {}
        img = labels.get("img") if image is None else image
        shape = img.shape[:2]  # å½“å‰å½¢çŠ¶ [é«˜åº¦, å®½åº¦]
        new_shape = labels.pop("rect_shape", self.new_shape)
        if isinstance(new_shape, int):
            new_shape = (new_shape, new_shape)

        # ç¼©æ”¾æ¯”ä¾‹ï¼ˆæ–° / æ—§ï¼‰
        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
        if not self.scaleup:  # ä»…ç¼©å°ï¼Œä¸æ”¾å¤§ï¼ˆä¸ºæé«˜éªŒè¯é›†mAPï¼‰
            r = min(r, 1.0)

        # è®¡ç®—å¡«å……
        ratio = r, r  # å®½åº¦ï¼Œé«˜åº¦æ¯”ä¾‹
        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
        dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # å®½é«˜å¡«å……
        if self.auto:  # æœ€å°çŸ©å½¢
            dw, dh = np.mod(dw, self.stride), np.mod(dh, self.stride)  # å®½é«˜å¡«å……
        elif self.scaleFill:  # æ‹‰ä¼¸
            dw, dh = 0.0, 0.0
            new_unpad = (new_shape[1], new_shape[0])
            ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # å®½åº¦ï¼Œé«˜åº¦æ¯”ä¾‹

        if self.center:
            dw /= 2  # å°†å¡«å……åˆ†é…åˆ°ä¸¤è¾¹
            dh /= 2

        if shape[::-1] != new_unpad:  # ç¼©æ”¾
            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
        top, bottom = int(round(dh - 0.1)) if self.center else 0, int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)) if self.center else 0, int(round(dw + 0.1))
        img = cv2.copyMakeBorder(
            img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114)
        )  # æ·»åŠ è¾¹æ¡†
        if labels.get("ratio_pad"):
            labels["ratio_pad"] = (labels["ratio_pad"], (left, top))  # ç”¨äºè¯„ä¼°

        if len(labels):
            labels = self._update_labels(labels, ratio, left, top)
            labels["img"] = img
            labels["resized_shape"] = new_shape
            return labels
        else:
            return img

    @staticmethod
    def _update_labels(labels, ratio, padw, padh):
        """
        åœ¨å¯¹å›¾åƒåº”ç”¨ä¿¡ç®±å¡«å……åæ›´æ–°æ ‡ç­¾ã€‚

        è¯¥æ–¹æ³•ä¿®æ”¹æ ‡ç­¾ä¸­çš„å®ä¾‹çš„è¾¹ç•Œæ¡†åæ ‡ï¼Œä»¥è€ƒè™‘ä¿¡ç®±å¡«å……è¿‡ç¨‹ä¸­çš„ç¼©æ”¾å’Œå¡«å……ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ ‡ç­¾å’Œå®ä¾‹çš„å­—å…¸ã€‚
            ratio (Tuple[float, float]): åº”ç”¨åˆ°å›¾åƒçš„ç¼©æ”¾æ¯”ä¾‹ï¼ˆå®½åº¦ï¼Œé«˜åº¦ï¼‰ã€‚
            padw (float): å›¾åƒæ·»åŠ çš„å¡«å……å®½åº¦ã€‚
            padh (float): å›¾åƒæ·»åŠ çš„å¡«å……é«˜åº¦ã€‚

        è¿”å›ï¼š
            (Dict): æ›´æ–°åçš„æ ‡ç­¾å­—å…¸ï¼ŒåŒ…å«ä¿®æ”¹åçš„å®ä¾‹åæ ‡ã€‚

        ç¤ºä¾‹ï¼š
            >>> letterbox = LetterBox(new_shape=(640, 640))
            >>> labels = {"instances": Instances(...)}
            >>> ratio = (0.5, 0.5)
            >>> padw, padh = 10, 20
            >>> updated_labels = letterbox._update_labels(labels, ratio, padw, padh)
        """
        labels["instances"].convert_bbox(format="xyxy")
        labels["instances"].denormalize(*labels["img"].shape[:2][::-1])
        labels["instances"].scale(*ratio)
        labels["instances"].add_padding(padw, padh)
        return labels


class CopyPaste(BaseMixTransform):
    """
    Copy-Pasteç±»ï¼Œç”¨äºå¯¹å›¾åƒæ•°æ®é›†åº”ç”¨Copy-Pasteå¢å¼ºã€‚

    è¯¥ç±»å®ç°äº†è®ºæ–‡â€œSimple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentationâ€
    ï¼ˆhttps://arxiv.org/abs/2012.07177ï¼‰ä¸­æè¿°çš„Copy-Pasteå¢å¼ºæŠ€æœ¯ã€‚å®ƒå°†æ¥è‡ªä¸åŒå›¾åƒçš„ç‰©ä½“ç»„åˆï¼Œ
    åˆ›å»ºæ–°çš„è®­ç»ƒæ ·æœ¬ã€‚

    å±æ€§ï¼š
        dataset (Any): åº”ç”¨Copy-Pasteå¢å¼ºçš„æ•°æ®é›†ã€‚
        pre_transform (Callable | None): å¯é€‰çš„åœ¨Copy-Pasteä¹‹å‰åº”ç”¨çš„å˜æ¢ã€‚
        p (float): åº”ç”¨Copy-Pasteå¢å¼ºçš„æ¦‚ç‡ã€‚

    æ–¹æ³•ï¼š
        get_indexes: è¿”å›æ•°æ®é›†ä¸­çš„éšæœºç´¢å¼•ã€‚
        _mix_transform: å¯¹è¾“å…¥æ ‡ç­¾åº”ç”¨Copy-Pasteå¢å¼ºã€‚
        __call__: å¯¹å›¾åƒå’Œæ³¨é‡Šåº”ç”¨Copy-Pasteå˜æ¢ã€‚

    ç¤ºä¾‹ï¼š
        >>> from ultralytics.data.augment import CopyPaste
        >>> dataset = YourDataset(...)  # ä½ çš„å›¾åƒæ•°æ®é›†
        >>> copypaste = CopyPaste(dataset, p=0.5)
        >>> augmented_labels = copypaste(original_labels)
    """

    def __init__(self, dataset=None, pre_transform=None, p=0.5, mode="flip") -> None:
        """åˆå§‹åŒ–CopyPasteå¯¹è±¡ï¼ŒåŒ…å«æ•°æ®é›†ã€é¢„å˜æ¢å’Œåº”ç”¨MixUpçš„æ¦‚ç‡ã€‚"""
        super().__init__(dataset=dataset, pre_transform=pre_transform, p=p)
        assert mode in {"flip", "mixup"}, f"æœŸæœ›`mode`ä¸º`flip`æˆ–`mixup`ï¼Œä½†å¾—åˆ° {mode}."
        self.mode = mode

    def get_indexes(self):
        """è¿”å›æ•°æ®é›†ä¸­çš„éšæœºç´¢å¼•ï¼Œç”¨äºCopyPasteå¢å¼ºã€‚"""
        return random.randint(0, len(self.dataset) - 1)

    def _mix_transform(self, labels):
        """åº”ç”¨Copy-Pasteå¢å¼ºï¼Œå°†å¦ä¸€ä¸ªå›¾åƒçš„ç‰©ä½“ç»„åˆåˆ°å½“å‰å›¾åƒä¸­ã€‚"""
        labels2 = labels["mix_labels"][0]
        return self._transform(labels, labels2)

    def __call__(self, labels):
        """å¯¹å›¾åƒåŠå…¶æ ‡ç­¾åº”ç”¨Copy-Pasteå¢å¼ºã€‚"""
        if len(labels["instances"].segments) == 0 or self.p == 0:
            return labels
        if self.mode == "flip":
            return self._transform(labels)

        # è·å–ä¸€ä¸ªæˆ–å¤šä¸ªå…¶ä»–å›¾åƒçš„ç´¢å¼•
        indexes = self.get_indexes()
        if isinstance(indexes, int):
            indexes = [indexes]

        # è·å–ç”¨äºMosaicæˆ–MixUpçš„å›¾åƒä¿¡æ¯
        mix_labels = [self.dataset.get_image_and_label(i) for i in indexes]

        if self.pre_transform is not None:
            for i, data in enumerate(mix_labels):
                mix_labels[i] = self.pre_transform(data)
        labels["mix_labels"] = mix_labels

        # æ›´æ–°ç±»åˆ«å’Œæ–‡æœ¬
        labels = self._update_label_text(labels)
        # Mosaicæˆ–MixUp
        labels = self._mix_transform(labels)
        labels.pop("mix_labels", None)
        return labels

    def _transform(self, labels1, labels2={}):
        """åº”ç”¨Copy-Pasteå¢å¼ºï¼Œå°†å¦ä¸€ä¸ªå›¾åƒçš„ç‰©ä½“ç»„åˆåˆ°å½“å‰å›¾åƒä¸­ã€‚"""
        im = labels1["img"]
        cls = labels1["cls"]
        h, w = im.shape[:2]
        instances = labels1.pop("instances")
        instances.convert_bbox(format="xyxy")
        instances.denormalize(w, h)

        im_new = np.zeros(im.shape, np.uint8)
        instances2 = labels2.pop("instances", None)
        if instances2 is None:
            instances2 = deepcopy(instances)
            instances2.fliplr(w)
        ioa = bbox_ioa(instances2.bboxes, instances.bboxes)  # è®¡ç®—äº¤é›†é¢ç§¯ï¼Œ(N, M)
        indexes = np.nonzero((ioa < 0.30).all(1))[0]  # (N, )
        n = len(indexes)
        sorted_idx = np.argsort(ioa.max(1)[indexes])
        indexes = indexes[sorted_idx]
        for j in indexes[: round(self.p * n)]:
            cls = np.concatenate((cls, labels2.get("cls", cls)[[j]]), axis=0)
            instances = Instances.concatenate((instances, instances2[[j]]), axis=0)
            cv2.drawContours(im_new, instances2.segments[[j]].astype(np.int32), -1, (1, 1, 1), cv2.FILLED)

        result = labels2.get("img", cv2.flip(im, 1))  # å¢å¼ºåˆ†å‰²
        i = im_new.astype(bool)
        im[i] = result[i]

        labels1["img"] = im
        labels1["cls"] = cls
        labels1["instances"] = instances
        return labels1


class Albumentations:
    """
    ç”¨äºå›¾åƒå¢å¼ºçš„Albumentationså˜æ¢ã€‚

    è¯¥ç±»ä½¿ç”¨Albumentationsåº“åº”ç”¨å„ç§å›¾åƒå˜æ¢ï¼ŒåŒ…æ‹¬æ¨¡ç³Šã€å‡å€¼æ¨¡ç³Šã€è½¬æ¢ä¸ºç°åº¦å›¾ã€å¯¹æ¯”åº¦é™åˆ¶è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ˆCLAHEï¼‰ã€éšæœºäº®åº¦å’Œå¯¹æ¯”åº¦å˜åŒ–ã€éšæœºä¼½é©¬è°ƒæ•´ï¼Œä»¥åŠé€šè¿‡å‹ç¼©é™ä½å›¾åƒè´¨é‡ç­‰æ“ä½œã€‚

    å±æ€§ï¼š
        p (float): åº”ç”¨å˜æ¢çš„æ¦‚ç‡ã€‚
        transform (albumentations.Compose): ç»„æˆçš„Albumentationså˜æ¢ã€‚
        contains_spatial (bool): æŒ‡ç¤ºå˜æ¢æ˜¯å¦åŒ…å«ç©ºé—´æ“ä½œã€‚

    æ–¹æ³•ï¼š
        __call__: å¯¹è¾“å…¥æ ‡ç­¾åº”ç”¨Albumentationså˜æ¢ã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = Albumentations(p=0.5)
        >>> augmented_labels = transform(labels)
    """

    def __init__(self, p=1.0):
        """
        åˆå§‹åŒ–Albumentationså˜æ¢å¯¹è±¡ï¼Œç”¨äºYOLOè¾¹ç•Œæ¡†æ ¼å¼çš„å‚æ•°ã€‚

        è¯¥ç±»ä½¿ç”¨Albumentationsåº“åº”ç”¨å„ç§å›¾åƒå¢å¼ºï¼ŒåŒ…æ‹¬æ¨¡ç³Šã€å‡å€¼æ¨¡ç³Šã€è½¬æ¢ä¸ºç°åº¦å›¾ã€å¯¹æ¯”åº¦é™åˆ¶è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ã€éšæœºäº®åº¦å’Œå¯¹æ¯”åº¦å˜åŒ–ã€éšæœºä¼½é©¬è°ƒæ•´ï¼Œä»¥åŠé€šè¿‡å‹ç¼©é™ä½å›¾åƒè´¨é‡ã€‚

        å‚æ•°ï¼š
            p (float): åº”ç”¨å¢å¼ºçš„æ¦‚ç‡ï¼Œå¿…é¡»åœ¨0åˆ°1ä¹‹é—´ã€‚

        å±æ€§ï¼š
            p (float): åº”ç”¨å¢å¼ºçš„æ¦‚ç‡ã€‚
            transform (albumentations.Compose): ç»„æˆçš„Albumentationså˜æ¢ã€‚
            contains_spatial (bool): æŒ‡ç¤ºå˜æ¢æ˜¯å¦åŒ…å«ç©ºé—´å˜æ¢ã€‚

        å¼‚å¸¸ï¼š
            ImportError: å¦‚æœæœªå®‰è£…AlbumentationsåŒ…ã€‚
            Exception: åˆå§‹åŒ–è¿‡ç¨‹ä¸­é‡åˆ°ä»»ä½•å…¶ä»–é”™è¯¯ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = Albumentations(p=0.5)
            >>> augmented = transform(image=image, bboxes=bboxes, class_labels=classes)
            >>> augmented_image = augmented["image"]
            >>> augmented_bboxes = augmented["bboxes"]

        å¤‡æ³¨ï¼š
            - éœ€è¦å®‰è£…Albumentationsç‰ˆæœ¬1.0.3æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚
            - ç©ºé—´å˜æ¢éœ€è¦ç‰¹åˆ«å¤„ç†ï¼Œä»¥ç¡®ä¿ä¸è¾¹ç•Œæ¡†çš„å…¼å®¹æ€§ã€‚
            - ä¸€äº›å˜æ¢é»˜è®¤ä»¥éå¸¸ä½çš„æ¦‚ç‡ï¼ˆ0.01ï¼‰åº”ç”¨ã€‚
        """
        self.p = p
        self.transform = None
        prefix = colorstr("albumentations: ")

        try:
            import albumentations as A

            check_version(A.__version__, "1.0.3", hard=True)  # ç‰ˆæœ¬è¦æ±‚

            # ç©ºé—´å˜æ¢çš„å¯èƒ½åˆ—è¡¨
            spatial_transforms = {
                "Affine",
                "BBoxSafeRandomCrop",
                "CenterCrop",
                "CoarseDropout",
                "Crop",
                "CropAndPad",
                "CropNonEmptyMaskIfExists",
                "D4",
                "ElasticTransform",
                "Flip",
                "GridDistortion",
                "GridDropout",
                "HorizontalFlip",
                "Lambda",
                "LongestMaxSize",
                "MaskDropout",
                "MixUp",
                "Morphological",
                "NoOp",
                "OpticalDistortion",
                "PadIfNeeded",
                "Perspective",
                "PiecewiseAffine",
                "PixelDropout",
                "RandomCrop",
                "RandomCropFromBorders",
                "RandomGridShuffle",
                "RandomResizedCrop",
                "RandomRotate90",
                "RandomScale",
                "RandomSizedBBoxSafeCrop",
                "RandomSizedCrop",
                "Resize",
                "Rotate",
                "SafeRotate",
                "ShiftScaleRotate",
                "SmallestMaxSize",
                "Transpose",
                "VerticalFlip",
                "XYMasking",
            }  # æ¥è‡ª https://albumentations.ai/docs/getting_started/transforms_and_targets/#spatial-level-transforms

            # å˜æ¢åˆ—è¡¨
            T = [
                A.Blur(p=0.01),
                A.MedianBlur(p=0.01),
                A.ToGray(p=0.01),
                A.CLAHE(p=0.01),
                A.RandomBrightnessContrast(p=0.0),
                A.RandomGamma(p=0.0),
                A.ImageCompression(quality_lower=75, p=0.0),
            ]

            # ç»„åˆå˜æ¢
            self.contains_spatial = any(transform.__class__.__name__ in spatial_transforms for transform in T)
            self.transform = (
                A.Compose(T, bbox_params=A.BboxParams(format="yolo", label_fields=["class_labels"]))
                if self.contains_spatial
                else A.Compose(T)
            )
            if hasattr(self.transform, "set_random_seed"):
                # éœ€è¦åœ¨albumentations>=1.4.21ç‰ˆæœ¬ä¸­è¿›è¡Œç¡®å®šæ€§å˜æ¢
                self.transform.set_random_seed(torch.initial_seed())
            LOGGER.info(prefix + ", ".join(f"{x}".replace("always_apply=False, ", "") for x in T if x.p))
        except ImportError:  # æœªå®‰è£…åŒ…ï¼Œè·³è¿‡
            pass
        except Exception as e:
            LOGGER.info(f"{prefix}{e}")

    def __call__(self, labels):
        """
        å¯¹è¾“å…¥æ ‡ç­¾åº”ç”¨Albumentationså˜æ¢ã€‚

        è¯¥æ–¹æ³•ä½¿ç”¨Albumentationsåº“åº”ç”¨ä¸€ç³»åˆ—å›¾åƒå¢å¼ºã€‚å®ƒå¯ä»¥å¯¹è¾“å…¥å›¾åƒåŠå…¶ç›¸åº”çš„æ ‡ç­¾æ‰§è¡Œç©ºé—´å’Œéç©ºé—´å˜æ¢ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ•°æ®å’Œæ³¨é‡Šçš„å­—å…¸ã€‚é¢„æœŸçš„é”®æœ‰ï¼š
                - 'img': è¡¨ç¤ºå›¾åƒçš„numpy.ndarray
                - 'cls': ç±»æ ‡ç­¾çš„numpy.ndarray
                - 'instances': åŒ…å«è¾¹ç•Œæ¡†å’Œå…¶ä»–å®ä¾‹ä¿¡æ¯çš„å¯¹è±¡

        è¿”å›ï¼š
            (Dict): åŒ…å«å¢å¼ºåçš„å›¾åƒå’Œæ›´æ–°åçš„æ³¨é‡Šçš„è¾“å…¥å­—å…¸ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = Albumentations(p=0.5)
            >>> labels = {
            ...     "img": np.random.rand(640, 640, 3),
            ...     "cls": np.array([0, 1]),
            ...     "instances": Instances(bboxes=np.array([[0, 0, 1, 1], [0.5, 0.5, 0.8, 0.8]])),
            ... }
            >>> augmented = transform(labels)
            >>> assert augmented["img"].shape == (640, 640, 3)

        å¤‡æ³¨ï¼š
            - æ­¤æ–¹æ³•ä»¥self.pçš„æ¦‚ç‡åº”ç”¨å˜æ¢ã€‚
            - ç©ºé—´å˜æ¢æ›´æ–°è¾¹ç•Œæ¡†ï¼Œè€Œéç©ºé—´å˜æ¢ä»…ä¿®æ”¹å›¾åƒã€‚
            - éœ€è¦å®‰è£…Albumentationsåº“ã€‚
        """
        if self.transform is None or random.random() > self.p:
            return labels

        if self.contains_spatial:
            cls = labels["cls"]
            if len(cls):
                im = labels["img"]
                labels["instances"].convert_bbox("xywh")
                labels["instances"].normalize(*im.shape[:2][::-1])
                bboxes = labels["instances"].bboxes
                # TODO: æ·»åŠ å¯¹åˆ†å‰²å’Œå…³é”®ç‚¹çš„æ”¯æŒ
                new = self.transform(image=im, bboxes=bboxes, class_labels=cls)  # å˜æ¢åçš„å›¾åƒ
                if len(new["class_labels"]) > 0:  # å¦‚æœæ–°å›¾åƒä¸­æ²¡æœ‰è¾¹ç•Œæ¡†ï¼Œåˆ™è·³è¿‡æ›´æ–°
                    labels["img"] = new["image"]
                    labels["cls"] = np.array(new["class_labels"])
                    bboxes = np.array(new["bboxes"], dtype=np.float32)
                labels["instances"].update(bboxes=bboxes)
        else:
            labels["img"] = self.transform(image=labels["img"])["image"]  # å˜æ¢åçš„å›¾åƒ

        return labels


class Format:
    """
    ç”¨äºç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ä»»åŠ¡çš„å›¾åƒæ³¨é‡Šæ ¼å¼åŒ–ç±»ã€‚

    è¯¥ç±»å°†å›¾åƒå’Œå®ä¾‹æ³¨é‡Šæ ‡å‡†åŒ–ï¼Œä»¥ä¾¿åœ¨PyTorch DataLoaderçš„`collate_fn`ä¸­ä½¿ç”¨ã€‚

    å±æ€§ï¼š
        bbox_format (str): è¾¹ç•Œæ¡†æ ¼å¼ã€‚å¯é€‰å€¼ä¸º'xywh'æˆ–'xyxy'ã€‚
        normalize (bool): æ˜¯å¦å¯¹è¾¹ç•Œæ¡†è¿›è¡Œå½’ä¸€åŒ–ã€‚
        return_mask (bool): æ˜¯å¦è¿”å›å®ä¾‹æ©ç ç”¨äºåˆ†å‰²ä»»åŠ¡ã€‚
        return_keypoint (bool): æ˜¯å¦è¿”å›å…³é”®ç‚¹ç”¨äºå§¿æ€ä¼°è®¡ä»»åŠ¡ã€‚
        return_obb (bool): æ˜¯å¦è¿”å›å®šå‘è¾¹ç•Œæ¡†ã€‚
        mask_ratio (int): æ©ç çš„ä¸‹é‡‡æ ·æ¯”ä¾‹ã€‚
        mask_overlap (bool): æ˜¯å¦å…è®¸æ©ç é‡å ã€‚
        batch_idx (bool): æ˜¯å¦ä¿ç•™æ‰¹æ¬¡ç´¢å¼•ã€‚
        bgr (float): æ˜¯å¦è¿”å›BGRå›¾åƒçš„æ¦‚ç‡ã€‚

    æ–¹æ³•ï¼š
        __call__: æ ¼å¼åŒ–åŒ…å«å›¾åƒã€ç±»åˆ«ã€è¾¹ç•Œæ¡†çš„æ ‡ç­¾å­—å…¸ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°è¿”å›æ©ç å’Œå…³é”®ç‚¹ã€‚
        _format_img: å°†å›¾åƒä»Numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ã€‚
        _format_segments: å°†å¤šè¾¹å½¢ç‚¹è½¬æ¢ä¸ºä½å›¾æ©ç ã€‚

    ç¤ºä¾‹ï¼š
        >>> formatter = Format(bbox_format="xywh", normalize=True, return_mask=True)
        >>> formatted_labels = formatter(labels)
        >>> img = formatted_labels["img"]
        >>> bboxes = formatted_labels["bboxes"]
        >>> masks = formatted_labels["masks"]
    """

    def __init__(
        self,
        bbox_format="xywh",
        normalize=True,
        return_mask=False,
        return_keypoint=False,
        return_obb=False,
        mask_ratio=4,
        mask_overlap=True,
        batch_idx=True,
        bgr=0.0,
    ):
        """
        ä½¿ç”¨ç»™å®šçš„å‚æ•°åˆå§‹åŒ–Formatç±»ï¼Œç”¨äºå›¾åƒå’Œå®ä¾‹æ³¨é‡Šçš„æ ¼å¼åŒ–ã€‚

        è¯¥ç±»å°†å›¾åƒå’Œå®ä¾‹æ³¨é‡Šæ ‡å‡†åŒ–ï¼Œä»¥ä¾¿ç”¨äºç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ä»»åŠ¡ï¼Œå‡†å¤‡å¥½ç”¨äºPyTorch DataLoaderçš„`collate_fn`ã€‚

        å‚æ•°ï¼š
            bbox_format (str): è¾¹ç•Œæ¡†æ ¼å¼ã€‚å¯é€‰å€¼ä¸º'xywh'ã€'xyxy'ç­‰ã€‚
            normalize (bool): æ˜¯å¦å°†è¾¹ç•Œæ¡†å½’ä¸€åŒ–åˆ°[0,1]ã€‚
            return_mask (bool): å¦‚æœä¸ºTrueï¼Œè¿”å›å®ä¾‹æ©ç ï¼Œç”¨äºåˆ†å‰²ä»»åŠ¡ã€‚
            return_keypoint (bool): å¦‚æœä¸ºTrueï¼Œè¿”å›å§¿æ€ä¼°è®¡ä»»åŠ¡ä¸­çš„å…³é”®ç‚¹ã€‚
            return_obb (bool): å¦‚æœä¸ºTrueï¼Œè¿”å›å®šå‘è¾¹ç•Œæ¡†ã€‚
            mask_ratio (int): æ©ç çš„ä¸‹é‡‡æ ·æ¯”ä¾‹ã€‚
            mask_overlap (bool): å¦‚æœä¸ºTrueï¼Œå…è®¸æ©ç é‡å ã€‚
            batch_idx (bool): å¦‚æœä¸ºTrueï¼Œä¿ç•™æ‰¹æ¬¡ç´¢å¼•ã€‚
            bgr (float): æ˜¯å¦è¿”å›BGRå›¾åƒçš„æ¦‚ç‡ã€‚

        å±æ€§ï¼š
            bbox_format (str): è¾¹ç•Œæ¡†æ ¼å¼ã€‚
            normalize (bool): æ˜¯å¦å½’ä¸€åŒ–è¾¹ç•Œæ¡†ã€‚
            return_mask (bool): æ˜¯å¦è¿”å›å®ä¾‹æ©ç ã€‚
            return_keypoint (bool): æ˜¯å¦è¿”å›å…³é”®ç‚¹ã€‚
            return_obb (bool): æ˜¯å¦è¿”å›å®šå‘è¾¹ç•Œæ¡†ã€‚
            mask_ratio (int): æ©ç çš„ä¸‹é‡‡æ ·æ¯”ä¾‹ã€‚
            mask_overlap (bool): æ˜¯å¦å…è®¸æ©ç é‡å ã€‚
            batch_idx (bool): æ˜¯å¦ä¿ç•™æ‰¹æ¬¡ç´¢å¼•ã€‚
            bgr (float): æ˜¯å¦è¿”å›BGRå›¾åƒçš„æ¦‚ç‡ã€‚

        ç¤ºä¾‹ï¼š
            >>> format = Format(bbox_format="xyxy", return_mask=True, return_keypoint=False)
            >>> print(format.bbox_format)
            xyxy
        """
        self.bbox_format = bbox_format
        self.normalize = normalize
        self.return_mask = return_mask  # åœ¨ä»…è®­ç»ƒæ£€æµ‹ä»»åŠ¡æ—¶è®¾ç½®ä¸ºFalse
        self.return_keypoint = return_keypoint
        self.return_obb = return_obb
        self.mask_ratio = mask_ratio
        self.mask_overlap = mask_overlap
        self.batch_idx = batch_idx  # ä¿ç•™æ‰¹æ¬¡ç´¢å¼•
        self.bgr = bgr

    def __call__(self, labels):
        """
        æ ¼å¼åŒ–ç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²å’Œå§¿æ€ä¼°è®¡ä»»åŠ¡çš„å›¾åƒæ³¨é‡Šã€‚

        è¯¥æ–¹æ³•æ ‡å‡†åŒ–è¾“å…¥æ ‡ç­¾å­—å…¸ä¸­çš„å›¾åƒå’Œå®ä¾‹æ³¨é‡Šï¼Œè½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼ï¼Œå¹¶åœ¨éœ€è¦æ—¶åº”ç”¨å½’ä¸€åŒ–ã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒå’Œæ³¨é‡Šæ•°æ®çš„å­—å…¸ï¼Œé¢„æœŸåŒ…å«ä»¥ä¸‹é”®ï¼š
                - 'img': è¾“å…¥å›¾åƒï¼ˆNumpyæ•°ç»„ï¼‰
                - 'cls': å®ä¾‹çš„ç±»åˆ«æ ‡ç­¾
                - 'instances': åŒ…å«è¾¹ç•Œæ¡†ã€åˆ†å‰²å’Œå…³é”®ç‚¹ç­‰ä¿¡æ¯çš„å®ä¾‹å¯¹è±¡

        è¿”å›ï¼š
            (Dict): åŒ…å«æ ¼å¼åŒ–æ•°æ®çš„å­—å…¸ï¼ŒåŒ…æ‹¬ï¼š
                - 'img': æ ¼å¼åŒ–åçš„å›¾åƒå¼ é‡ã€‚
                - 'cls': ç±»åˆ«æ ‡ç­¾å¼ é‡ã€‚
                - 'bboxes': ä»¥æŒ‡å®šæ ¼å¼å­˜å‚¨çš„è¾¹ç•Œæ¡†å¼ é‡ã€‚
                - 'masks': å®ä¾‹æ©ç å¼ é‡ï¼ˆå¦‚æœreturn_maskä¸ºTrueï¼‰ã€‚
                - 'keypoints': å…³é”®ç‚¹å¼ é‡ï¼ˆå¦‚æœreturn_keypointä¸ºTrueï¼‰ã€‚
                - 'batch_idx': æ‰¹æ¬¡ç´¢å¼•å¼ é‡ï¼ˆå¦‚æœbatch_idxä¸ºTrueï¼‰ã€‚

        ç¤ºä¾‹ï¼š
            >>> formatter = Format(bbox_format="xywh", normalize=True, return_mask=True)
            >>> labels = {"img": np.random.rand(640, 640, 3), "cls": np.array([0, 1]), "instances": Instances(...)}
            >>> formatted_labels = formatter(labels)
            >>> print(formatted_labels.keys())
        """
        img = labels.pop("img")
        h, w = img.shape[:2]
        cls = labels.pop("cls")
        instances = labels.pop("instances")
        instances.convert_bbox(format=self.bbox_format)
        instances.denormalize(w, h)
        nl = len(instances)

        if self.return_mask:
            if nl:
                masks, instances, cls = self._format_segments(instances, cls, w, h)
                masks = torch.from_numpy(masks)
            else:
                masks = torch.zeros(
                    1 if self.mask_overlap else nl, img.shape[0] // self.mask_ratio, img.shape[1] // self.mask_ratio
                )
            labels["masks"] = masks
        labels["img"] = self._format_img(img)
        labels["cls"] = torch.from_numpy(cls) if nl else torch.zeros(nl)
        labels["bboxes"] = torch.from_numpy(instances.bboxes) if nl else torch.zeros((nl, 4))
        if self.return_keypoint:
            labels["keypoints"] = torch.from_numpy(instances.keypoints)
            if self.normalize:
                labels["keypoints"][..., 0] /= w
                labels["keypoints"][..., 1] /= h
        if self.return_obb:
            labels["bboxes"] = (
                xyxyxyxy2xywhr(torch.from_numpy(instances.segments)) if len(instances.segments) else torch.zeros((0, 5))
            )
        # NOTE: éœ€è¦å¯¹obbè¿›è¡Œå½’ä¸€åŒ–ï¼Œç¡®ä¿å®½é«˜ä¸€è‡´
        if self.normalize:
            labels["bboxes"][:, [0, 2]] /= w
            labels["bboxes"][:, [1, 3]] /= h
        # ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨collate_fn
        if self.batch_idx:
            labels["batch_idx"] = torch.zeros(nl)
        return labels

    def _format_img(self, img):
        """
        å°†å›¾åƒæ ¼å¼åŒ–ä¸ºYOLOæ ¼å¼ï¼Œä»Numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ã€‚

        æ­¤å‡½æ•°æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
        1. ç¡®ä¿å›¾åƒå…·æœ‰3ä¸ªç»´åº¦ï¼ˆå¦‚æœéœ€è¦ï¼Œæ·»åŠ ä¸€ä¸ªé€šé“ç»´åº¦ï¼‰ã€‚
        2. å°†å›¾åƒä»HWCæ ¼å¼è½¬æ¢ä¸ºCHWæ ¼å¼ã€‚
        3. å¯é€‰æ‹©æ€§åœ°å°†é¢œè‰²é€šé“ä»RGBç¿»è½¬ä¸ºBGRã€‚
        4. å°†å›¾åƒè½¬æ¢ä¸ºè¿ç»­æ•°ç»„ã€‚
        5. å°†Numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ã€‚

        å‚æ•°ï¼š
            img (np.ndarray): è¾“å…¥å›¾åƒï¼Œå½¢çŠ¶ä¸º(H, W, C)æˆ–(H, W)ã€‚

        è¿”å›ï¼š
            (torch.Tensor): æ ¼å¼åŒ–åçš„å›¾åƒPyTorchå¼ é‡ï¼Œå½¢çŠ¶ä¸º(C, H, W)ã€‚

        ç¤ºä¾‹ï¼š
            >>> import numpy as np
            >>> img = np.random.rand(100, 100, 3)
            >>> formatted_img = self._format_img(img)
            >>> print(formatted_img.shape)
            torch.Size([3, 100, 100])
        """
        if len(img.shape) < 3:
            img = np.expand_dims(img, -1)
        img = img.transpose(2, 0, 1)
        img = np.ascontiguousarray(img[::-1] if random.uniform(0, 1) > self.bgr else img)
        img = torch.from_numpy(img)
        return img

    def _format_segments(self, instances, cls, w, h):
        """
        å°†å¤šè¾¹å½¢åˆ†å‰²è½¬æ¢ä¸ºä½å›¾æ©ç ã€‚

        å‚æ•°ï¼š
            instances (Instances): åŒ…å«åˆ†å‰²ä¿¡æ¯çš„å¯¹è±¡ã€‚
            cls (numpy.ndarray): æ¯ä¸ªå®ä¾‹çš„ç±»åˆ«æ ‡ç­¾ã€‚
            w (int): å›¾åƒçš„å®½åº¦ã€‚
            h (int): å›¾åƒçš„é«˜åº¦ã€‚

        è¿”å›ï¼š
            masks (numpy.ndarray): å½¢çŠ¶ä¸º(N, H, W)çš„ä½å›¾æ©ç ï¼ˆå¦‚æœmask_overlapä¸ºTrueï¼Œåˆ™ä¸º(1, H, W)ï¼‰ã€‚
            instances (Instances): æ›´æ–°åçš„å®ä¾‹å¯¹è±¡ï¼ˆå¦‚æœmask_overlapä¸ºTrueï¼Œåˆ™åŒ…å«æ’åºåçš„åˆ†å‰²ï¼‰ã€‚
            cls (numpy.ndarray): æ›´æ–°åçš„ç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚æœmask_overlapä¸ºTrueï¼Œåˆ™ä¸ºæ’åºåçš„æ ‡ç­¾ï¼‰ã€‚

        å¤‡æ³¨ï¼š
            - å¦‚æœself.mask_overlapä¸ºTrueï¼Œåˆ™æ©ç é‡å å¹¶æŒ‰é¢ç§¯æ’åºã€‚
            - å¦‚æœself.mask_overlapä¸ºFalseï¼Œåˆ™æ¯ä¸ªæ©ç å•ç‹¬è¡¨ç¤ºã€‚
            - æ©ç æ ¹æ®self.mask_ratioè¿›è¡Œä¸‹é‡‡æ ·ã€‚
        """
        segments = instances.segments
        if self.mask_overlap:
            masks, sorted_idx = polygons2masks_overlap((h, w), segments, downsample_ratio=self.mask_ratio)
            masks = masks[None]  # (640, 640) -> (1, 640, 640)
            instances = instances[sorted_idx]
            cls = cls[sorted_idx]
        else:
            masks = polygons2masks((h, w), segments, color=1, downsample_ratio=self.mask_ratio)

        return masks, instances, cls


class RandomLoadText:
    """
    éšæœºé‡‡æ ·æ­£è´Ÿæ–‡æœ¬ï¼Œå¹¶ç›¸åº”æ›´æ–°ç±»åˆ«ç´¢å¼•ã€‚

    è¯¥ç±»è´Ÿè´£ä»ç»™å®šçš„ç±»åˆ«æ–‡æœ¬é›†åˆä¸­éšæœºé‡‡æ ·æ–‡æœ¬ï¼ŒåŒ…æ‹¬æ­£æ ·æœ¬ï¼ˆå›¾åƒä¸­å­˜åœ¨çš„æ–‡æœ¬ï¼‰å’Œè´Ÿæ ·æœ¬ï¼ˆå›¾åƒä¸­ä¸å­˜åœ¨çš„æ–‡æœ¬ï¼‰ã€‚å®ƒä¼šæ›´æ–°ç±»åˆ«ç´¢å¼•ä»¥åæ˜ é‡‡æ ·çš„æ–‡æœ¬ï¼Œå¹¶ä¸”å¯ä»¥é€‰æ‹©æ€§åœ°å°†æ–‡æœ¬åˆ—è¡¨å¡«å……åˆ°å›ºå®šé•¿åº¦ã€‚

    å±æ€§ï¼š
        prompt_format (str): æ–‡æœ¬æç¤ºçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ã€‚
        neg_samples (Tuple[int, int]): éšæœºé‡‡æ ·è´Ÿæ–‡æœ¬çš„èŒƒå›´ã€‚
        max_samples (int): æ¯ä¸ªå›¾åƒä¸­ä¸åŒæ–‡æœ¬æ ·æœ¬çš„æœ€å¤§æ•°é‡ã€‚
        padding (bool): æ˜¯å¦å°†æ–‡æœ¬å¡«å……åˆ°max_samplesã€‚
        padding_value (str): å½“paddingä¸ºTrueæ—¶ç”¨äºå¡«å……çš„æ–‡æœ¬ã€‚

    æ–¹æ³•ï¼š
        __call__: å¤„ç†è¾“å…¥æ ‡ç­¾å¹¶è¿”å›æ›´æ–°åçš„ç±»åˆ«å’Œæ–‡æœ¬ã€‚

    ç¤ºä¾‹ï¼š
        >>> loader = RandomLoadText(prompt_format="Object: {}", neg_samples=(5, 10), max_samples=20)
        >>> labels = {"cls": [0, 1, 2], "texts": [["cat"], ["dog"], ["bird"]], "instances": [...]}
        >>> updated_labels = loader(labels)
        >>> print(updated_labels["texts"])
        ['Object: cat', 'Object: dog', 'Object: bird', 'Object: elephant', 'Object: car']
    """

    def __init__(
        self,
        prompt_format: str = "{}",
        neg_samples: Tuple[int, int] = (80, 80),
        max_samples: int = 80,
        padding: bool = False,
        padding_value: str = "",
    ) -> None:
        """
        åˆå§‹åŒ–RandomLoadTextç±»ï¼Œç”¨äºéšæœºé‡‡æ ·æ­£è´Ÿæ–‡æœ¬ã€‚

        è¯¥ç±»ç”¨äºéšæœºé‡‡æ ·æ­£æ–‡æœ¬å’Œè´Ÿæ–‡æœ¬ï¼Œå¹¶æ ¹æ®æ ·æœ¬æ•°é‡ç›¸åº”åœ°æ›´æ–°ç±»åˆ«ç´¢å¼•ã€‚å®ƒå¯ç”¨äºåŸºäºæ–‡æœ¬çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚

        å‚æ•°ï¼š
            prompt_format (str): æç¤ºçš„æ ¼å¼å­—ç¬¦ä¸²ã€‚é»˜è®¤æ˜¯'{}'ã€‚æ ¼å¼å­—ç¬¦ä¸²åº”è¯¥åŒ…å«ä¸€å¯¹å¤§æ‹¬å·{}ï¼Œå…¶ä¸­å°†æ’å…¥æ–‡æœ¬ã€‚
            neg_samples (Tuple[int, int]): éšæœºé‡‡æ ·è´Ÿæ–‡æœ¬çš„èŒƒå›´ã€‚ç¬¬ä¸€ä¸ªæ•´æ•°æŒ‡å®šè´Ÿæ ·æœ¬çš„æœ€å°æ•°é‡ï¼Œç¬¬äºŒä¸ªæ•´æ•°æŒ‡å®šæœ€å¤§æ•°é‡ã€‚é»˜è®¤æ˜¯(80, 80)ã€‚
            max_samples (int): æ¯ä¸ªå›¾åƒä¸­ä¸åŒæ–‡æœ¬æ ·æœ¬çš„æœ€å¤§æ•°é‡ã€‚é»˜è®¤æ˜¯80ã€‚
            padding (bool): æ˜¯å¦å°†æ–‡æœ¬å¡«å……åˆ°max_samplesã€‚å¦‚æœä¸ºTrueï¼Œæ–‡æœ¬æ•°é‡å°†å§‹ç»ˆç­‰äºmax_samplesã€‚é»˜è®¤æ˜¯Falseã€‚
            padding_value (str): å½“paddingä¸ºTrueæ—¶ç”¨äºå¡«å……çš„æ–‡æœ¬ã€‚é»˜è®¤æ˜¯ç©ºå­—ç¬¦ä¸²ã€‚

        å±æ€§ï¼š
            prompt_format (str): æç¤ºæ ¼å¼å­—ç¬¦ä¸²ã€‚
            neg_samples (Tuple[int, int]): éšæœºé‡‡æ ·è´Ÿæ–‡æœ¬çš„èŒƒå›´ã€‚
            max_samples (int): æœ€å¤§æ–‡æœ¬æ ·æœ¬æ•°é‡ã€‚
            padding (bool): æ˜¯å¦å¯ç”¨å¡«å……ã€‚
            padding_value (str): å¡«å……æ—¶ä½¿ç”¨çš„å€¼ã€‚

        ç¤ºä¾‹ï¼š
            >>> random_load_text = RandomLoadText(prompt_format="Object: {}", neg_samples=(50, 100), max_samples=120)
            >>> random_load_text.prompt_format
            'Object: {}'
            >>> random_load_text.neg_samples
            (50, 100)
            >>> random_load_text.max_samples
            120
        """
        self.prompt_format = prompt_format
        self.neg_samples = neg_samples
        self.max_samples = max_samples
        self.padding = padding
        self.padding_value = padding_value

    def __call__(self, labels: dict) -> dict:
        """
        éšæœºé‡‡æ ·æ­£è´Ÿæ–‡æœ¬å¹¶ç›¸åº”æ›´æ–°ç±»åˆ«ç´¢å¼•ã€‚

        è¯¥æ–¹æ³•åŸºäºå›¾åƒä¸­ç°æœ‰çš„ç±»åˆ«æ ‡ç­¾é‡‡æ ·æ­£æ–‡æœ¬ï¼Œå¹¶ä»å‰©ä½™ç±»åˆ«ä¸­éšæœºé€‰æ‹©è´Ÿæ–‡æœ¬ã€‚ç„¶åï¼Œå®ƒæ›´æ–°ç±»åˆ«ç´¢å¼•ä»¥åŒ¹é…æ–°çš„é‡‡æ ·æ–‡æœ¬é¡ºåºã€‚

        å‚æ•°ï¼š
            labels (Dict): åŒ…å«å›¾åƒæ ‡ç­¾å’Œå…ƒæ•°æ®çš„å­—å…¸ã€‚å¿…é¡»åŒ…å«'texts'å’Œ'cls'é”®ã€‚

        è¿”å›ï¼š
            (Dict): æ›´æ–°åçš„æ ‡ç­¾å­—å…¸ï¼ŒåŒ…å«æ–°çš„'cls'å’Œ'texts'æ¡ç›®ã€‚

        ç¤ºä¾‹ï¼š
            >>> loader = RandomLoadText(prompt_format="A photo of {}", neg_samples=(5, 10), max_samples=20)
            >>> labels = {"cls": np.array([[0], [1], [2]]), "texts": [["dog"], ["cat"], ["bird"]]}
            >>> updated_labels = loader(labels)
        """
        assert "texts" in labels, "æ ‡ç­¾ä¸­æœªæ‰¾åˆ°æ–‡æœ¬."
        class_texts = labels["texts"]
        num_classes = len(class_texts)
        cls = np.asarray(labels.pop("cls"), dtype=int)
        pos_labels = np.unique(cls).tolist()

        if len(pos_labels) > self.max_samples:
            pos_labels = random.sample(pos_labels, k=self.max_samples)

        neg_samples = min(min(num_classes, self.max_samples) - len(pos_labels), random.randint(*self.neg_samples))
        neg_labels = [i for i in range(num_classes) if i not in pos_labels]
        neg_labels = random.sample(neg_labels, k=neg_samples)

        sampled_labels = pos_labels + neg_labels
        random.shuffle(sampled_labels)

        label2ids = {label: i for i, label in enumerate(sampled_labels)}
        valid_idx = np.zeros(len(labels["instances"]), dtype=bool)
        new_cls = []
        for i, label in enumerate(cls.squeeze(-1).tolist()):
            if label not in label2ids:
                continue
            valid_idx[i] = True
            new_cls.append([label2ids[label]])
        labels["instances"] = labels["instances"][valid_idx]
        labels["cls"] = np.array(new_cls)

        # éšæœºé€‰æ‹©ä¸€ä¸ªæç¤ºï¼ˆå¦‚æœæœ‰å¤šä¸ªæç¤ºï¼‰
        texts = []
        for label in sampled_labels:
            prompts = class_texts[label]
            assert len(prompts) > 0
            prompt = self.prompt_format.format(prompts[random.randrange(len(prompts))])
            texts.append(prompt)

        if self.padding:
            valid_labels = len(pos_labels) + len(neg_labels)
            num_padding = self.max_samples - valid_labels
            if num_padding > 0:
                texts += [self.padding_value] * num_padding

        labels["texts"] = texts
        return labels


def v8_transforms(dataset, imgsz, hyp, stretch=False):
    """
    åº”ç”¨ä¸€ç³»åˆ—å›¾åƒè½¬æ¢ç”¨äºè®­ç»ƒã€‚

    è¿™ä¸ªå‡½æ•°åˆ›å»ºäº†ä¸€ç³»åˆ—å›¾åƒå¢å¼ºæŠ€æœ¯çš„ç»„åˆï¼Œä»¥å‡†å¤‡å›¾åƒç”¨äºYOLOè®­ç»ƒã€‚åŒ…æ‹¬çš„æ“ä½œæœ‰é©¬èµ›å…‹ã€å¤åˆ¶ç²˜è´´ã€éšæœºé€è§†ã€MixUpä»¥åŠå„ç§é¢œè‰²è°ƒæ•´ã€‚

    å‚æ•°ï¼š
        dataset (Dataset): åŒ…å«å›¾åƒæ•°æ®å’Œæ³¨é‡Šçš„æ•°æ®é›†å¯¹è±¡ã€‚
        imgsz (int): ç›®æ ‡å›¾åƒå¤§å°ï¼Œç”¨äºè°ƒæ•´å¤§å°ã€‚
        hyp (Namespace): æ§åˆ¶å„ç§è½¬æ¢æ–¹é¢çš„è¶…å‚æ•°å­—å…¸ã€‚
        stretch (bool): å¦‚æœä¸ºTrueï¼Œåˆ™åº”ç”¨å›¾åƒæ‹‰ä¼¸ã€‚å¦‚æœä¸ºFalseï¼Œåˆ™ä½¿ç”¨LetterBoxè°ƒæ•´å¤§å°ã€‚

    è¿”å›ï¼š
        (Compose): ä¸€ç»„å›¾åƒè½¬æ¢ï¼Œå°†åº”ç”¨äºæ•°æ®é›†ã€‚

    ç¤ºä¾‹ï¼š
        >>> from ultralytics.data.dataset import YOLODataset
        >>> from ultralytics.utils import IterableSimpleNamespace
        >>> dataset = YOLODataset(img_path="path/to/images", imgsz=640)
        >>> hyp = IterableSimpleNamespace(mosaic=1.0, copy_paste=0.5, degrees=10.0, translate=0.2, scale=0.9)
        >>> transforms = v8_transforms(dataset, imgsz=640, hyp=hyp)
        >>> augmented_data = transforms(dataset[0])
    """
    mosaic = Mosaic(dataset, imgsz=imgsz, p=hyp.mosaic)
    affine = RandomPerspective(
        degrees=hyp.degrees,
        translate=hyp.translate,
        scale=hyp.scale,
        shear=hyp.shear,
        perspective=hyp.perspective,
        pre_transform=None if stretch else LetterBox(new_shape=(imgsz, imgsz)),
    )

    pre_transform = Compose([mosaic, affine])
    if hyp.copy_paste_mode == "flip":
        pre_transform.insert(1, CopyPaste(p=hyp.copy_paste, mode=hyp.copy_paste_mode))
    else:
        pre_transform.append(
            CopyPaste(
                dataset,
                pre_transform=Compose([Mosaic(dataset, imgsz=imgsz, p=hyp.mosaic), affine]),
                p=hyp.copy_paste,
                mode=hyp.copy_paste_mode,
            )
        )
    flip_idx = dataset.data.get("flip_idx", [])  # ç”¨äºå…³é”®ç‚¹å¢å¼º
    if dataset.use_keypoints:
        kpt_shape = dataset.data.get("kpt_shape", None)
        if len(flip_idx) == 0 and hyp.fliplr > 0.0:
            hyp.fliplr = 0.0
            LOGGER.warning("WARNING âš ï¸ æ•°æ®æ–‡ä»¶ä¸­æœªå®šä¹‰ 'flip_idx' æ•°ç»„ï¼Œå·²å°†å¢å¼º 'fliplr=0.0' è®¾ç½®")
        elif flip_idx and (len(flip_idx) != kpt_shape[0]):
            raise ValueError(f"data.yamlä¸­çš„flip_idx={flip_idx}é•¿åº¦å¿…é¡»ä¸kpt_shape[0]={kpt_shape[0]}ç›¸ç­‰")

    return Compose(
        [
            pre_transform,
            MixUp(dataset, pre_transform=pre_transform, p=hyp.mixup),
            Albumentations(p=1.0),
            RandomHSV(hgain=hyp.hsv_h, sgain=hyp.hsv_s, vgain=hyp.hsv_v),
            RandomFlip(direction="vertical", p=hyp.flipud),
            RandomFlip(direction="horizontal", p=hyp.fliplr, flip_idx=flip_idx),
        ]
    )  # è½¬æ¢åºåˆ—


# åˆ†ç±»å¢å¼º -----------------------------------------------------------------------------------------
def classify_transforms(
    size=224,
    mean=DEFAULT_MEAN,
    std=DEFAULT_STD,
    interpolation="BILINEAR",
    crop_fraction: float = DEFAULT_CROP_FRACTION,
):
    """
    åˆ›å»ºä¸€ä¸ªç”¨äºåˆ†ç±»ä»»åŠ¡çš„å›¾åƒè½¬æ¢ç»„åˆã€‚

    è¿™ä¸ªå‡½æ•°ç”Ÿæˆä¸€ä¸ªé€‚ç”¨äºåˆ†ç±»æ¨¡å‹çš„å›¾åƒé¢„å¤„ç†å˜æ¢åºåˆ—ï¼Œç”¨äºè¯„ä¼°æˆ–æ¨ç†è¿‡ç¨‹ä¸­ã€‚åŒ…æ‹¬è°ƒæ•´å¤§å°ã€ä¸­å¿ƒè£å‰ªã€è½¬æ¢ä¸ºå¼ é‡ä»¥åŠå½’ä¸€åŒ–ã€‚

    å‚æ•°ï¼š
        size (int | tuple): è½¬æ¢åçš„ç›®æ ‡å›¾åƒå¤§å°ã€‚å¦‚æœæ˜¯æ•´æ•°ï¼Œåˆ™è¡¨ç¤ºæœ€çŸ­è¾¹çš„å¤§å°ã€‚å¦‚æœæ˜¯å…ƒç»„ï¼Œåˆ™è¡¨ç¤º(height, width)ã€‚
        mean (tuple): ç”¨äºå½’ä¸€åŒ–çš„æ¯ä¸ªRGBé€šé“çš„å‡å€¼ã€‚
        std (tuple): ç”¨äºå½’ä¸€åŒ–çš„æ¯ä¸ªRGBé€šé“çš„æ ‡å‡†å·®ã€‚
        interpolation (str): æ’å€¼æ–¹æ³•ï¼Œé€‰é¡¹æœ‰ 'NEAREST', 'BILINEAR' æˆ– 'BICUBIC'ã€‚
        crop_fraction (float): è¦è£å‰ªçš„å›¾åƒéƒ¨åˆ†çš„æ¯”ä¾‹ã€‚

    è¿”å›ï¼š
        (torchvision.transforms.Compose): ä¸€ä¸ªtorchvisionçš„å›¾åƒè½¬æ¢ç»„åˆã€‚

    ç¤ºä¾‹ï¼š
        >>> transforms = classify_transforms(size=224)
        >>> img = Image.open("path/to/image.jpg")
        >>> transformed_img = transforms(img)
    """
    import torchvision.transforms as T  # åœ¨æ›´å¿«çš„ 'import ultralytics' èŒƒå›´å†…

    if isinstance(size, (tuple, list)):
        assert len(size) == 2, f"'size'å…ƒç»„å¿…é¡»æ˜¯é•¿åº¦ä¸º2ï¼Œè€Œä¸æ˜¯é•¿åº¦ä¸º{len(size)}"
        scale_size = tuple(math.floor(x / crop_fraction) for x in size)
    else:
        scale_size = math.floor(size / crop_fraction)
        scale_size = (scale_size, scale_size)

    # ä¿æŒçºµæ¨ªæ¯”ï¼Œè£å‰ªå›¾åƒçš„ä¸­å¿ƒï¼Œä¸æ·»åŠ è¾¹æ¡†ï¼Œå›¾åƒä¼šä¸¢å¤±
    if scale_size[0] == scale_size[1]:
        # ç®€å•æƒ…å†µï¼Œä½¿ç”¨torchvisionå†…å»ºçš„Resizeï¼Œé‡‡ç”¨æœ€çŸ­è¾¹æ¨¡å¼ï¼ˆæ ‡é‡å¤§å°å‚æ•°ï¼‰
        tfl = [T.Resize(scale_size[0], interpolation=getattr(T.InterpolationMode, interpolation))]
    else:
        # å°†æœ€çŸ­è¾¹è°ƒæ•´åˆ°åŒ¹é…ç›®æ ‡å°ºå¯¸çš„éæ–¹å½¢ç›®æ ‡
        tfl = [T.Resize(scale_size)]
    tfl.extend(
        [
            T.CenterCrop(size),
            T.ToTensor(),
            T.Normalize(mean=torch.tensor(mean), std=torch.tensor(std)),
        ]
    )
    return T.Compose(tfl)


# åˆ†ç±»è®­ç»ƒå¢å¼º --------------------------------------------------------------------------------
def classify_augmentations(
    size=224,
    mean=DEFAULT_MEAN,
    std=DEFAULT_STD,
    scale=None,
    ratio=None,
    hflip=0.5,
    vflip=0.0,
    auto_augment=None,
    hsv_h=0.015,  # å›¾åƒ HSV-è‰²è°ƒå¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
    hsv_s=0.4,  # å›¾åƒ HSV-é¥±å’Œåº¦å¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
    hsv_v=0.4,  # å›¾åƒ HSV-æ˜åº¦å¢å¼ºï¼ˆæ¯”ä¾‹ï¼‰
    force_color_jitter=False,
    erasing=0.0,
    interpolation="BILINEAR",
):
    """
    åˆ›å»ºä¸€ä¸ªç”¨äºåˆ†ç±»ä»»åŠ¡çš„å›¾åƒå¢å¼ºè½¬æ¢ç»„åˆã€‚

    è¿™ä¸ªå‡½æ•°ç”Ÿæˆä¸€ç»„é€‚ç”¨äºè®­ç»ƒåˆ†ç±»æ¨¡å‹çš„å›¾åƒå¢å¼ºå˜æ¢ã€‚åŒ…æ‹¬è°ƒæ•´å¤§å°ã€ç¿»è½¬ã€é¢œè‰²æŠ–åŠ¨ã€è‡ªåŠ¨å¢å¼ºå’Œéšæœºæ“¦é™¤ç­‰é€‰é¡¹ã€‚

    å‚æ•°ï¼š
        size (int): è½¬æ¢åå›¾åƒçš„ç›®æ ‡å¤§å°ã€‚
        mean (tuple): æ¯ä¸ªé€šé“çš„å‡å€¼ï¼Œç”¨äºå½’ä¸€åŒ–ã€‚
        std (tuple): æ¯ä¸ªé€šé“çš„æ ‡å‡†å·®ï¼Œç”¨äºå½’ä¸€åŒ–ã€‚
        scale (tuple | None): åŸå§‹å¤§å°è£å‰ªçš„èŒƒå›´ã€‚
        ratio (tuple | None): åŸå§‹å®½é«˜æ¯”è£å‰ªçš„èŒƒå›´ã€‚
        hflip (float): æ°´å¹³ç¿»è½¬çš„æ¦‚ç‡ã€‚
        vflip (float): å‚ç›´ç¿»è½¬çš„æ¦‚ç‡ã€‚
        auto_augment (str | None): è‡ªåŠ¨å¢å¼ºç­–ç•¥ã€‚å¯ä»¥æ˜¯ 'randaugment'ã€'augmix'ã€'autoaugment' æˆ– Noneã€‚
        hsv_h (float): å›¾åƒ HSV-è‰²è°ƒå¢å¼ºå› å­ã€‚
        hsv_s (float): å›¾åƒ HSV-é¥±å’Œåº¦å¢å¼ºå› å­ã€‚
        hsv_v (float): å›¾åƒ HSV-æ˜åº¦å¢å¼ºå› å­ã€‚
        force_color_jitter (bool): æ˜¯å¦å³ä½¿å¯ç”¨äº†è‡ªåŠ¨å¢å¼ºä¹Ÿå¼ºåˆ¶åº”ç”¨é¢œè‰²æŠ–åŠ¨ã€‚
        erasing (float): éšæœºæ“¦é™¤çš„æ¦‚ç‡ã€‚
        interpolation (str): æ’å€¼æ–¹æ³•ï¼Œå¯ä»¥æ˜¯ 'NEAREST'ã€'BILINEAR' æˆ– 'BICUBIC'ã€‚

    è¿”å›ï¼š
        (torchvision.transforms.Compose): ä¸€ä¸ªå›¾åƒå¢å¼ºè½¬æ¢çš„ç»„åˆã€‚

    ç¤ºä¾‹ï¼š
        >>> transforms = classify_augmentations(size=224, auto_augment="randaugment")
        >>> augmented_image = transforms(original_image)
    """
    # å¦‚æœæ²¡æœ‰å®‰è£…Albumentationsï¼Œåº”ç”¨çš„å˜æ¢
    import torchvision.transforms as T  # åŠ é€Ÿ 'import ultralytics'

    if not isinstance(size, int):
        raise TypeError(f"classify_transforms() size {size} å¿…é¡»æ˜¯æ•´æ•°ï¼Œè€Œä¸æ˜¯ï¼ˆåˆ—è¡¨ã€å…ƒç»„ï¼‰")
    scale = tuple(scale or (0.08, 1.0))  # é»˜è®¤çš„imagenetç¼©æ”¾èŒƒå›´
    ratio = tuple(ratio or (3.0 / 4.0, 4.0 / 3.0))  # é»˜è®¤çš„imagenetå®½é«˜æ¯”èŒƒå›´
    interpolation = getattr(T.InterpolationMode, interpolation)
    primary_tfl = [T.RandomResizedCrop(size, scale=scale, ratio=ratio, interpolation=interpolation)]
    if hflip > 0.0:
        primary_tfl.append(T.RandomHorizontalFlip(p=hflip))
    if vflip > 0.0:
        primary_tfl.append(T.RandomVerticalFlip(p=vflip))

    secondary_tfl = []
    disable_color_jitter = False
    if auto_augment:
        assert isinstance(auto_augment, str), f"æä¾›çš„å‚æ•°åº”ä¸ºå­—ç¬¦ä¸²ï¼Œä½†å¾—åˆ°çš„ç±»å‹æ˜¯ {type(auto_augment)}"
        # é€šå¸¸å¦‚æœå¯ç”¨äº†AA/RAï¼Œåˆ™ç¦ç”¨é¢œè‰²æŠ–åŠ¨ï¼Œ
        # è¿™å…è®¸åœ¨ä¸ç ´åæ—§é…ç½®çš„æƒ…å†µä¸‹è¿›è¡Œè¦†ç›–
        disable_color_jitter = not force_color_jitter

        if auto_augment == "randaugment":
            if TORCHVISION_0_11:
                secondary_tfl.append(T.RandAugment(interpolation=interpolation))
            else:
                LOGGER.warning('"auto_augment=randaugment" éœ€è¦ torchvision >= 0.11.0ã€‚ç¦ç”¨å®ƒã€‚')

        elif auto_augment == "augmix":
            if TORCHVISION_0_13:
                secondary_tfl.append(T.AugMix(interpolation=interpolation))
            else:
                LOGGER.warning('"auto_augment=augmix" éœ€è¦ torchvision >= 0.13.0ã€‚ç¦ç”¨å®ƒã€‚')

        elif auto_augment == "autoaugment":
            if TORCHVISION_0_10:
                secondary_tfl.append(T.AutoAugment(interpolation=interpolation))
            else:
                LOGGER.warning('"auto_augment=autoaugment" éœ€è¦ torchvision >= 0.10.0ã€‚ç¦ç”¨å®ƒã€‚')

        else:
            raise ValueError(
                f'æ— æ•ˆçš„ auto_augment ç­–ç•¥: {auto_augment}ã€‚åº”ä¸º "randaugment"ã€'
                f'"augmix"ã€"autoaugment" æˆ– None'
            )

    if not disable_color_jitter:
        secondary_tfl.append(T.ColorJitter(brightness=hsv_v, contrast=hsv_v, saturation=hsv_s, hue=hsv_h))

    final_tfl = [
        T.ToTensor(),
        T.Normalize(mean=torch.tensor(mean), std=torch.tensor(std)),
        T.RandomErasing(p=erasing, inplace=True),
    ]

    return T.Compose(primary_tfl + secondary_tfl + final_tfl)


# ä¿æŒå‘åå…¼å®¹çš„ç±» ---------------------------------------------------------------------------------
class ClassifyLetterBox:
    """
    ç”¨äºåˆ†ç±»ä»»åŠ¡çš„å›¾åƒè°ƒæ•´å¤§å°å’Œå¡«å……çš„ç±»ã€‚

    è¿™ä¸ªç±»è®¾è®¡ä¸ºå›¾åƒè½¬æ¢ç®¡é“çš„ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼šT.Compose([LetterBox(size), ToTensor()])ã€‚
    å®ƒè°ƒæ•´å’Œå¡«å……å›¾åƒåˆ°æŒ‡å®šçš„å¤§å°ï¼ŒåŒæ—¶ä¿æŒåŸå§‹çš„çºµæ¨ªæ¯”ã€‚

    å±æ€§ï¼š
        h (int): å›¾åƒç›®æ ‡é«˜åº¦ã€‚
        w (int): å›¾åƒç›®æ ‡å®½åº¦ã€‚
        auto (bool): å¦‚æœä¸ºTrueï¼Œåˆ™è‡ªåŠ¨è®¡ç®—çŸ­è¾¹ä½¿ç”¨æ­¥å¹…ã€‚
        stride (int): æ­¥å¹…å€¼ï¼Œç”¨äº 'auto' ä¸ºTrueæ—¶ã€‚

    æ–¹æ³•ï¼š
        __call__: å°†LetterBoxè½¬æ¢åº”ç”¨äºè¾“å…¥å›¾åƒã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = ClassifyLetterBox(size=(640, 640), auto=False, stride=32)
        >>> img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        >>> result = transform(img)
        >>> print(result.shape)
        (640, 640, 3)
    """

    def __init__(self, size=(640, 640), auto=False, stride=32):
        """
        åˆå§‹åŒ–ç”¨äºå›¾åƒé¢„å¤„ç†çš„ClassifyLetterBoxå¯¹è±¡ã€‚

        è¿™ä¸ªç±»æ—¨åœ¨ä½œä¸ºå›¾åƒåˆ†ç±»ä»»åŠ¡çš„è½¬æ¢ç®¡é“çš„ä¸€éƒ¨åˆ†ã€‚å®ƒè°ƒæ•´å’Œå¡«å……å›¾åƒåˆ°æŒ‡å®šçš„å¤§å°ï¼ŒåŒæ—¶ä¿æŒåŸå§‹çš„çºµæ¨ªæ¯”ã€‚

        å‚æ•°ï¼š
            size (int | Tuple[int, int]): LetterBoxå›¾åƒçš„ç›®æ ‡å¤§å°ã€‚å¦‚æœæ˜¯æ•´æ•°ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªæ–¹å½¢å›¾åƒï¼ˆsize, sizeï¼‰ã€‚å¦‚æœæ˜¯å…ƒç»„ï¼Œåˆ™åº”ä¸ºï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰ã€‚
            auto (bool): å¦‚æœä¸ºTrueï¼Œåˆ™è‡ªåŠ¨æ ¹æ®æ­¥å¹…è®¡ç®—çŸ­è¾¹ã€‚é»˜è®¤ä¸ºFalseã€‚
            stride (int): ç”¨äºè‡ªåŠ¨è®¡ç®—çŸ­è¾¹çš„æ­¥å¹…å€¼ã€‚é»˜è®¤ä¸º32ã€‚

        å±æ€§ï¼š
            h (int): LetterBoxå›¾åƒçš„ç›®æ ‡é«˜åº¦ã€‚
            w (int): LetterBoxå›¾åƒçš„ç›®æ ‡å®½åº¦ã€‚
            auto (bool): æ ‡å¿—ï¼ŒæŒ‡ç¤ºæ˜¯å¦è‡ªåŠ¨è®¡ç®—çŸ­è¾¹ã€‚
            stride (int): ç”¨äºè‡ªåŠ¨è®¡ç®—çŸ­è¾¹çš„æ­¥å¹…å€¼ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = ClassifyLetterBox(size=224)
            >>> img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            >>> result = transform(img)
            >>> print(result.shape)
            (224, 224, 3)
        """
        super().__init__()
        self.h, self.w = (size, size) if isinstance(size, int) else size
        self.auto = auto  # ä¼ é€’æœ€å¤§å°ºå¯¸æ•´æ•°ï¼Œä½¿ç”¨æ­¥å¹…è‡ªåŠ¨è®¡ç®—çŸ­è¾¹
        self.stride = stride  # ä½¿ç”¨autoæ—¶

    def __call__(self, im):
        """
        ä½¿ç”¨LetterBoxæ–¹æ³•è°ƒæ•´å›¾åƒå¤§å°å’Œå¡«å……ã€‚

        è¿™ä¸ªæ–¹æ³•å°†è¾“å…¥å›¾åƒè°ƒæ•´ä¸ºé€‚åº”æŒ‡å®šå°ºå¯¸ï¼ŒåŒæ—¶ä¿æŒå…¶çºµæ¨ªæ¯”ï¼Œç„¶åå¡«å……è°ƒæ•´åçš„å›¾åƒä»¥åŒ¹é…ç›®æ ‡å°ºå¯¸ã€‚

        å‚æ•°ï¼š
            im (numpy.ndarray): è¾“å…¥å›¾åƒï¼Œå½¢çŠ¶ä¸ºï¼ˆH, W, Cï¼‰çš„numpyæ•°ç»„ã€‚

        è¿”å›ï¼š
            (numpy.ndarray): è°ƒæ•´å¤§å°å¹¶å¡«å……åçš„å›¾åƒï¼Œå½¢çŠ¶ä¸ºï¼ˆhs, ws, 3ï¼‰ï¼Œå…¶ä¸­hså’Œwsæ˜¯ç›®æ ‡é«˜åº¦å’Œå®½åº¦ã€‚

        ç¤ºä¾‹ï¼š
            >>> letterbox = ClassifyLetterBox(size=(640, 640))
            >>> image = np.random.randint(0, 255, (720, 1280, 3), dtype=np.uint8)
            >>> resized_image = letterbox(image)
            >>> print(resized_image.shape)
            (640, 640, 3)
        """
        imh, imw = im.shape[:2]
        r = min(self.h / imh, self.w / imw)  # æ–°æ—§å°ºå¯¸çš„æ¯”ä¾‹
        h, w = round(imh * r), round(imw * r)  # è°ƒæ•´åçš„å›¾åƒå°ºå¯¸

        # è®¡ç®—å¡«å……å°ºå¯¸
        hs, ws = (math.ceil(x / self.stride) * self.stride for x in (h, w)) if self.auto else (self.h, self.w)
        top, left = round((hs - h) / 2 - 0.1), round((ws - w) / 2 - 0.1)

        # åˆ›å»ºå¡«å……åçš„å›¾åƒ
        im_out = np.full((hs, ws, 3), 114, dtype=im.dtype)
        im_out[top : top + h, left : left + w] = cv2.resize(im, (w, h), interpolation=cv2.INTER_LINEAR)
        return im_out


class CenterCrop:
    """
    å¯¹å›¾åƒåº”ç”¨ä¸­å¿ƒè£å‰ªï¼Œç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚

    è¿™ä¸ªç±»å¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªï¼Œå°†å®ƒä»¬è°ƒæ•´ä¸ºæŒ‡å®šçš„å¤§å°ï¼ŒåŒæ—¶ä¿æŒåŸå§‹å›¾åƒçš„çºµæ¨ªæ¯”ã€‚
    å®ƒæ—¨åœ¨ä½œä¸ºå›¾åƒè½¬æ¢ç®¡é“çš„ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼šT.Compose([CenterCrop(size), ToTensor()]).

    å±æ€§ï¼š
        h (int): è£å‰ªåå›¾åƒçš„ç›®æ ‡é«˜åº¦ã€‚
        w (int): è£å‰ªåå›¾åƒçš„ç›®æ ‡å®½åº¦ã€‚

    æ–¹æ³•ï¼š
        __call__: å¯¹è¾“å…¥å›¾åƒåº”ç”¨ä¸­å¿ƒè£å‰ªè½¬æ¢ã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = CenterCrop(640)
        >>> image = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)
        >>> cropped_image = transform(image)
        >>> print(cropped_image.shape)
        (640, 640, 3)
    """

    def __init__(self, size=640):
        """
        åˆå§‹åŒ–CenterCropå¯¹è±¡ï¼Œç”¨äºå›¾åƒé¢„å¤„ç†ã€‚

        è¿™ä¸ªç±»è®¾è®¡ä¸ºå›¾åƒè½¬æ¢ç®¡é“çš„ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼šT.Compose([CenterCrop(size), ToTensor()]).
        å®ƒå¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸­å¿ƒè£å‰ªï¼Œè£å‰ªåˆ°æŒ‡å®šçš„å¤§å°ã€‚

        å‚æ•°ï¼š
            size (int | Tuple[int, int]): è£å‰ªåå›¾åƒçš„ç›®æ ‡å¤§å°ã€‚å¦‚æœsizeæ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œåˆ™è£å‰ªä¸ºæ–¹å½¢å›¾åƒï¼ˆsize, sizeï¼‰ã€‚å¦‚æœsizeæ˜¯ä¸€ä¸ªå…ƒç»„ï¼ˆh, wï¼‰ï¼Œåˆ™ç”¨ä½œè¾“å‡ºå¤§å°ã€‚

        è¿”å›ï¼š
            (None): è¿™ä¸ªæ–¹æ³•åˆå§‹åŒ–å¯¹è±¡ï¼Œå¹¶ä¸è¿”å›ä»»ä½•ä¸œè¥¿ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = CenterCrop(224)
            >>> img = np.random.rand(300, 300, 3)
            >>> cropped_img = transform(img)
            >>> print(cropped_img.shape)
            (224, 224, 3)
        """
        super().__init__()
        self.h, self.w = (size, size) if isinstance(size, int) else size

    def __call__(self, im):
        """
        å¯¹è¾“å…¥å›¾åƒåº”ç”¨ä¸­å¿ƒè£å‰ªã€‚

        è¿™ä¸ªæ–¹æ³•ä½¿ç”¨letterboxæ–¹æ³•è°ƒæ•´å›¾åƒå¤§å°ï¼Œå¹¶è£å‰ªå›¾åƒçš„ä¸­å¿ƒéƒ¨åˆ†ã€‚å®ƒä¿æŒåŸå§‹å›¾åƒçš„çºµæ¨ªæ¯”ï¼ŒåŒæ—¶å°†å›¾åƒé€‚åº”åˆ°æŒ‡å®šçš„å°ºå¯¸ã€‚

        å‚æ•°ï¼š
            im (numpy.ndarray | PIL.Image.Image): è¾“å…¥å›¾åƒï¼Œå½¢çŠ¶ä¸ºï¼ˆH, W, Cï¼‰çš„numpyæ•°ç»„ï¼Œæˆ–ä¸€ä¸ªPILå›¾åƒå¯¹è±¡ã€‚

        è¿”å›ï¼š
            (numpy.ndarray): è£å‰ªå¹¶è°ƒæ•´å¤§å°åçš„å›¾åƒï¼Œå½¢çŠ¶ä¸º(self.h, self.w, C)çš„numpyæ•°ç»„ã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = CenterCrop(size=224)
            >>> image = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
            >>> cropped_image = transform(image)
            >>> assert cropped_image.shape == (224, 224, 3)
        """
        if isinstance(im, Image.Image):  # å¦‚æœæ˜¯PILå›¾åƒï¼Œåˆ™è½¬æ¢ä¸ºnumpyæ•°ç»„
            im = np.asarray(im)
        imh, imw = im.shape[:2]
        m = min(imh, imw)  # æœ€å°å°ºå¯¸
        top, left = (imh - m) // 2, (imw - m) // 2
        return cv2.resize(im[top : top + m, left : left + m], (self.w, self.h), interpolation=cv2.INTER_LINEAR)


class ToTensor:
    """
    å°†å›¾åƒä»numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ã€‚

    è¿™ä¸ªç±»æ—¨åœ¨ä½œä¸ºå›¾åƒé¢„å¤„ç†è½¬æ¢ç®¡é“çš„ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼šT.Compose([LetterBox(size), ToTensor()]).

    å±æ€§ï¼š
        half (bool): å¦‚æœä¸ºTrueï¼Œå°†å›¾åƒè½¬æ¢ä¸ºåŠç²¾åº¦ï¼ˆfloat16ï¼‰ã€‚

    æ–¹æ³•ï¼š
        __call__: å¯¹è¾“å…¥å›¾åƒåº”ç”¨å¼ é‡è½¬æ¢ã€‚

    ç¤ºä¾‹ï¼š
        >>> transform = ToTensor(half=True)
        >>> img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        >>> tensor_img = transform(img)
        >>> print(tensor_img.shape, tensor_img.dtype)
        torch.Size([3, 640, 640]) torch.float16

    æ³¨æ„ï¼š
        è¾“å…¥å›¾åƒé¢„è®¡ä¸ºBGRæ ¼å¼ï¼Œå½¢çŠ¶ä¸º(H, W, C)ã€‚
        è¾“å‡ºå¼ é‡å°†ä¸ºRGBæ ¼å¼ï¼Œå½¢çŠ¶ä¸º(C, H, W)ï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0, 1]ã€‚
    """

    def __init__(self, half=False):
        """
        åˆå§‹åŒ–ToTensorå¯¹è±¡ï¼Œç”¨äºå°†å›¾åƒè½¬æ¢ä¸ºPyTorchå¼ é‡ã€‚

        è¿™ä¸ªç±»æ—¨åœ¨ä½œä¸ºUltralytics YOLOæ¡†æ¶ä¸­å›¾åƒé¢„å¤„ç†è½¬æ¢ç®¡é“çš„ä¸€éƒ¨åˆ†ã€‚å®ƒå°†numpyæ•°ç»„æˆ–PILå›¾åƒè½¬æ¢ä¸ºPyTorchå¼ é‡ï¼Œå¹¶æä¾›åŠç²¾åº¦ï¼ˆfloat16ï¼‰è½¬æ¢é€‰é¡¹ã€‚

        å‚æ•°ï¼š
            half (bool): å¦‚æœä¸ºTrueï¼Œåˆ™å°†å¼ é‡è½¬æ¢ä¸ºåŠç²¾åº¦ï¼ˆfloat16ï¼‰ã€‚é»˜è®¤å€¼ä¸ºFalseã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = ToTensor(half=True)
            >>> img = np.random.rand(640, 640, 3)
            >>> tensor_img = transform(img)
            >>> print(tensor_img.dtype)
            torch.float16
        """
        super().__init__()
        self.half = half

    def __call__(self, im):
        """
        å°†å›¾åƒä»numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ã€‚

        è¯¥æ–¹æ³•å°†è¾“å…¥å›¾åƒä»numpyæ•°ç»„è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼Œåº”ç”¨å¯é€‰çš„åŠç²¾åº¦è½¬æ¢å’Œå½’ä¸€åŒ–ã€‚å›¾åƒå°†ä»HWCæ ¼å¼è½¬ç½®ä¸ºCHWæ ¼å¼ï¼Œå¹¶ä¸”é¢œè‰²é€šé“ä»BGRåè½¬ä¸ºRGBã€‚

        å‚æ•°ï¼š
            im (numpy.ndarray): è¾“å…¥å›¾åƒï¼Œå½¢çŠ¶ä¸º(H, W, C)ï¼ŒBGRé¡ºåºã€‚

        è¿”å›ï¼š
            (torch.Tensor): è½¬æ¢åçš„å›¾åƒä½œä¸ºPyTorchå¼ é‡ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32æˆ–float16ï¼Œå½’ä¸€åŒ–åˆ°[0, 1]ï¼Œå½¢çŠ¶ä¸º(C, H, W)ï¼ŒRGBé¡ºåºã€‚

        ç¤ºä¾‹ï¼š
            >>> transform = ToTensor(half=True)
            >>> img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            >>> tensor_img = transform(img)
            >>> print(tensor_img.shape, tensor_img.dtype)
            torch.Size([3, 640, 640]) torch.float16
        """
        im = np.ascontiguousarray(im.transpose((2, 0, 1))[::-1])  # HWCè½¬CHW -> BGRè½¬RGB -> è¿ç»­å†…å­˜
        im = torch.from_numpy(im)  # è½¬æ¢ä¸ºtorchå¼ é‡
        im = im.half() if self.half else im.float()  # uint8 è½¬ä¸º fp16/32
        im /= 255.0  # 0-255 èŒƒå›´è½¬æ¢åˆ° 0.0-1.0
        return im
