# Ultralytics 🚀 AGPL-3.0 许可证 - https://ultralytics.com/license

# YOLO 训练、验证、预测和导出使用的全局配置 YAML，包含设置和超参数
# 文档请参见 https://docs.ultralytics.com/usage/cfg/

task: detect # (str) YOLO 任务类型，例如 detect（检测）、segment（分割）、classify（分类）、pose（姿态估计）、obb（旋转边界框）
mode: train # (str) YOLO 模式，例如 train（训练）、val（验证）、predict（预测）、export（导出）、track（跟踪）、benchmark（基准测试）

# 训练设置 -------------------------------------------------------------------------------------------------------
model: # (str, 可选) 模型文件路径，例如 yolov8n.pt, yolov8n.yaml
data: # (str, 可选) 数据文件路径，例如 coco8.yaml
epochs: 100 # (int) 训练的总历元数
time: # (float, 可选) 训练的时间（小时），如果设置，则覆盖 epochs 参数
patience: 100 # (int) 训练过程中，如果没有明显的改善，提前停止的历元数
batch: 16 # (int) 每个批次的图像数量（-1 表示自动批量）
imgsz: 640 # (int | list) 输入图像大小，适用于训练和验证模式；对于预测和导出模式，可以是 [h, w] 列表
save: True # (bool) 是否保存训练检查点和预测结果
save_period: -1 # (int) 每 x 个历元保存一次检查点（如果小于 1 则禁用）
cache: False # (bool) 使用缓存加载数据，True 表示使用内存缓存（ram），disk 表示使用磁盘缓存，False 表示不缓存
device: # (int | str | list, 可选) 运行设备，例如 cuda device=0 或 device=0,1,2,3 或 device=cpu
workers: 8 # (int) 数据加载的工作线程数（如果使用 DDP，则按 RANK 数量设置）
project: # (str, 可选) 项目名称
name: # (str, 可选) 实验名称，结果保存在 'project/name' 目录中
exist_ok: False # (bool) 是否允许覆盖现有实验
pretrained: True # (bool | str) 是否使用预训练模型（布尔值）或从某个模型加载权重（字符串路径）
optimizer: auto # (str) 使用的优化器，选项包括 [SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
verbose: True # (bool) 是否打印详细输出
seed: 0 # (int) 随机种子，用于保证结果的可重复性
deterministic: True # (bool) 是否启用确定性模式
single_cls: False # (bool) 将多类数据集作为单一类别进行训练
rect: False # (bool) 如果模式为 'train'，则使用矩形训练；如果模式为 'val'，则使用矩形验证
cos_lr: False # (bool) 是否使用余弦学习率调度器
close_mosaic: 10 # (int) 在最后 N 个历元禁用马赛克数据增强（设置为 0 禁用此功能）
resume: False # (bool) 是否从上次保存的检查点恢复训练
amp: True # (bool) 启用自动混合精度（AMP）训练，True 表示启用，False 表示禁用
fraction: 1.0 # (float) 用于训练的数据集部分（默认值为 1.0，表示使用训练集中的所有图像）
profile: False # (bool) 是否在训练过程中进行 ONNX 和 TensorRT 的速度分析
freeze: None # (int | list, 可选) 冻结前 N 层，或在训练过程中冻结指定的层（通过索引指定）
multi_scale: False # (bool) 是否在训练过程中使用多尺度训练

# 分割设置
overlap_mask: True # (bool) 在训练过程中将多个对象的掩码合并为一个单一的图像掩码（仅用于分割训练）
mask_ratio: 4 # (int) 分割掩码的下采样率（仅用于分割训练）

# 分类设置
dropout: 0.0 # (float) 是否使用 dropout 正则化（仅用于分类训练）

# 验证/测试设置 ----------------------------------------------------------------------------------------------------
val: True # (bool) 训练过程中是否进行验证/测试
split: val # (str) 用于验证的数据集分割，可以是 'val'、'test' 或 'train'
save_json: False # (bool) 是否将结果保存为 JSON 文件
save_hybrid: False # (bool) 是否保存标签和附加预测的混合版本
conf: # (float, 可选) 检测的对象置信度阈值（默认 0.25，预测时使用 0.001，验证时使用）
iou: 0.7 # (float) NMS 的交并比（IoU）阈值
max_det: 300 # (int) 每个图像的最大检测数
half: False # (bool) 是否使用半精度（FP16）
dnn: False # (bool) 是否使用 OpenCV DNN 进行 ONNX 推理
plots: True # (bool) 是否在训练/验证期间保存图表和图像

# 预测设置 -----------------------------------------------------------------------------------------------------
source: # (str, 可选) 图像或视频的源目录
vid_stride: 1 # (int) 视频帧率间隔
stream_buffer: False # (bool) 是否缓存所有流式帧（True）或返回最新的帧（False）
visualize: False # (bool) 是否可视化模型特征
augment: False # (bool) 是否对预测源应用图像增强
agnostic_nms: False # (bool) 是否使用类别无关的 NMS
classes: # (int | list[int], 可选) 按类别筛选结果，例如 classes=0，或 classes=[0,2,3]
retina_masks: False # (bool) 是否使用高分辨率的分割掩码
embed: # (list[int], 可选) 从指定的层返回特征向量/嵌入

# 可视化设置 ---------------------------------------------------------------------------------------------------
show: False # (bool) 如果环境允许，是否显示预测的图像和视频
save_frames: False # (bool) 是否保存预测的单独视频帧
save_txt: False # (bool) 是否将结果保存为 .txt 文件
save_conf: False # (bool) 是否保存带有置信度分数的结果
save_crop: False # (bool) 是否保存带有结果的裁剪图像
show_labels: True # (bool) 是否显示预测标签，例如 'person'
show_conf: True # (bool) 是否显示预测的置信度，例如 '0.99'
show_boxes: True # (bool) 是否显示预测框
line_width: # (int, 可选) 预测框的线宽，若为 None 则按图像大小缩放

# 导出设置 ------------------------------------------------------------------------------------------------------
format: torchscript # (str) 导出的格式，选项请见 https://docs.ultralytics.com/modes/export/#export-formats
keras: False # (bool) 是否使用 Keras 导出
optimize: False # (bool) 是否为移动设备优化 TorchScript 模型
int8: False # (bool) CoreML/TF INT8 量化
dynamic: False # (bool) ONNX/TF/TensorRT: 动态轴
simplify: True # (bool) ONNX: 使用 `onnxslim` 简化模型
opset: # (int, 可选) ONNX: opset 版本
workspace: None # (float, 可选) TensorRT: 工作区大小（GiB），`None` 会让 TensorRT 自动分配内存
nms: False # (bool) CoreML: 添加 NMS

# 超参数 ------------------------------------------------------------------------------------------------------
lr0: 0.01 # (float) 初始学习率（例如 SGD=1E-2，Adam=1E-3）
lrf: 0.01 # (float) 最终学习率（lr0 * lrf）
momentum: 0.937 # (float) SGD 动量/Adam beta1
weight_decay: 0.0005 # (float) 优化器权重衰减 5e-4
warmup_epochs: 3.0 # (float) 预热历元数（可以为小数）
warmup_momentum: 0.8 # (float) 预热阶段的初始动量
warmup_bias_lr: 0.0 # 0.1 # (float) 预热阶段的初始偏置学习率
box: 7.5 # (float) 边框损失增益
cls: 0.5 # (float) 分类损失增益（按像素缩放）
dfl: 1.5 # (float) 分布焦点损失增益
pose: 12.0 # (float) 姿态损失增益
kobj: 1.0 # (float) 关键点目标损失增益
nbs: 64 # (int) 标准批量大小
hsv_h: 0.015 # (float) 图像 HSV-Hue 增强（比例）
hsv_s: 0.7 # (float) 图像 HSV-Saturation 增强（比例）
hsv_v: 0.4 # (float) 图像 HSV-Value 增强（比例）
degrees: 0.0 # (float) 图像旋转（+/- 度）
translate: 0.1 # (float) 图像平移（+/- 比例）
scale: 0.5 # (float) 图像缩放（+/- 增益）
shear: 0.0 # (float) 图像剪切（+/- 度）
perspective: 0.0 # (float) 图像透视（+/- 比例），范围 0-0.001
flipud: 0.0 # (float) 图像上下翻转（概率）
fliplr: 0.5 # (float) 图像左右翻转（概率）
bgr: 0.0 # (float) 图像通道 BGR（概率）

mosaic: 1.0 # (float) 图像马赛克增强（概率）
mixup: 0.0 # (float) 图像 mixup（概率）
copy_paste: 0.1 # (float) 分割复制粘贴（概率）

copy_paste_mode: "flip" # (str) 用于复制粘贴增强的方法（flip，mixup）
auto_augment: randaugment # (str) 分类任务的自动增强策略（randaugment，autoaugment，augmix）
erasing: 0.4 # (float) 分类训练中的随机擦除概率（0-0.9），0 表示不擦除，必须小于 1.0
crop_fraction: 1.0 # (float) 分类训练中的图像裁剪比例（0.1-1），1.0 表示不裁剪，必须大于 0

# 自定义 config.yaml ---------------------------------------------------------------------------------------------------
cfg: # (str, 可选) 用于覆盖 defaults.yaml

# 跟踪器设置 ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml # (str) 跟踪器类型，选择 [botsort.yaml, bytetrack.yaml]
