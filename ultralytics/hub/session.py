# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import shutil
import threading
import time
from http import HTTPStatus
from pathlib import Path
from urllib.parse import parse_qs, urlparse

import requests

from ultralytics.hub.utils import HELP_MSG, HUB_WEB_ROOT, PREFIX, TQDM
from ultralytics.utils import IS_COLAB, LOGGER, SETTINGS, __version__, checks, emojis
from ultralytics.utils.errors import HUBModelError

AGENT_NAME = f"python-{__version__}-colab" if IS_COLAB else f"python-{__version__}-local"


class HUBTrainingSession:
    """
    ç”¨äºUltralytics HUB YOLOæ¨¡å‹çš„è®­ç»ƒä¼šè¯ã€‚å¤„ç†æ¨¡å‹åˆå§‹åŒ–ã€å¿ƒè·³å’Œæ£€æŸ¥ç‚¹ã€‚

    å±æ€§:
        model_id (str): è¢«è®­ç»ƒçš„YOLOæ¨¡å‹çš„æ ‡è¯†ç¬¦ã€‚
        model_url (str): Ultralytics HUBä¸­æ¨¡å‹çš„URLã€‚
        rate_limits (dict): ä¸åŒAPIè°ƒç”¨çš„é€Ÿç‡é™åˆ¶ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰ã€‚
        timers (dict): ç”¨äºé€Ÿç‡é™åˆ¶çš„è®¡æ—¶å™¨ã€‚
        metrics_queue (dict): å­˜å‚¨æ¯ä¸ªå‘¨æœŸçš„æ¨¡å‹æŒ‡æ ‡ï¼Œç›´åˆ°ä¸Šä¼ ã€‚
        model (dict): ä»Ultralytics HUBè·å–çš„æ¨¡å‹æ•°æ®ã€‚
    """

    def __init__(self, identifier):
        """
        ä½¿ç”¨æä¾›çš„æ¨¡å‹æ ‡è¯†ç¬¦åˆå§‹åŒ–HUBTrainingSessionã€‚

        å‚æ•°:
            identifier (str): ç”¨äºåˆå§‹åŒ–HUBè®­ç»ƒä¼šè¯çš„æ¨¡å‹æ ‡è¯†ç¬¦ã€‚
                å®ƒå¯ä»¥æ˜¯ä¸€ä¸ªURLå­—ç¬¦ä¸²ï¼Œæˆ–è€…å…·æœ‰ç‰¹å®šæ ¼å¼çš„æ¨¡å‹å¯†é’¥ã€‚

        å¼‚å¸¸:
            ValueError: å¦‚æœæä¾›çš„æ¨¡å‹æ ‡è¯†ç¬¦æ— æ•ˆã€‚
            ConnectionError: å¦‚æœæ— æ³•ä½¿ç”¨å…¨å±€APIå¯†é’¥è¿›è¡Œè¿æ¥ã€‚
            ModuleNotFoundError: å¦‚æœæœªå®‰è£…hub-sdkåŒ…ã€‚
        """
        from hub_sdk import HUBClient

        self.rate_limits = {"metrics": 3, "ckpt": 900, "heartbeat": 300}  # é€Ÿç‡é™åˆ¶ï¼ˆç§’ï¼‰
        self.metrics_queue = {}  # å­˜å‚¨æ¯ä¸ªå‘¨æœŸçš„æŒ‡æ ‡ï¼Œç›´åˆ°ä¸Šä¼ 
        self.metrics_upload_failed_queue = {}  # å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œåˆ™å­˜å‚¨æ¯ä¸ªå‘¨æœŸçš„æŒ‡æ ‡
        self.timers = {}  # å­˜å‚¨è®¡æ—¶å™¨ï¼Œç”¨äº ultralytics/utils/callbacks/hub.py
        self.model = None
        self.model_url = None
        self.model_file = None
        self.train_args = None

        # è§£æè¾“å…¥
        api_key, model_id, self.filename = self._parse_identifier(identifier)

        # è·å–å‡­è¯
        active_key = api_key or SETTINGS.get("api_key")
        credentials = {"api_key": active_key} if active_key else None  # è®¾ç½®å‡­è¯

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.client = HUBClient(credentials)

        # åŠ è½½æ¨¡å‹
        try:
            if model_id:
                self.load_model(model_id)  # åŠ è½½ç°æœ‰æ¨¡å‹
            else:
                self.model = self.client.model()  # åŠ è½½ç©ºæ¨¡å‹
        except Exception:
            if identifier.startswith(f"{HUB_WEB_ROOT}/models/") and not self.client.authenticated:
                LOGGER.warning(
                    f"{PREFIX}è­¦å‘Š âš ï¸ è¯·ä½¿ç”¨ 'yolo login API_KEY' ç™»å½•ã€‚"
                    "ä½ å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®æ‰¾åˆ°ä½ çš„APIå¯†é’¥: https://hub.ultralytics.com/settings?tab=api+keys."
                )

    @classmethod
    def create_session(cls, identifier, args=None):
        """ç±»æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºç»è¿‡è®¤è¯çš„HUBTrainingSessionï¼Œæˆ–è€…è¿”å›Noneã€‚"""
        try:
            session = cls(identifier)
            if args and not identifier.startswith(f"{HUB_WEB_ROOT}/models/"):  # ä¸æ˜¯HUBæ¨¡å‹URL
                session.create_model(args)
                assert session.model.id, "HUBæ¨¡å‹æœªæ­£ç¡®åŠ è½½"
            return session
        # PermissionErrorå’ŒModuleNotFoundErrorè¡¨ç¤ºæœªå®‰è£…hub-sdk
        except (PermissionError, ModuleNotFoundError, AssertionError):
            return None

    def load_model(self, model_id):
        """ä½¿ç”¨æä¾›çš„æ¨¡å‹æ ‡è¯†ç¬¦ä»Ultralytics HUBåŠ è½½ç°æœ‰æ¨¡å‹ã€‚"""
        self.model = self.client.model(model_id)
        if not self.model.data:  # å¦‚æœæ¨¡å‹ä¸å­˜åœ¨
            raise ValueError(emojis("âŒ æŒ‡å®šçš„HUBæ¨¡å‹ä¸å­˜åœ¨"))  # TODO: æ”¹è¿›é”™è¯¯å¤„ç†

        self.model_url = f"{HUB_WEB_ROOT}/models/{self.model.id}"
        if self.model.is_trained():
            print(emojis(f"åŠ è½½å·²è®­ç»ƒçš„HUBæ¨¡å‹ {self.model_url} ğŸš€"))
            url = self.model.get_weights_url("best")  # å…·æœ‰è®¤è¯çš„ä¸‹è½½URL
            self.model_file = checks.check_file(url, download_dir=Path(SETTINGS["weights_dir"]) / "hub" / self.model.id)
            return

        # è®¾ç½®è®­ç»ƒå‚æ•°å¹¶å¼€å§‹å¿ƒè·³ï¼Œä»¥ä¾¿HUBç›‘æ§ä»£ç†
        self._set_train_args()
        self.model.start_heartbeat(self.rate_limits["heartbeat"])
        LOGGER.info(f"{PREFIX}æŸ¥çœ‹æ¨¡å‹ {self.model_url} ğŸš€")

    def create_model(self, model_args):
        """ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æ ‡è¯†ç¬¦åˆå§‹åŒ–HUBè®­ç»ƒä¼šè¯ã€‚"""
        payload = {
            "config": {
                "batchSize": model_args.get("batch", -1),
                "epochs": model_args.get("epochs", 300),
                "imageSize": model_args.get("imgsz", 640),
                "patience": model_args.get("patience", 100),
                "device": str(model_args.get("device", "")),  # å°†Noneè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                "cache": str(model_args.get("cache", "ram")),  # å°†True, False, Noneè½¬æ¢ä¸ºå­—ç¬¦ä¸²
            },
            "dataset": {"name": model_args.get("data")},
            "lineage": {
                "architecture": {"name": self.filename.replace(".pt", "").replace(".yaml", "")},
                "parent": {},
            },
            "meta": {"name": self.filename},
        }

        if self.filename.endswith(".pt"):
            payload["lineage"]["parent"]["name"] = self.filename

        self.model.create_model(payload)

        # å¦‚æœæ¨¡å‹æœªèƒ½åˆ›å»º
        # TODO: æ”¹è¿›é”™è¯¯å¤„ç†
        if not self.model.id:
            return None

        self.model_url = f"{HUB_WEB_ROOT}/models/{self.model.id}"

        # å¼€å§‹å¿ƒè·³ï¼Œä»¥ä¾¿HUBç›‘æ§ä»£ç†
        self.model.start_heartbeat(self.rate_limits["heartbeat"])

        LOGGER.info(f"{PREFIX}æŸ¥çœ‹æ¨¡å‹ {self.model_url} ğŸš€")

    @staticmethod
    def _parse_identifier(identifier):
        """
        è§£æç»™å®šçš„æ ‡è¯†ç¬¦ä»¥ç¡®å®šæ ‡è¯†ç¬¦ç±»å‹å¹¶æå–ç›¸å…³ç»„ä»¶ã€‚

        è¯¥æ–¹æ³•æ”¯æŒä¸åŒçš„æ ‡è¯†ç¬¦æ ¼å¼ï¼š
            - ä¸€ä¸ªHUBæ¨¡å‹URL https://hub.ultralytics.com/models/MODEL
            - ä¸€ä¸ªå¸¦æœ‰APIå¯†é’¥çš„HUBæ¨¡å‹URL https://hub.ultralytics.com/models/MODEL?api_key=APIKEY
            - ä¸€ä¸ªä»¥'.pt'æˆ–'.yaml'ç»“å°¾çš„æœ¬åœ°æ–‡ä»¶å

        å‚æ•°ï¼š
            identifier (str): è¦è§£æçš„æ ‡è¯†ç¬¦å­—ç¬¦ä¸²ã€‚

        è¿”å›ï¼š
            (tuple): ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«APIå¯†é’¥ã€æ¨¡å‹IDå’Œæ–‡ä»¶åï¼ˆå¦‚é€‚ç”¨ï¼‰ã€‚

        å¼‚å¸¸ï¼š
            HUBModelError: å¦‚æœæ ‡è¯†ç¬¦æ ¼å¼æ— æ³•è¯†åˆ«ã€‚
        """
        api_key, model_id, filename = None, None, None
        if Path(identifier).suffix in {".pt", ".yaml"}:
            filename = identifier
        elif identifier.startswith(f"{HUB_WEB_ROOT}/models/"):
            parsed_url = urlparse(identifier)
            model_id = Path(parsed_url.path).stem  # å¤„ç†å¯èƒ½å­˜åœ¨çš„æœ«å°¾æ–œæ 
            query_params = parse_qs(parsed_url.query)  # å­—å…¸å½¢å¼ï¼Œä¾‹ï¼š{"api_key": ["API_KEY_HERE"]}
            api_key = query_params.get("api_key", [None])[0]
        else:
            raise HUBModelError(f"model='{identifier} æ— æ•ˆï¼Œæ­£ç¡®æ ¼å¼æ˜¯ {HUB_WEB_ROOT}/models/MODEL_ID")
        return api_key, model_id, filename

    def _set_train_args(self):
        """
        åˆå§‹åŒ–è®­ç»ƒå‚æ•°å¹¶åœ¨Ultralytics HUBä¸Šåˆ›å»ºæ¨¡å‹æ¡ç›®ã€‚

        è¯¥æ–¹æ³•æ ¹æ®æ¨¡å‹çš„çŠ¶æ€è®¾ç½®è®­ç»ƒå‚æ•°ï¼Œå¹¶æ ¹æ®æä¾›çš„é¢å¤–å‚æ•°æ›´æ–°å®ƒä»¬ã€‚å®ƒå¤„ç†æ¨¡å‹çš„ä¸åŒçŠ¶æ€ï¼Œä¾‹å¦‚æ˜¯å¦å¯ä»¥æ¢å¤è®­ç»ƒï¼Œæ˜¯å¦æ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ–æ˜¯å¦éœ€è¦ç‰¹å®šçš„æ–‡ä»¶è®¾ç½®ã€‚

        å¼‚å¸¸ï¼š
            ValueError: å¦‚æœæ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼Œç¼ºå°‘æ‰€éœ€çš„æ•°æ®é›†ä¿¡æ¯ï¼Œæˆ–æä¾›çš„è®­ç»ƒå‚æ•°å­˜åœ¨é—®é¢˜ã€‚
        """
        if self.model.is_resumable():
            # æ¨¡å‹æœ‰å·²ä¿å­˜çš„æƒé‡
            self.train_args = {"data": self.model.get_dataset_url(), "resume": True}
            self.model_file = self.model.get_weights_url("last")
        else:
            # æ¨¡å‹æ²¡æœ‰å·²ä¿å­˜çš„æƒé‡
            self.train_args = self.model.data.get("train_args")  # æ–°çš„å“åº”

            # å°†æ¨¡å‹æ–‡ä»¶è®¾ç½®ä¸º*.ptæˆ–*.yamlæ–‡ä»¶
            self.model_file = (
                self.model.get_weights_url("parent") if self.model.is_pretrained() else self.model.get_architecture()
            )

        if "data" not in self.train_args:
            # RF bug - æ•°æ®é›†æœ‰æ—¶æœªå¯¼å‡º
            raise ValueError("æ•°æ®é›†å¯èƒ½ä»åœ¨å¤„ç†ã€‚è¯·ç¨ç­‰ç‰‡åˆ»å†è¯•ã€‚")

        self.model_file = checks.check_yolov5u_filename(self.model_file, verbose=False)  # YOLOv5->YOLOv5u
        self.model_id = self.model.id

    def request_queue(
        self,
        request_func,
        retry=3,
        timeout=30,
        thread=True,
        verbose=True,
        progress_total=None,
        stream_response=None,
        *args,
        **kwargs,
    ):
        """å°è¯•æ‰§è¡Œ`request_func`ï¼Œå¹¶æ”¯æŒé‡è¯•ã€è¶…æ—¶å¤„ç†ã€å¯é€‰çš„å¤šçº¿ç¨‹å’Œè¿›åº¦æ˜¾ç¤ºã€‚"""

        def retry_request():
            """å°è¯•è°ƒç”¨`request_func`ï¼Œæ”¯æŒé‡è¯•ã€è¶…æ—¶å’Œå¯é€‰çš„å¤šçº¿ç¨‹ã€‚"""
            t0 = time.time()  # è®°å½•è¶…æ—¶çš„å¼€å§‹æ—¶é—´
            response = None
            for i in range(retry + 1):
                if (time.time() - t0) > timeout:
                    LOGGER.warning(f"{PREFIX}è¯·æ±‚è¶…æ—¶ã€‚ {HELP_MSG}")
                    break  # è¶…æ—¶ï¼Œé€€å‡ºå¾ªç¯

                response = request_func(*args, **kwargs)
                if response is None:
                    LOGGER.warning(f"{PREFIX}æœªæ”¶åˆ°è¯·æ±‚çš„å“åº”ã€‚ {HELP_MSG}")
                    time.sleep(2**i)  # æŒ‡æ•°é€€é¿ï¼Œå†æ¬¡é‡è¯•å‰ç­‰å¾…
                    continue  # è·³è¿‡è¿›ä¸€æ­¥å¤„ç†ï¼Œé‡æ–°å°è¯•

                if progress_total:
                    self._show_upload_progress(progress_total, response)
                elif stream_response:
                    self._iterate_content(response)

                if HTTPStatus.OK <= response.status_code < HTTPStatus.MULTIPLE_CHOICES:
                    # å¦‚æœè¯·æ±‚ä¸æŒ‡æ ‡ä¸Šä¼ ç›¸å…³
                    if kwargs.get("metrics"):
                        self.metrics_upload_failed_queue = {}
                    return response  # æˆåŠŸï¼Œä¸éœ€è¦é‡è¯•

                if i == 0:
                    # åˆæ¬¡å°è¯•ï¼Œæ£€æŸ¥çŠ¶æ€ç å¹¶æä¾›æç¤ºä¿¡æ¯
                    message = self._get_failure_message(response, retry, timeout)

                    if verbose:
                        LOGGER.warning(f"{PREFIX}{message} {HELP_MSG} ({response.status_code})")

                if not self._should_retry(response.status_code):
                    LOGGER.warning(f"{PREFIX}è¯·æ±‚å¤±è´¥ã€‚ {HELP_MSG} ({response.status_code})")
                    break  # ä¸æ˜¯éœ€è¦é‡è¯•çš„é”™è¯¯ï¼Œé€€å‡ºå¾ªç¯

                time.sleep(2**i)  # é‡è¯•æ—¶æŒ‡æ•°é€€é¿

            # å¦‚æœè¯·æ±‚ä¸æŒ‡æ ‡ä¸Šä¼ ç›¸å…³å¹¶ä¸”é‡è¯•æ¬¡æ•°è¶…è¿‡
            if response is None and kwargs.get("metrics"):
                self.metrics_upload_failed_queue.update(kwargs.get("metrics"))

            return response

        if thread:
            # å¯åŠ¨ä¸€ä¸ªæ–°çº¿ç¨‹è¿è¡Œretry_requestå‡½æ•°
            threading.Thread(target=retry_request, daemon=True).start()
        else:
            # å¦‚æœåœ¨ä¸»çº¿ç¨‹ä¸­è¿è¡Œï¼Œç›´æ¥è°ƒç”¨retry_request
            return retry_request()

    @staticmethod
    def _should_retry(status_code):
        """æ ¹æ®HTTPçŠ¶æ€ç åˆ¤æ–­è¯·æ±‚æ˜¯å¦éœ€è¦é‡è¯•ã€‚"""
        retry_codes = {
            HTTPStatus.REQUEST_TIMEOUT,
            HTTPStatus.BAD_GATEWAY,
            HTTPStatus.GATEWAY_TIMEOUT,
        }
        return status_code in retry_codes

    def _get_failure_message(self, response: requests.Response, retry: int, timeout: int):
        """
        æ ¹æ®å“åº”çŠ¶æ€ç ç”Ÿæˆé‡è¯•æ¶ˆæ¯ã€‚

        å‚æ•°:
            response: HTTP å“åº”å¯¹è±¡ã€‚
            retry: å…è®¸çš„é‡è¯•æ¬¡æ•°ã€‚
            timeout: æœ€å¤§è¶…æ—¶æ—¶é—´ã€‚

        è¿”å›:
            (str): é‡è¯•æ¶ˆæ¯ã€‚
        """
        if self._should_retry(response.status_code):
            return f"æ­£åœ¨é‡è¯• {retry} æ¬¡ï¼Œè¶…æ—¶ {timeout} ç§’ã€‚" if retry else ""
        elif response.status_code == HTTPStatus.TOO_MANY_REQUESTS:  # è¾¾åˆ°é€Ÿç‡é™åˆ¶
            headers = response.headers
            return (
                f"è¾¾åˆ°é€Ÿç‡é™åˆ¶ï¼ˆ{headers['X-RateLimit-Remaining']}/{headers['X-RateLimit-Limit']}ï¼‰ã€‚"
                f" è¯·åœ¨ {headers['Retry-After']} ç§’åé‡è¯•ã€‚"
            )
        else:
            try:
                return response.json().get("message", "æ²¡æœ‰ JSON æ¶ˆæ¯ã€‚")
            except AttributeError:
                return "æ— æ³•è¯»å– JSONã€‚"

    def upload_metrics(self):
        """å°†æ¨¡å‹æŒ‡æ ‡ä¸Šä¼ åˆ° Ultralytics HUBã€‚"""
        return self.request_queue(self.model.upload_metrics, metrics=self.metrics_queue.copy(), thread=True)

    def upload_model(
        self,
        epoch: int,
        weights: str,
        is_best: bool = False,
        map: float = 0.0,
        final: bool = False,
    ) -> None:
        """
        å°†æ¨¡å‹æ£€æŸ¥ç‚¹ä¸Šä¼ åˆ° Ultralytics HUBã€‚

        å‚æ•°:
            epoch (int): å½“å‰çš„è®­ç»ƒå‘¨æœŸã€‚
            weights (str): æ¨¡å‹æƒé‡æ–‡ä»¶çš„è·¯å¾„ã€‚
            is_best (bool): è¡¨ç¤ºå½“å‰æ¨¡å‹æ˜¯å¦æ˜¯è¿„ä»Šä¸ºæ­¢æœ€ä½³çš„æ¨¡å‹ã€‚
            map (float): æ¨¡å‹çš„å¹³å‡ç²¾åº¦ï¼ˆMean Average Precisionï¼‰ã€‚
            final (bool): è¡¨ç¤ºè¯¥æ¨¡å‹æ˜¯å¦æ˜¯è®­ç»ƒç»“æŸåçš„æœ€ç»ˆæ¨¡å‹ã€‚
        """
        weights = Path(weights)
        if not weights.is_file():
            last = weights.with_name(f"last{weights.suffix}")
            if final and last.is_file():
                LOGGER.warning(
                    f"{PREFIX} è­¦å‘Š âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹ 'best.pt'ï¼Œå°† 'last.pt' å¤åˆ¶åˆ° 'best.pt' å¹¶ä¸Šä¼ ã€‚"
                    "å½“åœ¨åƒ Google Colab è¿™æ ·çš„ä¸´æ—¶ç¯å¢ƒä¸­æ¢å¤è®­ç»ƒæ—¶ï¼Œå¸¸å¸¸ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚"
                    "ä¸ºäº†æ›´å¯é çš„è®­ç»ƒï¼Œå»ºè®®ä½¿ç”¨ Ultralytics HUB Cloudã€‚"
                    "æ›´å¤šä¿¡æ¯è¯·è®¿é—® https://docs.ultralytics.com/hub/cloud-training."
                )
                shutil.copy(last, weights)  # å°† last.pt å¤åˆ¶åˆ° best.pt
            else:
                LOGGER.warning(f"{PREFIX} è­¦å‘Š âš ï¸ æ¨¡å‹ä¸Šä¼ é—®é¢˜ã€‚ç¼ºå°‘æ¨¡å‹ {weights}ã€‚")
                return

        self.request_queue(
            self.model.upload_model,
            epoch=epoch,
            weights=str(weights),
            is_best=is_best,
            map=map,
            final=final,
            retry=10,
            timeout=3600,
            thread=not final,
            progress_total=weights.stat().st_size if final else None,  # ä»…åœ¨æœ€ç»ˆæ¨¡å‹æ—¶æ˜¾ç¤ºè¿›åº¦
            stream_response=True,
        )

    @staticmethod
    def _show_upload_progress(content_length: int, response: requests.Response) -> None:
        """
        æ˜¾ç¤ºè¿›åº¦æ¡ä»¥è·Ÿè¸ªæ–‡ä»¶ä¸Šä¼ çš„è¿›åº¦ã€‚

        å‚æ•°:
            content_length (int): è¦ä¸‹è½½çš„å†…å®¹çš„æ€»å¤§å°ï¼ˆå­—èŠ‚æ•°ï¼‰ã€‚
            response (requests.Response): æ¥è‡ªæ–‡ä»¶ä¸‹è½½è¯·æ±‚çš„å“åº”å¯¹è±¡ã€‚

        è¿”å›:
            None
        """
        with TQDM(total=content_length, unit="B", unit_scale=True, unit_divisor=1024) as pbar:
            for data in response.iter_content(chunk_size=1024):
                pbar.update(len(data))

    @staticmethod
    def _iterate_content(response: requests.Response) -> None:
        """
        å¤„ç†æµå¼ HTTP å“åº”æ•°æ®ã€‚

        å‚æ•°:
            response (requests.Response): æ¥è‡ªæ–‡ä»¶ä¸‹è½½è¯·æ±‚çš„å“åº”å¯¹è±¡ã€‚

        è¿”å›:
            None
        """
        for _ in response.iter_content(chunk_size=1024):
            pass  # ä¸å¤„ç†æ•°æ®å—
