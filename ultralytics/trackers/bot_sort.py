# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from collections import deque

import numpy as np

from .basetrack import TrackState
from .byte_tracker import BYTETracker, STrack
from .utils import matching
from .utils.gmc import GMC
from .utils.kalman_filter import KalmanFilterXYWH


class BOTrack(STrack):
    """
    YOLOv8 çš„ STrack ç±»çš„æ‰©å±•ç‰ˆæœ¬ï¼Œå¢åŠ äº†ç›®æ ‡è·Ÿè¸ªåŠŸèƒ½ã€‚

    è¯¥ç±»æ‰©å±•äº† STrackï¼Œæ·»åŠ äº†å¦‚ç‰¹å¾å¹³æ»‘ã€å¡å°”æ›¼é¢„æµ‹ã€è½¨è¿¹é‡æ¿€æ´»ç­‰åŠŸèƒ½ã€‚

    å±æ€§:
        shared_kalman (KalmanFilterXYWH): æ‰€æœ‰ BOTrack å®ä¾‹å…±äº«çš„å¡å°”æ›¼æ»¤æ³¢å™¨ã€‚
        smooth_feat (np.ndarray): å¹³æ»‘åçš„ç‰¹å¾å‘é‡ã€‚
        curr_feat (np.ndarray): å½“å‰å¸§çš„ç‰¹å¾å‘é‡ã€‚
        features (deque): å­˜å‚¨ç‰¹å¾å‘é‡çš„é˜Ÿåˆ—ï¼Œæœ€å¤§é•¿åº¦ç”± feat_history å®šä¹‰ã€‚
        alpha (float): ç”¨äºç‰¹å¾æŒ‡æ•°å¹³æ»‘çš„ç³»æ•°ã€‚
        mean (np.ndarray): å¡å°”æ›¼æ»¤æ³¢å™¨çš„å‡å€¼çŠ¶æ€ã€‚
        covariance (np.ndarray): å¡å°”æ›¼æ»¤æ³¢å™¨çš„åæ–¹å·®çŸ©é˜µã€‚

    æ–¹æ³•:
        update_features(feat): æ›´æ–°ç‰¹å¾å‘é‡ï¼Œå¹¶ä½¿ç”¨æŒ‡æ•°æ»‘åŠ¨å¹³å‡è¿›è¡Œå¹³æ»‘ã€‚
        predict(): ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨é¢„æµ‹å‡å€¼å’Œåæ–¹å·®ã€‚
        re_activate(new_track, frame_id, new_id): ä½¿ç”¨æ–°ç‰¹å¾é‡æ–°æ¿€æ´»ç›®æ ‡è½¨è¿¹ï¼Œå¯é€‰æ›´æ¢ IDã€‚
        update(new_track, frame_id): ä½¿ç”¨æ–°è½¨è¿¹å’Œå¸§ ID æ›´æ–°å½“å‰å¯¹è±¡ã€‚
        tlwh: è¿”å›å½“å‰ç›®æ ‡çš„ tlwh æ ¼å¼åæ ‡ï¼ˆå·¦ä¸Šè§’x, å·¦ä¸Šè§’y, å®½, é«˜ï¼‰ã€‚
        multi_predict(stracks): ä½¿ç”¨å…±äº«å¡å°”æ›¼æ»¤æ³¢å™¨å¯¹å¤šä¸ªè½¨è¿¹è¿›è¡Œé¢„æµ‹ã€‚
        convert_coords(tlwh): å°† tlwh åæ ‡æ ¼å¼è½¬æ¢ä¸º xywh æ ¼å¼ã€‚
        tlwh_to_xywh(tlwh): å°†è¾¹ç•Œæ¡†ä» tlwh è½¬æ¢ä¸º xywh æ ¼å¼ï¼ˆä¸­å¿ƒx, ä¸­å¿ƒy, å®½, é«˜ï¼‰ã€‚

    ç¤ºä¾‹:
        åˆ›å»ºä¸€ä¸ª BOTrack å®ä¾‹å¹¶æ›´æ–°å…¶ç‰¹å¾
        >>> bo_track = BOTrack(tlwh=[100, 50, 80, 40], score=0.9, cls=1, feat=np.random.rand(128))
        >>> bo_track.predict()
        >>> new_track = BOTrack(tlwh=[110, 60, 80, 40], score=0.85, cls=1, feat=np.random.rand(128))
        >>> bo_track.update(new_track, frame_id=2)
    """

    shared_kalman = KalmanFilterXYWH()

    def __init__(self, tlwh, score, cls, feat=None, feat_history=50):
        """
        åˆå§‹åŒ–ä¸€ä¸ª BOTrack å¯¹è±¡ï¼ŒåŒ…å«ç‰¹å¾å†å²ã€å¹³æ»‘ç³»æ•°ç­‰æ—¶é—´ç›¸å…³å‚æ•°ã€‚

        å‚æ•°:
            tlwh (np.ndarray): è¾¹ç•Œæ¡†åæ ‡ï¼Œæ ¼å¼ä¸º (å·¦ä¸Šx, å·¦ä¸Šy, å®½, é«˜)ã€‚
            score (float): è¯¥æ£€æµ‹çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚
            cls (int): æ£€æµ‹ç›®æ ‡çš„ç±»åˆ« IDã€‚
            feat (np.ndarray | None): ä¸è¯¥æ£€æµ‹ç›¸å…³è”çš„ç‰¹å¾å‘é‡ã€‚
            feat_history (int): ç‰¹å¾å†å²è®°å½•é˜Ÿåˆ—çš„æœ€å¤§é•¿åº¦ã€‚

        ç¤ºä¾‹:
            åˆå§‹åŒ–ä¸€ä¸ª BOTrack å®ä¾‹
            >>> tlwh = np.array([100, 50, 80, 120])
            >>> score = 0.9
            >>> cls = 1
            >>> feat = np.random.rand(128)
            >>> bo_track = BOTrack(tlwh, score, cls, feat)
        """
        super().__init__(tlwh, score, cls)

        self.smooth_feat = None
        self.curr_feat = None
        if feat is not None:
            self.update_features(feat)
        self.features = deque([], maxlen=feat_history)
        self.alpha = 0.9

    def update_features(self, feat):
        """æ›´æ–°å½“å‰å¸§çš„ç‰¹å¾å‘é‡ï¼Œå¹¶è¿›è¡ŒæŒ‡æ•°æ»‘åŠ¨å¹³å‡å¹³æ»‘å¤„ç†ã€‚"""
        feat /= np.linalg.norm(feat)
        self.curr_feat = feat
        if self.smooth_feat is None:
            self.smooth_feat = feat
        else:
            self.smooth_feat = self.alpha * self.smooth_feat + (1 - self.alpha) * feat
        self.features.append(feat)
        self.smooth_feat /= np.linalg.norm(self.smooth_feat)

    def predict(self):
        """ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨é¢„æµ‹ç›®æ ‡çš„æœªæ¥çŠ¶æ€ï¼ˆå‡å€¼å’Œåæ–¹å·®ï¼‰ã€‚"""
        mean_state = self.mean.copy()
        if self.state != TrackState.Tracked:
            mean_state[6] = 0
            mean_state[7] = 0

        self.mean, self.covariance = self.kalman_filter.predict(mean_state, self.covariance)

    def re_activate(self, new_track, frame_id, new_id=False):
        """ä½¿ç”¨æ–°è½¨è¿¹æ›´æ–°å½“å‰è½¨è¿¹å¹¶é‡æ¿€æ´»ç›®æ ‡ï¼Œå¯é€‰æ‹©æ˜¯å¦æ›´æ¢ IDã€‚"""
        if new_track.curr_feat is not None:
            self.update_features(new_track.curr_feat)
        super().re_activate(new_track, frame_id, new_id)

    def update(self, new_track, frame_id):
        """ä½¿ç”¨æ–°è½¨è¿¹ä¿¡æ¯å’Œå½“å‰å¸§ ID æ›´æ–°å½“å‰ç›®æ ‡ã€‚"""
        if new_track.curr_feat is not None:
            self.update_features(new_track.curr_feat)
        super().update(new_track, frame_id)

    @property
    def tlwh(self):
        """è¿”å›å½“å‰ç›®æ ‡çš„è¾¹ç•Œæ¡†ä½ç½®ï¼Œæ ¼å¼ä¸º `(å·¦ä¸Šè§’x, å·¦ä¸Šè§’y, å®½, é«˜)`ã€‚"""
        if self.mean is None:
            return self._tlwh.copy()
        ret = self.mean[:4].copy()
        ret[:2] -= ret[2:] / 2
        return ret

    @staticmethod
    def multi_predict(stracks):
        """ä½¿ç”¨å…±äº«çš„å¡å°”æ›¼æ»¤æ³¢å™¨å¯¹å¤šä¸ªç›®æ ‡è½¨è¿¹è¿›è¡Œå‡å€¼å’Œåæ–¹å·®é¢„æµ‹ã€‚"""
        if len(stracks) <= 0:
            return
        multi_mean = np.asarray([st.mean.copy() for st in stracks])
        multi_covariance = np.asarray([st.covariance for st in stracks])
        for i, st in enumerate(stracks):
            if st.state != TrackState.Tracked:
                multi_mean[i][6] = 0
                multi_mean[i][7] = 0
        multi_mean, multi_covariance = BOTrack.shared_kalman.multi_predict(multi_mean, multi_covariance)
        for i, (mean, cov) in enumerate(zip(multi_mean, multi_covariance)):
            stracks[i].mean = mean
            stracks[i].covariance = cov

    def convert_coords(self, tlwh):
        """å°† tlwh è¾¹ç•Œæ¡†åæ ‡è½¬æ¢ä¸º xywh æ ¼å¼ï¼ˆä¸­å¿ƒç‚¹ï¼‰ã€‚"""
        return self.tlwh_to_xywh(tlwh)

    @staticmethod
    def tlwh_to_xywh(tlwh):
        """å°†è¾¹ç•Œæ¡†ä» tlwhï¼ˆå·¦ä¸Šè§’ï¼‰æ ¼å¼è½¬æ¢ä¸º xywhï¼ˆä¸­å¿ƒç‚¹ï¼‰æ ¼å¼ã€‚"""
        ret = np.asarray(tlwh).copy()
        ret[:2] += ret[2:] / 2
        return ret


class BOTSORT(BYTETracker):
    """
    BOTSORT æ˜¯ BYTETracker ç±»çš„æ‰©å±•ç‰ˆæœ¬ï¼Œé€‚ç”¨äº YOLOv8ï¼Œæ”¯æŒä½¿ç”¨ ReID å’Œ GMC ç®—æ³•è¿›è¡Œç›®æ ‡è·Ÿè¸ªã€‚

    å±æ€§:
        proximity_thresh (float): è¡¨ç¤ºè½¨è¿¹ä¸æ£€æµ‹æ¡†ä¹‹é—´ç©ºé—´æ¥è¿‘åº¦ï¼ˆIoUï¼‰çš„é˜ˆå€¼ã€‚
        appearance_thresh (float): è¡¨ç¤ºè½¨è¿¹ä¸æ£€æµ‹æ¡†ä¹‹é—´å¤–è§‚ç›¸ä¼¼åº¦ï¼ˆReIDç‰¹å¾ï¼‰çš„é˜ˆå€¼ã€‚
        encoder (Any): å¤„ç† ReID ç‰¹å¾çš„å¯¹è±¡ï¼Œå¦‚æœæœªå¯ç”¨ ReIDï¼Œåˆ™ä¸º Noneã€‚
        gmc (GMC): GMC ç®—æ³•å®ä¾‹ï¼Œç”¨äºæ•°æ®å…³è”ã€‚
        args (Any): åŒ…å«è·Ÿè¸ªå‚æ•°çš„è§£æå‘½ä»¤è¡Œå‚æ•°ã€‚

    æ–¹æ³•:
        get_kalmanfilter(): è¿”å›ä¸€ä¸ª KalmanFilterXYWH å®ä¾‹ç”¨äºç›®æ ‡è·Ÿè¸ªã€‚
        init_track(dets, scores, cls, img): ä½¿ç”¨æ£€æµ‹ç»“æœã€ç½®ä¿¡åº¦åˆ†æ•°å’Œç±»åˆ«åˆå§‹åŒ–è½¨è¿¹ã€‚
        get_dists(tracks, detections): ä½¿ç”¨ IoUï¼ˆå¯é€‰ ReIDï¼‰è®¡ç®—è½¨è¿¹ä¸æ£€æµ‹æ¡†ä¹‹é—´çš„è·ç¦»ã€‚
        multi_predict(tracks): ä½¿ç”¨ YOLOv8 æ¨¡å‹é¢„æµ‹å¹¶è·Ÿè¸ªå¤šä¸ªç›®æ ‡ã€‚

    ç¤ºä¾‹:
        åˆå§‹åŒ– BOTSORT å¹¶å¤„ç†æ£€æµ‹ç»“æœ
        >>> bot_sort = BOTSORT(args, frame_rate=30)
        >>> bot_sort.init_track(dets, scores, cls, img)
        >>> bot_sort.multi_predict(tracks)

    æ³¨æ„:
        è¯¥ç±»ä¸“ä¸ºä¸ YOLOv8 æ£€æµ‹æ¨¡å‹é…åˆä½¿ç”¨è€Œè®¾è®¡ï¼ŒReID åŠŸèƒ½éœ€é€šè¿‡ args æ˜¾å¼å¯ç”¨ã€‚
    """

    def __init__(self, args, frame_rate=30):
        """
        åˆå§‹åŒ– YOLOv8 å¯¹è±¡è·Ÿè¸ªå™¨ï¼ŒåŒ…å« ReID æ¨¡å—å’Œ GMC ç®—æ³•ã€‚

        å‚æ•°:
            args (object): åŒ…å«è·Ÿè¸ªå‚æ•°çš„è§£æå‘½ä»¤è¡Œå‚æ•°ã€‚
            frame_rate (int): å½“å‰å¤„ç†è§†é¢‘çš„å¸§ç‡ã€‚

        ç¤ºä¾‹:
            ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°å’ŒæŒ‡å®šå¸§ç‡åˆå§‹åŒ– BOTSORTï¼š
            >>> args = parse_args()
            >>> bot_sort = BOTSORT(args, frame_rate=30)
        """
        super().__init__(args, frame_rate)
        # ReID æ¨¡å—
        self.proximity_thresh = args.proximity_thresh
        self.appearance_thresh = args.appearance_thresh

        if args.with_reid:
            # å°šæœªæ”¯æŒå¸¦ ReID çš„ BoT-SORT
            self.encoder = None
        self.gmc = GMC(method=args.gmc_method)

    def get_kalmanfilter(self):
        """è¿”å›ä¸€ä¸ª KalmanFilterXYWH å®ä¾‹ï¼Œç”¨äºåœ¨è·Ÿè¸ªè¿‡ç¨‹ä¸­é¢„æµ‹å’Œæ›´æ–°ç›®æ ‡çŠ¶æ€ã€‚"""
        return KalmanFilterXYWH()

    def init_track(self, dets, scores, cls, img=None):
        """ä½¿ç”¨æ£€æµ‹æ¡†ã€ç½®ä¿¡åº¦åˆ†æ•°ã€ç±»åˆ«æ ‡ç­¾å’Œå¯é€‰çš„ ReID ç‰¹å¾åˆå§‹åŒ–ç›®æ ‡è½¨è¿¹ã€‚"""
        if len(dets) == 0:
            return []
        if self.args.with_reid and self.encoder is not None:
            features_keep = self.encoder.inference(img, dets)
            return [BOTrack(xyxy, s, c, f) for (xyxy, s, c, f) in zip(dets, scores, cls, features_keep)]  # æ£€æµ‹ç›®æ ‡
        else:
            return [BOTrack(xyxy, s, c) for (xyxy, s, c) in zip(dets, scores, cls)]  # æ£€æµ‹ç›®æ ‡

    def get_dists(self, tracks, detections):
        """ä½¿ç”¨ IoU å’Œå¯é€‰çš„ ReID ç‰¹å¾è®¡ç®—è½¨è¿¹ä¸æ£€æµ‹ç›®æ ‡ä¹‹é—´çš„è·ç¦»ã€‚"""
        dists = matching.iou_distance(tracks, detections)
        dists_mask = dists > self.proximity_thresh

        if self.args.fuse_score:
            dists = matching.fuse_score(dists, detections)

        if self.args.with_reid and self.encoder is not None:
            emb_dists = matching.embedding_distance(tracks, detections) / 2.0
            emb_dists[emb_dists > self.appearance_thresh] = 1.0
            emb_dists[dists_mask] = 1.0
            dists = np.minimum(dists, emb_dists)
        return dists

    def multi_predict(self, tracks):
        """ä½¿ç”¨å…±äº«çš„å¡å°”æ›¼æ»¤æ³¢å™¨å¯¹å¤šä¸ªç›®æ ‡è½¨è¿¹è¿›è¡ŒçŠ¶æ€é¢„æµ‹ã€‚"""
        BOTrack.multi_predict(tracks)

    def reset(self):
        """é‡ç½® BOTSORT è·Ÿè¸ªå™¨ä¸ºåˆå§‹çŠ¶æ€ï¼Œæ¸…é™¤æ‰€æœ‰å·²è·Ÿè¸ªç›®æ ‡å’Œå†…éƒ¨çŠ¶æ€ã€‚"""
        super().reset()
        self.gmc.reset_params()
