# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import copy

import cv2
import numpy as np

from ultralytics.utils import LOGGER


class GMC:
    """
    å¹¿ä¹‰è¿åŠ¨è¡¥å¿ï¼ˆGMCï¼‰ç±»ï¼Œç”¨äºè§†é¢‘å¸§ä¸­çš„ç›®æ ‡è·Ÿè¸ªå’Œæ£€æµ‹ã€‚

    æ­¤ç±»æä¾›å¤šç§è·Ÿè¸ªç®—æ³•ï¼ˆåŒ…æ‹¬ ORBã€SIFTã€ECC å’Œç¨€ç–å…‰æµï¼‰çš„æ–¹æ³•ï¼Œç”¨äºåŸºäºå¸§ä¹‹é—´çš„å˜åŒ–è¿›è¡Œç›®æ ‡è·Ÿè¸ªä¸æ£€æµ‹ã€‚
    åŒæ—¶æ”¯æŒå¸§é™é‡‡æ ·ä»¥æé«˜å¤„ç†æ•ˆç‡ã€‚

    å±æ€§:
        method (str): æ‰€ä½¿ç”¨çš„è·Ÿè¸ªæ–¹æ³•ï¼Œå¯é€‰é¡¹åŒ…æ‹¬ 'orb', 'sift', 'ecc', 'sparseOptFlow', 'none'ã€‚
        downscale (int): é™é‡‡æ ·å› å­ï¼Œç”¨äºåŠ å¿«å¤„ç†é€Ÿåº¦ã€‚
        prevFrame (np.ndarray): å­˜å‚¨å‰ä¸€å¸§å›¾åƒã€‚
        prevKeyPoints (List): å­˜å‚¨å‰ä¸€å¸§çš„å…³é”®ç‚¹ã€‚
        prevDescriptors (np.ndarray): å­˜å‚¨å‰ä¸€å¸§çš„ç‰¹å¾æè¿°ç¬¦ã€‚
        initializedFirstFrame (bool): æ ‡å¿—ä½ï¼ŒæŒ‡ç¤ºæ˜¯å¦å·²ç»å¤„ç†äº†ç¬¬ä¸€å¸§ã€‚

    æ–¹æ³•:
        __init__: åˆå§‹åŒ– GMC å¯¹è±¡ï¼ŒæŒ‡å®šè·Ÿè¸ªæ–¹æ³•å’Œé™é‡‡æ ·å› å­ã€‚
        apply: å¯¹è¾“å…¥å¸§åº”ç”¨æ‰€é€‰æ–¹æ³•ï¼Œå¯é€‰åœ°ä½¿ç”¨æä¾›çš„æ£€æµ‹æ¡†ã€‚
        apply_ecc: å¯¹è¾“å…¥å¸§åº”ç”¨ ECC ç®—æ³•ã€‚
        apply_features: ä½¿ç”¨ ORB æˆ– SIFT ç­‰ç‰¹å¾ç‚¹æ–¹æ³•å¤„ç†å¸§ã€‚
        apply_sparseoptflow: ä½¿ç”¨ç¨€ç–å…‰æµæ³•å¤„ç†å¸§ã€‚
        reset_params: é‡ç½® GMC å¯¹è±¡çš„å†…éƒ¨çŠ¶æ€å‚æ•°ã€‚

    ç¤ºä¾‹:
        åˆ›å»ºä¸€ä¸ª GMC å¯¹è±¡å¹¶åº”ç”¨äºä¸€å¸§å›¾åƒ
        >>> gmc = GMC(method="sparseOptFlow", downscale=2)
        >>> frame = np.array([[1, 2, 3], [4, 5, 6]])
        >>> processed_frame = gmc.apply(frame)
        >>> print(processed_frame)
        array([[1, 2, 3],
               [4, 5, 6]])
    """

    def __init__(self, method: str = "sparseOptFlow", downscale: int = 2) -> None:
        """
        åˆå§‹åŒ– GMCï¼ˆå¹¿ä¹‰è¿åŠ¨è¡¥å¿ï¼‰å¯¹è±¡ï¼ŒæŒ‡å®šè·Ÿè¸ªæ–¹æ³•å’Œå›¾åƒé™é‡‡æ ·å› å­ã€‚

        å‚æ•°:
            method (str): æ‰€é€‰è·Ÿè¸ªæ–¹æ³•ï¼Œæ”¯æŒ 'orb', 'sift', 'ecc', 'sparseOptFlow', 'none'ã€‚
            downscale (int): å›¾åƒé™é‡‡æ ·å› å­ï¼Œç”¨äºåŠ å¿«å¤„ç†é€Ÿåº¦ã€‚

        ç¤ºä¾‹:
            åˆå§‹åŒ–ä¸€ä¸ªä½¿ç”¨ç¨€ç–å…‰æµæ–¹æ³•ï¼Œé™é‡‡æ ·å› å­ä¸º2çš„ GMC å¯¹è±¡
            >>> gmc = GMC(method="sparseOptFlow", downscale=2)
        """
        super().__init__()

        self.method = method
        self.downscale = max(1, downscale)

        if self.method == "orb":
            self.detector = cv2.FastFeatureDetector_create(20)
            self.extractor = cv2.ORB_create()
            self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING)

        elif self.method == "sift":
            self.detector = cv2.SIFT_create(nOctaveLayers=3, contrastThreshold=0.02, edgeThreshold=20)
            self.extractor = cv2.SIFT_create(nOctaveLayers=3, contrastThreshold=0.02, edgeThreshold=20)
            self.matcher = cv2.BFMatcher(cv2.NORM_L2)

        elif self.method == "ecc":
            number_of_iterations = 5000
            termination_eps = 1e-6
            self.warp_mode = cv2.MOTION_EUCLIDEAN
            self.criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)

        elif self.method == "sparseOptFlow":
            self.feature_params = dict(
                maxCorners=1000, qualityLevel=0.01, minDistance=1, blockSize=3, useHarrisDetector=False, k=0.04
            )

        elif self.method in {"none", "None", None}:
            self.method = None
        else:
            raise ValueError(f"é”™è¯¯ï¼šæœªçŸ¥çš„ GMC æ–¹æ³•: {method}")

        self.prevFrame = None
        self.prevKeyPoints = None
        self.prevDescriptors = None
        self.initializedFirstFrame = False

    def apply(self, raw_frame: np.array, detections: list = None) -> np.array:
        """
        å¯¹è¾“å…¥å¸§åº”ç”¨é€‰å®šçš„ç›®æ ‡æ£€æµ‹æˆ–è·Ÿè¸ªæ–¹æ³•ã€‚

        å‚æ•°:
            raw_frame (np.ndarray): åŸå§‹å›¾åƒå¸§ï¼Œå½¢çŠ¶ä¸º (H, W, C)ã€‚
            detections (List | None): å¯é€‰çš„ç›®æ ‡æ£€æµ‹æ¡†åˆ—è¡¨ï¼Œå‚ä¸å¤„ç†ã€‚

        è¿”å›:
            (np.ndarray): å¤„ç†åçš„å¸§ï¼Œæˆ–è¿”å›è¿åŠ¨ä¼°è®¡çŸ©é˜µï¼ˆå¦‚ä»¿å°„çŸ©é˜µï¼‰ã€‚

        ç¤ºä¾‹:
            >>> gmc = GMC(method="sparseOptFlow")
            >>> raw_frame = np.random.rand(480, 640, 3)
            >>> processed_frame = gmc.apply(raw_frame)
            >>> print(processed_frame.shape)
            (480, 640, 3)
        """
        if self.method in {"orb", "sift"}:
            return self.apply_features(raw_frame, detections)
        elif self.method == "ecc":
            return self.apply_ecc(raw_frame)
        elif self.method == "sparseOptFlow":
            return self.apply_sparseoptflow(raw_frame)
        else:
            return np.eye(2, 3)

    def apply_ecc(self, raw_frame: np.array) -> np.array:
        """
        å¯¹åŸå§‹å¸§åº”ç”¨ ECCï¼ˆå¢å¼ºç›¸å…³ç³»æ•°ï¼‰ç®—æ³•ä»¥è¿›è¡Œè¿åŠ¨è¡¥å¿ã€‚

        å‚æ•°:
            raw_frame (np.ndarray): å¾…å¤„ç†çš„åŸå§‹å¸§ï¼Œå½¢çŠ¶ä¸º (H, W, C)ã€‚

        è¿”å›:
            (np.ndarray): åº”ç”¨ ECC å˜æ¢åçš„å¤„ç†å¸§ã€‚

        ç¤ºä¾‹:
            >>> gmc = GMC(method="ecc")
            >>> processed_frame = gmc.apply_ecc(np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]))
            >>> print(processed_frame)
            [[1. 0. 0.]
            [0. 1. 0.]]
        """
        height, width, _ = raw_frame.shape
        frame = cv2.cvtColor(raw_frame, cv2.COLOR_BGR2GRAY)  # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
        H = np.eye(2, 3, dtype=np.float32)  # åˆå§‹åŒ–ä»¿å°„å˜æ¢çŸ©é˜µä¸ºå•ä½çŸ©é˜µ

        # è‹¥éœ€è¦é™é‡‡æ ·ï¼Œåˆ™è¿›è¡Œå›¾åƒé™é‡‡æ ·å¤„ç†
        if self.downscale > 1.0:
            frame = cv2.GaussianBlur(frame, (3, 3), 1.5)  # æ¨¡ç³Šå¤„ç†ä»¥å‡å°‘å™ªå£°
            frame = cv2.resize(frame, (width // self.downscale, height // self.downscale))  # å›¾åƒå°ºå¯¸ç¼©å°

        # è‹¥æ˜¯ç¬¬ä¸€å¸§ï¼Œåˆ™è¿›è¡Œåˆå§‹åŒ–
        if not self.initializedFirstFrame:
            self.prevFrame = frame.copy()  # ä¿å­˜å½“å‰å¸§ä½œä¸ºå‚è€ƒå¸§
            self.initializedFirstFrame = True  # æ ‡è®°å·²ç»åˆå§‹åŒ–
            return H  # è¿”å›å•ä½çŸ©é˜µ

        # è¿è¡Œ ECC ç®—æ³•ï¼Œç»“æœä¿å­˜åœ¨å˜æ¢çŸ©é˜µ H ä¸­
        # (cc, H) = cv2.findTransformECC(self.prevFrame, frame, H, self.warp_mode, self.criteria)
        try:
            (_, H) = cv2.findTransformECC(self.prevFrame, frame, H, self.warp_mode, self.criteria, None, 1)
        except Exception as e:
            LOGGER.warning(f"è­¦å‘Šï¼šECC å˜æ¢ä¼°è®¡å¤±è´¥ï¼Œä½¿ç”¨å•ä½å˜æ¢çŸ©é˜µã€‚å¼‚å¸¸ä¿¡æ¯ï¼š{e}")

        return H

    def apply_features(self, raw_frame: np.array, detections: list = None) -> np.array:
        """
        å¯¹åŸå§‹å¸§åº”ç”¨åŸºäºç‰¹å¾çš„æ–¹æ³•ï¼Œå¦‚ ORB æˆ– SIFTã€‚

        å‚æ•°:
            raw_frame (np.ndarray): è¦å¤„ç†çš„åŸå§‹å¸§ï¼Œå½¢çŠ¶ä¸º (H, W, C)ã€‚
            detections (List | None): ç”¨äºå¤„ç†çš„æ£€æµ‹æ¡†åˆ—è¡¨ã€‚

        è¿”å›:
            (np.ndarray): å¤„ç†åçš„å¸§ã€‚

        ç¤ºä¾‹:
            >>> gmc = GMC(method="orb")
            >>> raw_frame = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            >>> processed_frame = gmc.apply_features(raw_frame)
            >>> print(processed_frame.shape)
            (2, 3)
        """
        height, width, _ = raw_frame.shape
        frame = cv2.cvtColor(raw_frame, cv2.COLOR_BGR2GRAY)
        H = np.eye(2, 3)

        # ç¼©å°å›¾åƒå°ºå¯¸
        if self.downscale > 1.0:
            frame = cv2.resize(frame, (width // self.downscale, height // self.downscale))
            width = width // self.downscale
            height = height // self.downscale

        # æŸ¥æ‰¾å…³é”®ç‚¹
        mask = np.zeros_like(frame)
        mask[int(0.02 * height): int(0.98 * height), int(0.02 * width): int(0.98 * width)] = 255
        if detections is not None:
            for det in detections:
                tlbr = (det[:4] / self.downscale).astype(np.int_)
                mask[tlbr[1]: tlbr[3], tlbr[0]: tlbr[2]] = 0

        keypoints = self.detector.detect(frame, mask)

        # è®¡ç®—æè¿°å­
        keypoints, descriptors = self.extractor.compute(frame, keypoints)

        # å¤„ç†ç¬¬ä¸€å¸§
        if not self.initializedFirstFrame:
            # åˆå§‹åŒ–æ•°æ®
            self.prevFrame = frame.copy()
            self.prevKeyPoints = copy.copy(keypoints)
            self.prevDescriptors = copy.copy(descriptors)

            # åˆå§‹åŒ–å®Œæˆ
            self.initializedFirstFrame = True

            return H

        # è¿›è¡Œæè¿°å­çš„åŒ¹é…
        knnMatches = self.matcher.knnMatch(self.prevDescriptors, descriptors, 2)

        # æ ¹æ®æœ€å°ç©ºé—´è·ç¦»è¿‡æ»¤åŒ¹é…
        matches = []
        spatialDistances = []

        maxSpatialDistance = 0.25 * np.array([width, height])

        # å¤„ç†æ— åŒ¹é…çš„æƒ…å†µ
        if len(knnMatches) == 0:
            # ä¿å­˜åˆ°ä¸‹ä¸€å¸§
            self.prevFrame = frame.copy()
            self.prevKeyPoints = copy.copy(keypoints)
            self.prevDescriptors = copy.copy(descriptors)

            return H

        for m, n in knnMatches:
            if m.distance < 0.9 * n.distance:
                prevKeyPointLocation = self.prevKeyPoints[m.queryIdx].pt
                currKeyPointLocation = keypoints[m.trainIdx].pt

                spatialDistance = (
                    prevKeyPointLocation[0] - currKeyPointLocation[0],
                    prevKeyPointLocation[1] - currKeyPointLocation[1],
                )

                if (np.abs(spatialDistance[0]) < maxSpatialDistance[0]) and (
                    np.abs(spatialDistance[1]) < maxSpatialDistance[1]
                ):
                    spatialDistances.append(spatialDistance)
                    matches.append(m)

        meanSpatialDistances = np.mean(spatialDistances, 0)
        stdSpatialDistances = np.std(spatialDistances, 0)

        inliers = (spatialDistances - meanSpatialDistances) < 2.5 * stdSpatialDistances

        goodMatches = []
        prevPoints = []
        currPoints = []
        for i in range(len(matches)):
            if inliers[i, 0] and inliers[i, 1]:
                goodMatches.append(matches[i])
                prevPoints.append(self.prevKeyPoints[matches[i].queryIdx].pt)
                currPoints.append(keypoints[matches[i].trainIdx].pt)

        prevPoints = np.array(prevPoints)
        currPoints = np.array(currPoints)

        # åœ¨è¾“å‡ºå›¾åƒä¸Šç»˜åˆ¶å…³é”®ç‚¹åŒ¹é…
        # if False:
        #     import matplotlib.pyplot as plt
        #     matches_img = np.hstack((self.prevFrame, frame))
        #     matches_img = cv2.cvtColor(matches_img, cv2.COLOR_GRAY2BGR)
        #     W = self.prevFrame.shape[1]
        #     for m in goodMatches:
        #         prev_pt = np.array(self.prevKeyPoints[m.queryIdx].pt, dtype=np.int_)
        #         curr_pt = np.array(keypoints[m.trainIdx].pt, dtype=np.int_)
        #         curr_pt[0] += W
        #         color = np.random.randint(0, 255, 3)
        #         color = (int(color[0]), int(color[1]), int(color[2]))
        #
        #         matches_img = cv2.line(matches_img, prev_pt, curr_pt, tuple(color), 1, cv2.LINE_AA)
        #         matches_img = cv2.circle(matches_img, prev_pt, 2, tuple(color), -1)
        #         matches_img = cv2.circle(matches_img, curr_pt, 2, tuple(color), -1)
        #
        #     plt.figure()
        #     plt.imshow(matches_img)
        #     plt.show()

        # ä¼°è®¡åˆšæ€§å˜æ¢çŸ©é˜µ
        if prevPoints.shape[0] > 4:
            H, inliers = cv2.estimateAffinePartial2D(prevPoints, currPoints, cv2.RANSAC)

            # å¤„ç†ç¼©æ”¾è¿˜åŸ
            if self.downscale > 1.0:
                H[0, 2] *= self.downscale
                H[1, 2] *= self.downscale
        else:
            LOGGER.warning("è­¦å‘Š: åŒ¹é…ç‚¹æ•°ä¸è¶³")

        # ä¿å­˜æ•°æ®ä¾›ä¸‹ä¸€å¸§ä½¿ç”¨
        self.prevFrame = frame.copy()
        self.prevKeyPoints = copy.copy(keypoints)
        self.prevDescriptors = copy.copy(descriptors)

        return H

    def apply_sparseoptflow(self, raw_frame: np.array) -> np.array:
        """
        å¯¹åŸå§‹å¸§åº”ç”¨ç¨€ç–å…‰æµæ–¹æ³•ã€‚

        å‚æ•°:
            raw_frame (np.ndarray): å¾…å¤„ç†çš„åŸå§‹å¸§ï¼Œå½¢çŠ¶ä¸º (H, W, C)ã€‚

        è¿”å›:
            (np.ndarray): å¤„ç†åçš„ä»¿å°„å˜æ¢çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (2, 3)ã€‚

        ç¤ºä¾‹:
            >>> gmc = GMC()
            >>> result = gmc.apply_sparseoptflow(np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]))
            >>> print(result)
            [[1. 0. 0.]
             [0. 1. 0.]]
        """
        height, width, _ = raw_frame.shape
        frame = cv2.cvtColor(raw_frame, cv2.COLOR_BGR2GRAY)
        H = np.eye(2, 3)

        # å›¾åƒä¸‹é‡‡æ ·
        if self.downscale > 1.0:
            frame = cv2.resize(frame, (width // self.downscale, height // self.downscale))

        # è®¡ç®—å…³é”®ç‚¹
        keypoints = cv2.goodFeaturesToTrack(frame, mask=None, **self.feature_params)

        # å¤„ç†ç¬¬ä¸€å¸§
        if not self.initializedFirstFrame or self.prevKeyPoints is None:
            self.prevFrame = frame.copy()
            self.prevKeyPoints = copy.copy(keypoints)
            self.initializedFirstFrame = True
            return H

        # è®¡ç®—å…³é”®ç‚¹å¯¹åº”å…³ç³»ï¼ˆå‰åå¸§çš„å…‰æµï¼‰
        matchedKeypoints, status, _ = cv2.calcOpticalFlowPyrLK(self.prevFrame, frame, self.prevKeyPoints, None)

        # ä»…ä¿ç•™åŒ¹é…æˆåŠŸçš„å…³é”®ç‚¹å¯¹
        prevPoints = []
        currPoints = []

        for i in range(len(status)):
            if status[i]:
                prevPoints.append(self.prevKeyPoints[i])
                currPoints.append(matchedKeypoints[i])

        prevPoints = np.array(prevPoints)
        currPoints = np.array(currPoints)

        # è®¡ç®—åˆšæ€§å˜æ¢çŸ©é˜µï¼ˆä»¿å°„ï¼‰
        if (prevPoints.shape[0] > 4) and (prevPoints.shape[0] == prevPoints.shape[0]):
            H, _ = cv2.estimateAffinePartial2D(prevPoints, currPoints, cv2.RANSAC)

            if self.downscale > 1.0:
                H[0, 2] *= self.downscale
                H[1, 2] *= self.downscale
        else:
            LOGGER.warning("è­¦å‘Šï¼šåŒ¹é…ç‚¹æ•°é‡ä¸è¶³")

        self.prevFrame = frame.copy()
        self.prevKeyPoints = copy.copy(keypoints)

        return H

    def reset_params(self) -> None:
        """é‡ç½®å†…éƒ¨å‚æ•°ï¼ŒåŒ…æ‹¬ä¸Šä¸€å¸§å›¾åƒã€å…³é”®ç‚¹å’Œæè¿°å­ç­‰ã€‚"""
        self.prevFrame = None
        self.prevKeyPoints = None
        self.prevDescriptors = None
        self.initializedFirstFrame = False
