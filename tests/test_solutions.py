# Ultralytics ğŸš€ AGPL-3.0 è®¸å¯è¯ - https://ultralytics.com/license

import cv2
import pytest

from tests import TMP
from ultralytics import YOLO, solutions
from ultralytics.utils import ASSETS_URL, WEIGHTS_DIR
from ultralytics.utils.downloads import safe_download

DEMO_VIDEO = "solutions_ci_demo.mp4"
POSE_VIDEO = "solution_ci_pose_demo.mp4"


@pytest.mark.slow
def test_major_solutions():
    """æµ‹è¯•ç›®æ ‡è®¡æ•°ã€çƒ­åŠ›å›¾ã€é€Ÿåº¦ä¼°ç®—ã€è½¨è¿¹åŒºåŸŸå’Œé˜Ÿåˆ—ç®¡ç†ç­‰è§£å†³æ–¹æ¡ˆã€‚"""
    safe_download(url=f"{ASSETS_URL}/{DEMO_VIDEO}", dir=TMP)  # ä¸‹è½½æ¼”ç¤ºè§†é¢‘
    cap = cv2.VideoCapture(str(TMP / DEMO_VIDEO))  # è¯»å–è§†é¢‘æ–‡ä»¶
    assert cap.isOpened(), "è¯»å–è§†é¢‘æ–‡ä»¶æ—¶å‡ºé”™"
    
    # å®šä¹‰ç›®æ ‡åŒºåŸŸ
    region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]
    
    # åˆå§‹åŒ–ä¸åŒçš„åˆ†ææ–¹æ¡ˆ
    counter = solutions.ObjectCounter(region=region_points, model="yolo11n.pt", show=False)  # ç›®æ ‡è®¡æ•°
    heatmap = solutions.Heatmap(colormap=cv2.COLORMAP_PARULA, model="yolo11n.pt", show=False)  # çƒ­åŠ›å›¾
    heatmap_count = solutions.Heatmap(
        colormap=cv2.COLORMAP_PARULA, model="yolo11n.pt", show=False, region=region_points
    )  # å¸¦ç›®æ ‡è®¡æ•°çš„çƒ­åŠ›å›¾
    speed = solutions.SpeedEstimator(region=region_points, model="yolo11n.pt", show=False)  # é€Ÿåº¦ä¼°ç®—
    queue = solutions.QueueManager(region=region_points, model="yolo11n.pt", show=False)  # é˜Ÿåˆ—ç®¡ç†
    line_analytics = solutions.Analytics(analytics_type="line", model="yolo11n.pt", show=False)  # çº¿å½¢åˆ†æ
    pie_analytics = solutions.Analytics(analytics_type="pie", model="yolo11n.pt", show=False)  # é¥¼å›¾åˆ†æ
    bar_analytics = solutions.Analytics(analytics_type="bar", model="yolo11n.pt", show=False)  # æŸ±çŠ¶å›¾åˆ†æ
    area_analytics = solutions.Analytics(analytics_type="area", model="yolo11n.pt", show=False)  # é¢ç§¯åˆ†æ
    trackzone = solutions.TrackZone(region=region_points, model="yolo11n.pt", show=False)  # è½¨è¿¹åŒºåŸŸ

    frame_count = 0  # ç»Ÿè®¡å¸§æ•°ï¼ˆç”¨äºåˆ†æï¼‰

    # é€å¸§è¯»å–è§†é¢‘
    while cap.isOpened():
        success, im0 = cap.read()
        if not success:
            break
        frame_count += 1
        original_im0 = im0.copy()

        # è°ƒç”¨ä¸åŒçš„åˆ†ææ–¹æ³•
        _ = counter.count(original_im0.copy())  # ç›®æ ‡è®¡æ•°
        _ = heatmap.generate_heatmap(original_im0.copy())  # ç”Ÿæˆçƒ­åŠ›å›¾
        _ = heatmap_count.generate_heatmap(original_im0.copy())  # ç”Ÿæˆå¸¦ç›®æ ‡è®¡æ•°çš„çƒ­åŠ›å›¾
        _ = speed.estimate_speed(original_im0.copy())  # é€Ÿåº¦ä¼°ç®—
        _ = queue.process_queue(original_im0.copy())  # å¤„ç†é˜Ÿåˆ—ç®¡ç†
        _ = line_analytics.process_data(original_im0.copy(), frame_count)  # çº¿å½¢åˆ†æ
        _ = pie_analytics.process_data(original_im0.copy(), frame_count)  # é¥¼å›¾åˆ†æ
        _ = bar_analytics.process_data(original_im0.copy(), frame_count)  # æŸ±çŠ¶å›¾åˆ†æ
        _ = area_analytics.process_data(original_im0.copy(), frame_count)  # é¢ç§¯åˆ†æ
        _ = trackzone.trackzone(original_im0.copy())  # è½¨è¿¹åŒºåŸŸåˆ†æ
    
    cap.release()  # é‡Šæ”¾è§†é¢‘èµ„æº

    # æµ‹è¯•å¥èº«ç›‘æµ‹è§£å†³æ–¹æ¡ˆ
    safe_download(url=f"{ASSETS_URL}/{POSE_VIDEO}", dir=TMP)  # ä¸‹è½½å§¿æ€ä¼°è®¡è§†é¢‘
    cap = cv2.VideoCapture(str(TMP / POSE_VIDEO))  # è¯»å–å§¿æ€ä¼°è®¡è§†é¢‘
    assert cap.isOpened(), "è¯»å–è§†é¢‘æ–‡ä»¶æ—¶å‡ºé”™"
    
    gym = solutions.AIGym(kpts=[5, 11, 13], show=False)  # ç›‘æµ‹å…³é”®ç‚¹ 5, 11, 13

    while cap.isOpened():
        success, im0 = cap.read()
        if not success:
            break
        _ = gym.monitor(im0)  # ç›‘æµ‹å§¿åŠ¿
    
    cap.release()  # é‡Šæ”¾è§†é¢‘èµ„æº


@pytest.mark.slow
def test_instance_segmentation():
    """æµ‹è¯•å®ä¾‹åˆ†å‰²è§£å†³æ–¹æ¡ˆã€‚"""
    from ultralytics.utils.plotting import Annotator, colors

    model = YOLO(WEIGHTS_DIR / "yolo11n-seg.pt")  # åŠ è½½åˆ†å‰²æ¨¡å‹
    names = model.names  # è·å–ç±»åˆ«åç§°
    cap = cv2.VideoCapture(TMP / DEMO_VIDEO)  # è¯»å–æ¼”ç¤ºè§†é¢‘
    assert cap.isOpened(), "è¯»å–è§†é¢‘æ–‡ä»¶æ—¶å‡ºé”™"

    while cap.isOpened():
        success, im0 = cap.read()
        if not success:
            break
        
        results = model.predict(im0)  # è¿›è¡Œå®ä¾‹åˆ†å‰²é¢„æµ‹
        annotator = Annotator(im0, line_width=2)  # æ ‡æ³¨å·¥å…·
        
        # å¦‚æœæ£€æµ‹åˆ°äº†æ©ç 
        if results[0].masks is not None:
            clss = results[0].boxes.cls.cpu().tolist()  # è·å–ç±»åˆ«
            masks = results[0].masks.xy  # è·å–æ©ç åæ ‡
            for mask, cls in zip(masks, clss):
                color = colors(int(cls), True)  # é€‰å–é¢œè‰²
                annotator.seg_bbox(mask=mask, mask_color=color, label=names[int(cls)])  # ç»˜åˆ¶åˆ†å‰²ç»“æœ
    
    cap.release()  # é‡Šæ”¾è§†é¢‘èµ„æº
    cv2.destroyAllWindows()  # å…³é—­æ‰€æœ‰çª—å£


@pytest.mark.slow
def test_streamlit_predict():
    """æµ‹è¯• Streamlit ç›´æ’­æ¨ç†è§£å†³æ–¹æ¡ˆã€‚"""
    solutions.Inference().inference()  # è¿è¡Œ Streamlit æ¨ç†
